{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data():\n",
    "    df = pd.read_csv(Path(r'C:/\\Users/\\vchar/\\OneDrive/\\Desktop/\\ML Projects/\\Upwork/\\AlgoT_ML_Dev/\\GrammarEvolution/\\PonyGE2/\\datasets/\\BTCUSD_ohlcv.csv'))\n",
    "    # df = pd.read_csv('/kaggle/input/btcusd-test/BTCUSD_ohlcv.csv')\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "    df = df.iloc[-10000:]\n",
    "    df.sort_values('datetime', ascending=True, inplace=True)\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-30 22:05:00</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>16583.4</td>\n",
       "      <td>16583.4</td>\n",
       "      <td>4741.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-30 22:06:00</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-30 22:07:00</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>16583.4</td>\n",
       "      <td>16583.4</td>\n",
       "      <td>34811.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-30 22:08:00</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-30 22:09:00</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>5783.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime     open     high      low    close   volume\n",
       "0 2022-12-30 22:05:00  16583.5  16583.5  16583.4  16583.4   4741.0\n",
       "1 2022-12-30 22:06:00  16583.5  16583.5  16583.5  16583.5     22.0\n",
       "2 2022-12-30 22:07:00  16583.5  16583.5  16583.4  16583.4  34811.0\n",
       "3 2022-12-30 22:08:00  16583.5  16583.5  16583.5  16583.5     20.0\n",
       "4 2022-12-30 22:09:00  16583.5  16583.5  16583.5  16583.5   5783.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = generate_data()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numba import prange, njit, types\n",
    "from numba.typed import Dict\n",
    "import pandas_ta as ta\n",
    "import itertools\n",
    "import gc\n",
    "import time\n",
    "from scipy.stats import norm, iqr, chi2, chi2_contingency\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_observation(x, x_median, x_iqr, is_centered=True, is_scaled=True):\n",
    "\n",
    "    if is_centered:\n",
    "        new_x = x - x_median\n",
    "    else:\n",
    "        new_x = x.copy()\n",
    "\n",
    "    if is_scaled:\n",
    "        new_x = 100 * norm.cdf(0.25 * new_x / x_iqr) - 50\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    return new_x\n",
    "\n",
    "# Creating functions for trend indicators/variables\n",
    "\n",
    "def MA_DIFFERENCE(df, ShortLength, LongLength, Lag):\n",
    "    short_ma = ta.sma(df['close'], length=ShortLength)\n",
    "    long_ma = ta.sma(df['close'].shift(Lag), length=LongLength)\n",
    "    ma_diff = short_ma - long_ma\n",
    "    df_atr = ta.atr(high=df['high'], low=df['low'], close=df['close'], length=LongLength+Lag)\n",
    "    df_stat = ma_diff / df_atr\n",
    "    period = LongLength+Lag\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['MA_Diff']\n",
    "    return df_stat\n",
    "\n",
    "def get_ls_slope(y, length):\n",
    "    # X = np.vstack([np.arange(1, length+1), np.ones(length, dtype='int')]).T\n",
    "    # m, c = np.linalg.lstsq(X, y, rcond=None)[0]\n",
    "    x = np.arange(1, length+1)\n",
    "    # np.polyfit(x, y, 1)\n",
    "    return np.polyfit(x, y, 1)[0] #m #* np.arange(1, length+1) + c\n",
    "\n",
    "def LINEAR_PER_ATR(df, HistLength, ATRlength):\n",
    "    df_log_mean = np.log(df[['high', 'low', 'open', 'close']].mean(axis=1))\n",
    "    df_atr = ta.atr(high=df['high'], low=df['low'], close=df['close'], length=ATRlength)\n",
    "    df_slope = df_log_mean.rolling(window=HistLength).apply(lambda x: get_ls_slope(y=x, length=len(x)))\n",
    "    df_stat = df_slope / df_atr\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Price_Velocity']\n",
    "    return df_stat\n",
    "\n",
    "def get_quad_slope(y, length):\n",
    "    # X = np.vstack([np.arange(1, length+1), np.ones(length, dtype='int')]).T\n",
    "    # m, c = np.linalg.lstsq(X, y, rcond=None)[0]\n",
    "    x = np.arange(1, length+1)\n",
    "    # np.polyfit(x, y, 1)\n",
    "    return np.polyfit(x, y, 2)[0] #m #* np.arange(1, length+1) + c\n",
    "\n",
    "def QUADRATIC_PER_ATR(df, HistLength, ATRlength):\n",
    "    df_log_mean = np.log(df[['high', 'low', 'open', 'close']].mean(axis=1))\n",
    "    df_atr = ta.atr(high=df['high'], low=df['low'], close=df['close'], length=ATRlength)\n",
    "    df_slope = df_log_mean.rolling(window=HistLength).apply(lambda x: get_quad_slope(y=x, length=len(x)))\n",
    "    df_stat = df_slope / df_atr\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Price_Acceleration']\n",
    "    return df_stat\n",
    "\n",
    "def get_cubic_slope(y, length):\n",
    "    # X = np.vstack([np.arange(1, length+1), np.ones(length, dtype='int')]).T\n",
    "    # m, c = np.linalg.lstsq(X, y, rcond=None)[0]\n",
    "    x = np.arange(1, length+1)\n",
    "    # np.polyfit(x, y, 1)\n",
    "    return np.polyfit(x, y, 3)[0] #m #* np.arange(1, length+1) + c\n",
    "\n",
    "def CUBIC_PER_ATR(df, HistLength, ATRlength):\n",
    "    df_log_mean = np.log(df[['high', 'low', 'open', 'close']].mean(axis=1))\n",
    "    df_atr = ta.atr(high=df['high'], low=df['low'], close=df['close'], length=ATRlength)\n",
    "    df_slope = df_log_mean.rolling(window=HistLength).apply(lambda x: get_cubic_slope(y=x, length=len(x)))\n",
    "    df_stat = df_slope / df_atr\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Acceleration_Rate_of_Change']\n",
    "    return df_stat\n",
    "\n",
    "def RSI(df, HistLength):\n",
    "    rsi_df = ta.rsi(df['close'], length=HistLength).to_frame()\n",
    "    rsi_df.columns = ['RSI']\n",
    "    return rsi_df\n",
    "\n",
    "def STOCHASTIC_K(df, fastk_period, slowk_period, slowd_period):\n",
    "\n",
    "\tdf_stat = ta.stoch(\n",
    "\t\tdf[\"high\"], df[\"low\"], df[\"close\"], \n",
    "\t\tfastk_period, slowk_period, slowd_period)[f'STOCHk_{fastk_period}_{slowk_period}_{slowd_period}']\n",
    "\tdf_stat = df_stat.to_frame()\n",
    "\tdf_stat.columns = ['STOCHASTIC_K']\n",
    "\treturn df_stat\n",
    "\n",
    "def STOCHASTIC_D(df, fastk_period, slowk_period, slowd_period):\n",
    "\tdf_stat = ta.stoch(\n",
    "\t\tdf[\"high\"], df[\"low\"], df[\"close\"], \n",
    "\t\tfastk_period, slowk_period, slowd_period)[f'STOCHd_{fastk_period}_{slowk_period}_{slowd_period}']\n",
    "\tdf_stat = df_stat.to_frame()\n",
    "\tdf_stat.columns = ['STOCHASTIC_D']\n",
    "\treturn df_stat\n",
    "\n",
    "def PRICE_MOMENTUM(df, HistLength, StdDevLength):\n",
    "\n",
    "    df_stat = df['close'] / df['close'].shift(HistLength)\n",
    "    df_std = df['close'].rolling(window=StdDevLength).std()\n",
    "    df_stat = df_stat / df_std\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Price_Momentum']\n",
    "    return df_stat\n",
    "\n",
    "def ADX(df, HistLength):\n",
    "\tdf_stat = ta.adx(\n",
    "\t\thigh=df['high'], \n",
    "\t\tlow=df['low'], \n",
    "\t\tclose=df['close'], \n",
    "\t\tlength=HistLength\n",
    "\t)[f'ADX_{HistLength}']\n",
    "\n",
    "\tdf_stat = df_stat.to_frame()\n",
    "\tdf_stat.columns = ['ADX']\n",
    "\treturn df_stat\n",
    "\n",
    "def MIN_ADX(df, HistLength, MinLength):\n",
    "\n",
    "    adx_list = []\n",
    "\n",
    "    for i in range(MinLength):\n",
    "        temp_adx = ta.adx(\n",
    "            high=df['high'].shift(i), \n",
    "            low=df['low'].shift(i), \n",
    "            close=df['close'].shift(i), \n",
    "            length=HistLength\n",
    "        )[f'ADX_{HistLength}']\n",
    "\n",
    "        adx_list.append(temp_adx.values)\n",
    "\n",
    "    df_stat = pd.Series(np.min(np.array(adx_list), axis=0), index=temp_adx.index)\n",
    "    df_stat = df_stat.to_frame()  \n",
    "    df_stat.columns = ['Min_ADX']\n",
    "    return df_stat\n",
    "\n",
    "def RESIDUAL_MIN_ADX(df, HistLength, MinLength):\n",
    "\n",
    "    current_adx = ta.adx(\n",
    "        high=df['high'], \n",
    "        low=df['low'], \n",
    "        close=df['close'], \n",
    "        length=HistLength\n",
    "    )[f'ADX_{HistLength}']\n",
    "\n",
    "    min_adx = MIN_ADX(df, HistLength, MinLength)\n",
    "\n",
    "    df_stat = current_adx - min_adx\n",
    "\n",
    "    return df_stat\n",
    "\n",
    "def MAX_ADX(df, HistLength, MaxLength):\n",
    "\n",
    "    adx_list = []\n",
    "\n",
    "    for i in range(MaxLength):\n",
    "        temp_adx = ta.adx(\n",
    "            high=df['high'].shift(i), \n",
    "            low=df['low'].shift(i), \n",
    "            close=df['close'].shift(i), \n",
    "            length=HistLength\n",
    "        )[f'ADX_{HistLength}']\n",
    "\n",
    "        adx_list.append(temp_adx.values)\n",
    "\n",
    "    df_stat = pd.DataFrame(np.max(np.array(adx_list), axis=0), index=df.index)\n",
    "    df_stat.columns = ['MAX_ADX']\n",
    "    return df_stat\n",
    "\n",
    "def RESIDUAL_MAX_ADX(df, HistLength, MaxLength):\n",
    "\n",
    "    current_adx = ta.adx(\n",
    "        high=df['high'], \n",
    "        low=df['low'], \n",
    "        close=df['close'], \n",
    "        length=HistLength\n",
    "    )[f'ADX_{HistLength}']\n",
    "\n",
    "    max_adx = MAX_ADX(df, HistLength, MaxLength)\n",
    "\n",
    "    df_stat = max_adx - current_adx\n",
    "\n",
    "    return df_stat\n",
    "\n",
    "def DELTA_ADX(df, HistLength,  DeltaLength):\n",
    "\n",
    "    current_adx = ta.adx(\n",
    "        high=df['high'], \n",
    "        low=df['low'], \n",
    "        close=df['close'], \n",
    "        length=HistLength\n",
    "    )[f'ADX_{HistLength}']\n",
    "\n",
    "    lag_adx = ta.adx(\n",
    "        high=df['high'].shift(DeltaLength), \n",
    "        low=df['low'].shift(DeltaLength), \n",
    "        close=df['close'].shift(DeltaLength), \n",
    "        length=HistLength\n",
    "    )[f'ADX_{HistLength}']\n",
    "\n",
    "    df_stat = current_adx - lag_adx\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['ADX_Velocity']\n",
    "    return df_stat\n",
    "\n",
    "def ACCEL_ADX(df, HistLength, DeltaLength):\n",
    "\n",
    "    current_adx = ta.adx(\n",
    "        high=df['high'], \n",
    "        low=df['low'], \n",
    "        close=df['close'], \n",
    "        length=HistLength\n",
    "    )[f'ADX_{HistLength}']\n",
    "\n",
    "    lag_adx1 = ta.adx(\n",
    "        high=df['high'].shift(DeltaLength), \n",
    "        low=df['low'].shift(DeltaLength), \n",
    "        close=df['close'].shift(DeltaLength), \n",
    "        length=HistLength\n",
    "    )[f'ADX_{HistLength}']\n",
    "\n",
    "    lag_adx2 = ta.adx(\n",
    "        high=df['high'].shift(2*DeltaLength), \n",
    "        low=df['low'].shift(2*DeltaLength), \n",
    "        close=df['close'].shift(2*DeltaLength), \n",
    "        length=HistLength\n",
    "    )[f'ADX_{HistLength}']\n",
    "\n",
    "    df_stat = current_adx + lag_adx2 - 2 * lag_adx1\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['ADX_Acceleration']\n",
    "    return df_stat\n",
    "\n",
    "def INTRADAY_INTENSITY(df, HistLength):\n",
    "\n",
    "    diff1 = df['high'] - df['low']\n",
    "    diff2 = df['high'] - df['close'].shift(1)\n",
    "    diff3 = df['close'].shift(1) - df['low']\n",
    "\n",
    "    true_range = np.max(\n",
    "        np.array(\n",
    "            [\n",
    "                diff1.values, \n",
    "                diff2.values, \n",
    "                diff3.values\n",
    "             ]\n",
    "        ), \n",
    "    axis=0\n",
    "    )\n",
    "\n",
    "    current_change = df['close'] - df['open']\n",
    "\n",
    "    df_stat = current_change / true_range\n",
    "    df_stat = df_stat.rolling(window=HistLength).mean()\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Intraday_Intensity']\n",
    "    return df_stat\n",
    "\n",
    "def DELTA_INTRADAY_INTENSITY(df, HistLength, DeltaLength):\n",
    "\n",
    "    current_inten = INTRADAY_INTENSITY(df, HistLength)\n",
    "    lag_inten = INTRADAY_INTENSITY(df=df.shift(DeltaLength), HistLength=HistLength)\n",
    "    df_stat = current_inten - lag_inten\n",
    "    df_stat.columns = ['Delta_Intraday_Intensity']\n",
    "    return df_stat\n",
    "\n",
    "def REACTIVITY(df, HistLength):\n",
    "\n",
    "    price_change = df['close'] - df['close'].shift(HistLength)\n",
    "\n",
    "    max_price = df['high'].rolling(window=HistLength).max()\n",
    "    min_price = df['low'].rolling(window=HistLength).min()\n",
    "    price_range = max_price - min_price\n",
    "\n",
    "    total_volume = df['volume'].rolling(window=HistLength).sum()\n",
    "\n",
    "    ema_price_range = ta.ema(close=price_range, length=8*HistLength)\n",
    "    ema_total_volume = ta.ema(close=total_volume, length=8*HistLength)\n",
    "    aspect_ratio = (price_range / ema_price_range) / (total_volume / ema_total_volume)\n",
    "\n",
    "    raw_reactivity = price_change * aspect_ratio\n",
    "    df_stat = raw_reactivity / ema_price_range\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Reactivity']\n",
    "    return df_stat\n",
    "\n",
    "def DELTA_REACTIVITY(df, HistLength, DeltaDist):\n",
    "\n",
    "    current_reactivity = REACTIVITY(df, HistLength)\n",
    "    lag_reactivity = REACTIVITY(df=df.shift(DeltaDist), HistLength=HistLength)\n",
    "\n",
    "    stat_values = (current_reactivity - lag_reactivity).values.reshape(-1, )\n",
    "\n",
    "    df_stat = pd.Series(stat_values, index=df.index)\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Delta_Reactivity']\n",
    "    return df_stat\n",
    "\n",
    "def MIN_REACTIVITY(df, HistLength, Dist):\n",
    "\n",
    "    reactivity_list = []\n",
    "    for i in range(Dist):\n",
    "        reactivity_list.append(REACTIVITY(df=df.shift(i), HistLength=HistLength).values)\n",
    "\n",
    "    stat_values = np.min(np.array(reactivity_list), axis=0).reshape(-1, )\n",
    "\n",
    "    df_stat = pd.Series(stat_values, index=df.index)\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Min_Reactivity']\n",
    "    return df_stat\n",
    "\n",
    "def MAX_REACTIVITY(df, HistLength, Dist):\n",
    "\n",
    "    reactivity_list = []\n",
    "    for i in range(Dist):\n",
    "        reactivity_list.append(REACTIVITY(df=df.shift(i), HistLength=HistLength).values)\n",
    "\n",
    "    stat_values = np.max(np.array(reactivity_list), axis=0).reshape(-1, )\n",
    "\n",
    "    df_stat = pd.Series(stat_values, index=df.index)\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Max_Reactivity']\n",
    "    return df_stat\n",
    "\n",
    "# Creating functions for trend like indicators/variables\n",
    "\n",
    "def CLOSE_TO_CLOSE(df):\n",
    "\n",
    "    df_stat = 100 * np.log(df['close'] / df['close'].shift(1))\n",
    "    df_stat = df_stat.to_frame()\n",
    "    df_stat.columns = ['Close_to_Close']\n",
    "    return df_stat\n",
    "\n",
    "@njit\n",
    "def get_n_day_high(x, y):\n",
    "\n",
    "    N = len(x) + 1\n",
    "\n",
    "    for i in prange(len(x)-1, -1, -1):\n",
    "        if x[i] > y:\n",
    "            N = i + 1\n",
    "            break\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    return 100 * (N-1) / len(x) - 50\n",
    "\n",
    "@njit\n",
    "def get_hist_values(x, length):\n",
    "\n",
    "    hist_values = []\n",
    "\n",
    "    for i in prange(length, len(x)+1):\n",
    "\n",
    "        hist_values.append(x[i-length: i])\n",
    "\n",
    "    return hist_values\n",
    "\n",
    "def N_DAY_HIGH(df, HistLength):\n",
    "\n",
    "    list_of_values = get_hist_values(x=df['high'].values, length=HistLength)\n",
    "    # df['high'].rolling(window=HistLength, closed='left').apply(\n",
    "    #     lambda x: list_of_values.append(x.values) or 0, \n",
    "    #     raw=False\n",
    "    # )\n",
    "\n",
    "    temp_df = pd.Series(list_of_values, index=df.iloc[HistLength-1:].index)\n",
    "    temp_df = temp_df.to_frame()\n",
    "    temp_df.columns = ['high_list']\n",
    "    temp_df['high'] = df.iloc[HistLength:]['high']\n",
    "\n",
    "    df_stat = temp_df.apply(lambda x: get_n_day_high(x=x['high_list'], y=x['high']), axis=1)\n",
    "    df_stat = df_stat.to_frame()\n",
    "    df_stat.columns = ['N_Day_High']\n",
    "    return df_stat\n",
    "\n",
    "@njit\n",
    "def get_n_day_low(x, y):\n",
    "\n",
    "    N = len(x) + 1\n",
    "\n",
    "    for i in prange(len(x)-1, -1, -1):\n",
    "        if x[i] < y:\n",
    "            N = i + 1\n",
    "            break\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    return 100 * (N-1) / len(x) - 50\n",
    "\n",
    "def N_DAY_LOW(df, HistLength):\n",
    "\n",
    "    list_of_values = get_hist_values(x=df['low'].values, length=HistLength)\n",
    "    # df['low'].rolling(window=HistLength, closed='left').apply(\n",
    "    #     lambda x: list_of_values.append(x.values) or 0, \n",
    "    #     raw=False\n",
    "    # )\n",
    "\n",
    "    temp_df = pd.Series(list_of_values, index=df.iloc[HistLength-1:].index)\n",
    "    temp_df = temp_df.to_frame()\n",
    "    temp_df.columns = ['low_list']\n",
    "    temp_df['low'] = df.iloc[HistLength:]['low']\n",
    "\n",
    "    df_stat = temp_df.apply(lambda x: get_n_day_low(x=x['low_list'], y=x['low']), axis=1)\n",
    "    df_stat = df_stat.to_frame()\n",
    "    df_stat.columns = ['N_Day_Low']\n",
    "    return df_stat\n",
    "\n",
    "# Creating functions for indicators/variables of deviations from trend\n",
    "\n",
    "def CLOSE_MINUS_MOVING_AVERAGE(df, HistLen, ATRlen):\n",
    "\n",
    "    close_ratio = np.log(df['close'] / df['close'].rolling(window=HistLen).mean())\n",
    "    atr = ta.atr(high=df['high'], low=df['low'], close=df['close'], length=ATRlen)\n",
    "    df_stat = close_ratio / atr\n",
    "    period = HistLen\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['CMMA']\n",
    "    return df_stat\n",
    "\n",
    "def get_ls_fit(y):\n",
    "    length = len(y)\n",
    "    x = np.arange(1, length+1)\n",
    "    result = np.polyfit(x, y, 1)\n",
    "    y_fit = result[1] + length * result[0]\n",
    "    std_dev = np.sum((y - y_fit)**2)\n",
    "    std_error = (std_dev / (length-1)) ** 0.5\n",
    "    return [y_fit, std_error]\n",
    "\n",
    "def LINEAR_DEVIATION(df, HistLength):\n",
    "\n",
    "    df_log_mean = np.log(df[['high', 'low', 'open', 'close']].mean(axis=1))\n",
    "\n",
    "    list_of_values = get_hist_values(x=df_log_mean.values, length=HistLength)\n",
    "    # df_log_mean.rolling(window=HistLength, closed='both').apply(\n",
    "    #     lambda x: list_of_values.append(x.values) or 0, \n",
    "    #     raw=False\n",
    "    # )\n",
    "\n",
    "    temp_df = pd.Series(list_of_values, index=df.iloc[HistLength-1:].index)\n",
    "    temp_df = temp_df.apply(lambda x: get_ls_fit(y=x))\n",
    "    temp_df = pd.DataFrame(temp_df.to_list(), columns=['fit','std_error'])\n",
    "    temp_df.index = df.iloc[HistLength-1:].index\n",
    "    temp_df['log_price'] = df_log_mean.iloc[HistLength-1:]\n",
    "\n",
    "    df_stat = (temp_df['log_price'] - temp_df['fit']) / temp_df['std_error']\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Linear_Deviation']\n",
    "    return df_stat\n",
    "\n",
    "def get_quadratic_fit(y):\n",
    "    length = len(y)\n",
    "    x = np.arange(1, length+1)\n",
    "    result = np.polyfit(x, y, 2)\n",
    "    y_fit = result[2] + length * result[1] + (length**2) * result[0]\n",
    "    std_dev = np.sum((y - y_fit)**2)\n",
    "    std_error = (std_dev / (length-1)) ** 0.5\n",
    "    return [y_fit, std_error]\n",
    "\n",
    "def QUADRATIC_DEVIATION(df, HistLength):\n",
    "\n",
    "    df_log_mean = np.log(df[['high', 'low', 'open', 'close']].mean(axis=1))\n",
    "\n",
    "    # list_of_values = []\n",
    "    # df_log_mean.rolling(window=HistLength, closed='both').apply(\n",
    "    #     lambda x: list_of_values.append(x.values) or 0, \n",
    "    #     raw=False\n",
    "    # )\n",
    "    list_of_values = get_hist_values(x=df_log_mean.values, length=HistLength)\n",
    "\n",
    "    temp_df = pd.Series(list_of_values, index=df.iloc[HistLength-1:].index)\n",
    "    temp_df = temp_df.apply(lambda x: get_quadratic_fit(y=x))\n",
    "    temp_df = pd.DataFrame(temp_df.to_list(), columns=['fit','std_error'])\n",
    "    temp_df.index = df.iloc[HistLength-1:].index\n",
    "    temp_df['log_price'] = df_log_mean.iloc[HistLength-1:]\n",
    "\n",
    "    df_stat = (temp_df['log_price'] - temp_df['fit']) / temp_df['std_error']\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Quadratic_Deviation']\n",
    "    return df_stat\n",
    "\n",
    "def get_cubic_fit(y):\n",
    "    length = len(y)\n",
    "    x = np.arange(1, length+1)\n",
    "    result = np.polyfit(x, y, 3)\n",
    "    y_fit = result[3] + length * result[2] + (length**2) * result[1] + (length**3) * result[0]\n",
    "    std_dev = np.sum((y - y_fit)**2)\n",
    "    std_error = (std_dev / (length-1)) ** 0.5\n",
    "    return [y_fit, std_error]\n",
    "\n",
    "def CUBIC_DEVIATION(df, HistLength):\n",
    "\n",
    "    df_log_mean = np.log(df[['high', 'low', 'open', 'close']].mean(axis=1))\n",
    "\n",
    "    # list_of_values = []\n",
    "    # df_log_mean.rolling(window=HistLength, closed='both').apply(\n",
    "    #     lambda x: list_of_values.append(x.values) or 0, \n",
    "    #     raw=False\n",
    "    # )\n",
    "    list_of_values = get_hist_values(x=df_log_mean.values, length=HistLength)\n",
    "\n",
    "    temp_df = pd.Series(list_of_values, index=df.iloc[HistLength-1:].index)\n",
    "    temp_df = temp_df.apply(lambda x: get_cubic_fit(y=x))\n",
    "    temp_df = pd.DataFrame(temp_df.to_list(), columns=['fit','std_error'])\n",
    "    temp_df.index = df.iloc[HistLength-1:].index\n",
    "    temp_df['log_price'] = df_log_mean.iloc[HistLength-1:]\n",
    "\n",
    "    df_stat = (temp_df['log_price'] - temp_df['fit']) / temp_df['std_error']\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Cubic_Deviation']\n",
    "    return df_stat\n",
    "\n",
    "def get_ls_fit2(x, y):\n",
    "    result = np.polyfit(x, y, 1)\n",
    "    y_fit = result[1] + x[-1] * result[0]\n",
    "    return y_fit\n",
    "\n",
    "def DETRENDED_RSI(df, DetrendedLength, DetrenderLength, Lookback):\n",
    "\n",
    "    rsi_y = ta.rsi(df['close'], length=DetrendedLength)\n",
    "\n",
    "    if DetrendedLength == 2:\n",
    "        rsi_y = 1 / (1 + np.exp(-rsi_y))\n",
    "\n",
    "    rsi_x = ta.rsi(df['close'], length=DetrenderLength)\n",
    "\n",
    "    rsi_array = np.vstack([rsi_y.values, rsi_x.values]).T\n",
    "    rsi_df = pd.DataFrame(rsi_array, columns=['rsi_y', 'rsi_x'], index=rsi_y.index)\n",
    "    rsi_df.dropna(inplace=True)\n",
    "\n",
    "    # list_of_rsi_y = []\n",
    "    # rsi_df['rsi_y'].rolling(window=Lookback, closed='both').apply(\n",
    "    #     lambda x: list_of_rsi_y.append(x.values) or 0, \n",
    "    #     raw=False\n",
    "    # )\n",
    "    list_of_rsi_y = get_hist_values(x=rsi_df['rsi_y'].values, length=Lookback)\n",
    "\n",
    "    # list_of_rsi_x = []\n",
    "    # rsi_df['rsi_x'].rolling(window=Lookback, closed='both').apply(\n",
    "    #     lambda x: list_of_rsi_x.append(x.values) or 0, \n",
    "    #     raw=False\n",
    "    # )\n",
    "    list_of_rsi_x = get_hist_values(x=rsi_df['rsi_x'].values, length=Lookback)\n",
    "\n",
    "    temp_df = pd.Series(list_of_rsi_x, index=df.iloc[Lookback-1+DetrenderLength:].index)\n",
    "    temp_df = temp_df.to_frame()\n",
    "    temp_df.columns = ['rsi_x']\n",
    "    temp_df['rsi_y'] = list_of_rsi_y\n",
    "\n",
    "    temp_df['fit'] = temp_df.apply(lambda x: get_ls_fit2(x=x['rsi_x'], y=x['rsi_y']), axis=1)\n",
    "    temp_df['rsi_y'] = rsi_y.iloc[Lookback-1:]\n",
    "\n",
    "    df_stat = (temp_df['rsi_y'] - temp_df['fit'])\n",
    "    df_stat = df_stat.to_frame()\n",
    "    df_stat.columns = ['Detrended_RSI']\n",
    "    return df_stat\n",
    "\n",
    "# Creating functions for volatility indicators/variables\n",
    "\n",
    "def ABS_PRICE_CHANGE_OSCILLATOR(df, ShortLen, Multiplier):\n",
    "\n",
    "    price_changes = np.abs(np.log(df['close']/df['close'].shift(1)))\n",
    "    short_ma = price_changes.rolling(window=ShortLen).mean()\n",
    "    long_ma = price_changes.rolling(window=ShortLen*Multiplier).mean()\n",
    "    atr = ta.atr(high=df['high'], low=df['low'], close=df['close'], length=ShortLen*Multiplier)\n",
    "    df_stat = (short_ma - long_ma) / atr\n",
    "    period = ShortLen\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['APCO']\n",
    "    return df_stat\n",
    "\n",
    "def PRICE_VARIANCE_RATIO(df, HistLength, Multiplier):\n",
    "\n",
    "    log_prices = np.log(df['close'])\n",
    "    short_var = log_prices.rolling(window=HistLength).var()\n",
    "    long_var = log_prices.rolling(window=HistLength*Multiplier).var()\n",
    "    df_stat = short_var / long_var\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['PVR']\n",
    "    return df_stat\n",
    "\n",
    "def MIN_PRICE_VARIANCE_RATIO(df, HistLen, Mult, Mlength):\n",
    "\n",
    "    pvr_list = []\n",
    "\n",
    "    for i in range(Mlength):\n",
    "\n",
    "        pvr_list.append(PRICE_VARIANCE_RATIO(df=df.shift(i), HistLength=HistLen, Multiplier=Mult))\n",
    "\n",
    "    df_stat = np.min(np.array(pvr_list), axis=0)\n",
    "    df_stat = pd.DataFrame(df_stat, index=df.index)\n",
    "    df_stat.columns = ['MinPVR']\n",
    "    return df_stat\n",
    "\n",
    "def MAX_PRICE_VARIANCE_RATIO(df, HistLen, Mult, Mlength):\n",
    "\n",
    "    pvr_list = []\n",
    "\n",
    "    for i in range(Mlength):\n",
    "\n",
    "        pvr_list.append(PRICE_VARIANCE_RATIO(df=df.shift(i), HistLength=HistLen, Multiplier=Mult))\n",
    "\n",
    "    df_stat = np.max(np.array(pvr_list), axis=0)\n",
    "    df_stat = pd.DataFrame(df_stat, index=df.index)\n",
    "    df_stat.columns = ['MaxPVR']\n",
    "    return df_stat\n",
    "\n",
    "def CHANGE_VARIANCE_RATIO(df, HistLength, Multiplier):\n",
    "\n",
    "    log_prices = np.log(df['close']/df['close'].shift(1))\n",
    "    short_var = log_prices.rolling(window=HistLength).var()\n",
    "    long_var = log_prices.rolling(window=HistLength*Multiplier).var()\n",
    "    df_stat = short_var / long_var\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['CVR']\n",
    "    return df_stat\n",
    "\n",
    "def MIN_CHANGE_VARIANCE_RATIO(df, HistLen, Mult, Mlen):\n",
    "\n",
    "    pvr_list = []\n",
    "\n",
    "    for i in range(Mlen):\n",
    "\n",
    "        pvr_list.append(CHANGE_VARIANCE_RATIO(df=df.shift(i), HistLength=HistLen, Multiplier=Mult))\n",
    "\n",
    "    df_stat = np.min(np.array(pvr_list), axis=0)\n",
    "    df_stat = pd.DataFrame(df_stat, index=df.index)\n",
    "    df_stat.columns = ['MinCVR']\n",
    "    return df_stat\n",
    "\n",
    "def MAX_CHANGE_VARIANCE_RATIO(df, HistLen, Mult, Mlength):\n",
    "\n",
    "    pvr_list = []\n",
    "\n",
    "    for i in range(Mlength):\n",
    "\n",
    "        pvr_list.append(CHANGE_VARIANCE_RATIO(df=df.shift(i), HistLength=HistLen, Multiplier=Mult))\n",
    "\n",
    "    df_stat = np.max(np.array(pvr_list), axis=0)\n",
    "    df_stat = pd.DataFrame(df_stat, index=df.index)\n",
    "    df_stat.columns = ['MaxCVR']\n",
    "    return df_stat\n",
    "\n",
    "def ATR_RATIO(df, HistLength, Multiplier):\n",
    "\n",
    "    short_atr = ta.atr(high=df['high'], low=df['low'], close=df['close'], length=HistLength)\n",
    "    long_atr = ta.atr(high=df['high'], low=df['low'], close=df['close'], length=HistLength*Multiplier)\n",
    "    df_stat = short_atr / long_atr\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['ATR_Ratio']\n",
    "    return df_stat\n",
    "\n",
    "def DELTA_PRICE_VARIANCE_RATIO(df, HistLength, Multiplier):\n",
    "\n",
    "    current_pvr = PRICE_VARIANCE_RATIO(df, HistLength, Multiplier)\n",
    "    lag_value = HistLength * Multiplier\n",
    "    lag_pvr = PRICE_VARIANCE_RATIO(df=df.shift(lag_value), HistLength=HistLength, Multiplier=Multiplier)\n",
    "    df_stat = current_pvr - lag_pvr\n",
    "    df_stat.columns = ['DPVR']\n",
    "    return df_stat\n",
    "\n",
    "def DELTA_CHANGE_VARIANCE_RATIO(df, HistLength, Multiplier):\n",
    "\n",
    "    current_pvr = CHANGE_VARIANCE_RATIO(df, HistLength, Multiplier)\n",
    "    lag_value = HistLength * Multiplier\n",
    "    lag_pvr = CHANGE_VARIANCE_RATIO(df=df.shift(lag_value), HistLength=HistLength, Multiplier=Multiplier)\n",
    "    df_stat = current_pvr - lag_pvr\n",
    "    df_stat.columns = ['DCVR']\n",
    "    return df_stat\n",
    "\n",
    "def DELTA_ATR_RATIO(df, HistLength, Multiplier):\n",
    "\n",
    "    current_pvr = ATR_RATIO(df, HistLength, Multiplier)\n",
    "    lag_value = HistLength * Multiplier\n",
    "    lag_pvr = ATR_RATIO(df=df.shift(lag_value), HistLength=HistLength, Multiplier=Multiplier)\n",
    "    df_stat = current_pvr - lag_pvr\n",
    "    df_stat.columns = ['Delta_ATR_Ration']\n",
    "    return df_stat\n",
    "\n",
    "def BOLLINGER_WIDTH(df, HistLength):\n",
    "\n",
    "    mean = df['close'].rolling(window=HistLength).mean()\n",
    "    std = df['close'].rolling(window=HistLength).std()\n",
    "    df_stat = np.log(std / mean)\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Bollinger_Width']\n",
    "    return df_stat\n",
    "\n",
    "def DELTA_BOLLINGER_WIDTH(df, HistLength, DeltaLength):\n",
    "\n",
    "    current_bw = BOLLINGER_WIDTH(df, HistLength)\n",
    "    lag_bw = BOLLINGER_WIDTH(df=df.shift(DeltaLength), HistLength=HistLength)\n",
    "    df_stat = current_bw - lag_bw\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:]['Bollinger_Width'].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:]['Bollinger_Width'].values)\n",
    "    df_stat = pd.Series(df_stat.values.reshape(-1, ), index=df_stat.index)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Delta_Bollinger_Width']\n",
    "    return df_stat\n",
    "\n",
    "@njit\n",
    "def get_n_day_narrower(x, y):\n",
    "\n",
    "    N = len(x) + 1\n",
    "\n",
    "    for i in prange(len(x)-1, -1, -1):\n",
    "        if x[i] < y:\n",
    "            N = i + 1\n",
    "            break\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    return 100 * (N-1) / len(x) - 50\n",
    "\n",
    "def N_DAY_NARROWER(df, HistLength):\n",
    "\n",
    "    diff1 = df['high'] - df['low']\n",
    "    diff2 = df['high'] - df['close'].shift(1)\n",
    "    diff3 = df['close'].shift(1) - df['low']\n",
    "\n",
    "    true_range = np.max(\n",
    "        np.array(\n",
    "            [\n",
    "                diff1.values, \n",
    "                diff2.values, \n",
    "                diff3.values\n",
    "             ]\n",
    "        ), \n",
    "    axis=0\n",
    "    )\n",
    "\n",
    "    true_range = pd.Series(true_range, index=df.index)\n",
    "\n",
    "    # list_of_values = []\n",
    "    # true_range.rolling(window=HistLength, closed='left').apply(\n",
    "    #     lambda x: list_of_values.append(x.values) or 0, \n",
    "    #     raw=False\n",
    "    # )\n",
    "    list_of_values = get_hist_values(x=true_range.values, length=HistLength)\n",
    "\n",
    "    temp_df = pd.Series(list_of_values, index=df.iloc[HistLength-1:].index)\n",
    "    temp_df = temp_df.to_frame()\n",
    "    temp_df.columns = ['tr_list']\n",
    "    temp_df['tr'] = true_range.iloc[HistLength+1:]\n",
    "\n",
    "    df_stat = temp_df.apply(lambda x: get_n_day_narrower(x=x['tr_list'], y=x['tr']), axis=1)\n",
    "    df_stat = df_stat.to_frame()\n",
    "    df_stat.columns = ['N_Day_Narrower']\n",
    "    return df_stat\n",
    "\n",
    "@njit\n",
    "def get_n_day_wider(x, y):\n",
    "\n",
    "    N = len(x) + 1\n",
    "\n",
    "    for i in prange(len(x)-1, -1, -1):\n",
    "        if x[i] > y:\n",
    "            N = i + 1\n",
    "            break\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    return 100 * (N-1) / len(x) - 50\n",
    "\n",
    "def N_DAY_WIDER(df, HistLength):\n",
    "\n",
    "    diff1 = df['high'] - df['low']\n",
    "    diff2 = df['high'] - df['close'].shift(1)\n",
    "    diff3 = df['close'].shift(1) - df['low']\n",
    "\n",
    "    true_range = np.max(\n",
    "        np.array(\n",
    "            [\n",
    "                diff1.values, \n",
    "                diff2.values, \n",
    "                diff3.values\n",
    "             ]\n",
    "        ), \n",
    "    axis=0\n",
    "    )\n",
    "\n",
    "    true_range = pd.Series(true_range, index=df.index)\n",
    "\n",
    "    # list_of_values = []\n",
    "    # true_range.rolling(window=HistLength, closed='left').apply(\n",
    "    #     lambda x: list_of_values.append(x.values) or 0, \n",
    "    #     raw=False\n",
    "    # )\n",
    "    list_of_values = get_hist_values(x=true_range.values, length=HistLength)\n",
    "\n",
    "    temp_df = pd.Series(list_of_values, index=df.iloc[HistLength-1:].index)\n",
    "    temp_df = temp_df.to_frame()\n",
    "    temp_df.columns = ['tr_list']\n",
    "    temp_df['tr'] = true_range.iloc[HistLength+1:]\n",
    "\n",
    "    df_stat = temp_df.apply(lambda x: get_n_day_wider(x=x['tr_list'], y=x['tr']), axis=1)\n",
    "    df_stat = df_stat.to_frame()\n",
    "    df_stat.columns = ['N_Day_Wider']\n",
    "    return df_stat\n",
    "\n",
    "# Creating functions for basic price distribution statistics\n",
    "\n",
    "def PRICE_SKEWNESS(df, HistLength, Multiplier):\n",
    "\n",
    "    short_skew = df['close'].rolling(window=HistLength).skew()\n",
    "\n",
    "    if Multiplier > 1:\n",
    "        long_skew = df['close'].rolling(window=HistLength*Multiplier).skew()\n",
    "        df_stat = short_skew / long_skew\n",
    "    else:\n",
    "        df_stat = short_skew\n",
    "\n",
    "    df_stat = df_stat.to_frame()\n",
    "    df_stat.columns = ['Price_Skewness']\n",
    "    return df_stat\n",
    "\n",
    "def CHANGE_SKEWNESS(df, HistLength, Multiplier):\n",
    "\n",
    "    price_change = df['close'] / df['close'].shift(1)\n",
    "\n",
    "    short_skew = price_change.rolling(window=HistLength).skew()\n",
    "\n",
    "    if Multiplier > 1:\n",
    "        long_skew = price_change.rolling(window=HistLength*Multiplier).skew()\n",
    "        df_stat = short_skew / long_skew\n",
    "    else:\n",
    "        df_stat = short_skew\n",
    "\n",
    "    df_stat = df_stat.to_frame()\n",
    "    df_stat.columns = ['Change_Skewness']\n",
    "    return df_stat\n",
    "\n",
    "def PRICE_KURTOSIS(df, HistLength, Multiplier):\n",
    "\n",
    "    short_kurtosis = df['close'].rolling(window=HistLength).kurt()\n",
    "\n",
    "    if Multiplier > 1:\n",
    "        long_kurtosis = df['close'].rolling(window=HistLength*Multiplier).kurt()\n",
    "        df_stat = short_kurtosis / long_kurtosis\n",
    "    else:\n",
    "        df_stat = short_kurtosis\n",
    "\n",
    "    df_stat = df_stat.to_frame()\n",
    "    df_stat.columns = ['Price_Kurtosis']\n",
    "    return df_stat\n",
    "\n",
    "def CHANGE_KURTOSIS(df, HistLength, Multiplier):\n",
    "\n",
    "    price_change = df['close'] / df['close'].shift(1)\n",
    "\n",
    "    short_kurtosis = price_change.rolling(window=HistLength).kurt()\n",
    "\n",
    "    if Multiplier > 1:\n",
    "        long_kurtosis = price_change.rolling(window=HistLength*Multiplier).kurt()\n",
    "        df_stat = short_kurtosis / long_kurtosis\n",
    "    else:\n",
    "        df_stat = short_kurtosis\n",
    "\n",
    "    df_stat = df_stat.to_frame()\n",
    "    df_stat.columns = ['Change_Kurtosis']\n",
    "    return df_stat\n",
    "\n",
    "def DELTA_PRICE_SKEWNESS(df, HistLen, Multiplier, DeltaLen):\n",
    "\n",
    "    current_ps = PRICE_SKEWNESS(df, HistLen, Multiplier)\n",
    "    lag_ps = PRICE_SKEWNESS(df=df.shift(DeltaLen), HistLength=HistLen, Multiplier=Multiplier)\n",
    "    df_stat = current_ps - lag_ps\n",
    "    df_stat.columns = ['Delta_Price_Skewness']\n",
    "    return df_stat\n",
    "\n",
    "def DELTA_CHANGE_SKEWNESS(df, HistLen, Multiplier, DeltaLen):\n",
    "\n",
    "    current_cs = CHANGE_SKEWNESS(df, HistLen, Multiplier)\n",
    "    lag_cs = CHANGE_SKEWNESS(df=df.shift(DeltaLen), HistLength=HistLen, Multiplier=Multiplier)\n",
    "    df_stat = current_cs - lag_cs\n",
    "    df_stat.columns = ['Delta_Change_Skewness']\n",
    "    return df_stat\n",
    "\n",
    "def DELTA_PRICE_KURTOSIS(df, HistLen, Multiplier, DeltaLen):\n",
    "\n",
    "    current_pk = PRICE_KURTOSIS(df, HistLen, Multiplier)\n",
    "    lag_pk = PRICE_KURTOSIS(df=df.shift(DeltaLen), HistLength=HistLen, Multiplier=Multiplier)\n",
    "    df_stat = current_pk - lag_pk\n",
    "    df_stat.columns = ['Delta_Price_Kurtosis']\n",
    "    return df_stat\n",
    "\n",
    "def DELTA_CHANGE_KURTOSIS(df, HistLen, Multiplier, DeltaLen):\n",
    "\n",
    "    current_ck = CHANGE_KURTOSIS(df, HistLen, Multiplier)\n",
    "    lag_ck = CHANGE_KURTOSIS(df=df.shift(DeltaLen), HistLength=HistLen, Multiplier=Multiplier)\n",
    "    df_stat = current_ck - lag_ck\n",
    "    df_stat.columns = ['Delta_Change_Kurtosis']\n",
    "    return df_stat\n",
    "\n",
    "# Creating functions for indicators/variables that significantly involve volume\n",
    "\n",
    "def VOLUME_MOMENTUM(df, HistLength, Multiplier):\n",
    "\n",
    "    short_ma = df['volume'].rolling(window=HistLength).mean()\n",
    "    long_ma = df['volume'].rolling(window=HistLength*Multiplier).mean()\n",
    "    df_stat = short_ma / long_ma\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Volume_Momentum']\n",
    "    return df_stat\n",
    "\n",
    "def DELTA_VOLUME_MOMENTUM(df, HistLen, Multiplier, DeltaLen):\n",
    "\n",
    "    current_vm = CHANGE_KURTOSIS(df, HistLen, Multiplier)\n",
    "    lag_vm = CHANGE_KURTOSIS(df=df.shift(DeltaLen), HistLength=HistLen, Multiplier=Multiplier)\n",
    "    df_stat = current_vm - lag_vm\n",
    "    period = HistLen\n",
    "    x_median = df_stat.iloc[-period:]['Change_Kurtosis'].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:]['Change_Kurtosis'].values)\n",
    "    df_stat = pd.Series(df_stat.values.reshape(-1, ), index=df_stat.index)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Delta_Volume_Momentum']\n",
    "    return df_stat\n",
    "\n",
    "def VOLUME_WEIGHTED_MA_OVER_MA(df, HistLength):\n",
    "\n",
    "    volume_sum = df['volume'].rolling(window=HistLength).sum()\n",
    "    vp = df['close'] * df['volume']\n",
    "    vp_sum = vp.rolling(window=HistLength).sum()\n",
    "    ma_vw = vp_sum / volume_sum\n",
    "\n",
    "    simple_ma = df['close'].rolling(window=HistLength).mean()\n",
    "\n",
    "    df_stat = np.log(ma_vw / simple_ma)\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['VWMOM']\n",
    "    return df_stat\n",
    "\n",
    "def DIFF_VOLUME_WEIGHTED_MA_OVER_MA(df, ShortDist, LongDist):\n",
    "\n",
    "    short_vwmom = VOLUME_WEIGHTED_MA_OVER_MA(df, HistLength=ShortDist)\n",
    "    long_vwmom = VOLUME_WEIGHTED_MA_OVER_MA(df, HistLength=LongDist)\n",
    "    df_stat = short_vwmom - long_vwmom\n",
    "    period = ShortDist\n",
    "    x_median = df_stat.iloc[-period:]['VWMOM'].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:]['VWMOM'].values)\n",
    "    df_stat = pd.Series(df_stat.values.reshape(-1, ), index=df_stat.index)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Diff_VWMOM']\n",
    "    return df_stat\n",
    "\n",
    "def get_ls_slope2(x, y):\n",
    "    result = np.polyfit(x, y, 1)\n",
    "    return result[0]\n",
    "\n",
    "@njit\n",
    "def get_hist_values(x, length):\n",
    "\n",
    "    hist_values = []\n",
    "\n",
    "    for i in prange(length, len(x)+1):\n",
    "\n",
    "        hist_values.append(x[i-length: i])\n",
    "\n",
    "    return hist_values\n",
    "\n",
    "def PRICE_VOLUME_FIT(df, HistLength):\n",
    "\n",
    "    log_price = np.log(df['close'])\n",
    "\n",
    "    log_volume = np.log(df['volume']).replace(-np.inf, 0)\n",
    "\n",
    "    log_array = np.vstack([log_price.values, log_volume.values]).T\n",
    "    log_df = pd.DataFrame(log_array, columns=['log_price', 'log_volume'], index=log_price.index)\n",
    "    log_df.dropna(inplace=True)\n",
    "\n",
    "    list_of_log_price = get_hist_values(x=log_df['log_price'].values, length=HistLength)\n",
    "\n",
    "    list_of_log_volume = get_hist_values(x=log_df['log_volume'].values, length=HistLength)\n",
    "\n",
    "    index_length = len(list_of_log_volume)\n",
    "    temp_df = pd.Series(list_of_log_volume, index=df.iloc[-index_length:].index)\n",
    "    temp_df = temp_df.to_frame()\n",
    "    temp_df.columns = ['log_volume']\n",
    "    temp_df['log_price'] = list_of_log_price\n",
    "\n",
    "    temp_df['slope'] = temp_df.apply(lambda x: get_ls_slope2(x=x['log_volume'], y=x['log_price']), axis=1)\n",
    "\n",
    "    df_stat = temp_df['slope']\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Price_Volume_Fit']\n",
    "    return df_stat\n",
    "\n",
    "def DIFF_PRICE_VOLUME_FIT(df, ShortDist, LongDist):\n",
    "\n",
    "    short_pvf = PRICE_VOLUME_FIT(df, HistLength=ShortDist)\n",
    "    long_pvf = PRICE_VOLUME_FIT(df, HistLength=LongDist)\n",
    "    df_stat = short_pvf - long_pvf\n",
    "    period = ShortDist\n",
    "    x_median = df_stat.iloc[-period:]['Price_Volume_Fit'].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:]['Price_Volume_Fit'].values)\n",
    "    df_stat = pd.Series(df_stat.values.reshape(-1, ), index=df_stat.index)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Diff_PVF']\n",
    "    return df_stat\n",
    "\n",
    "def DELTA_PRICE_VOLUME_FIT(df, HistLength, DeltaDist):\n",
    "\n",
    "    current_pvf = PRICE_VOLUME_FIT(df, HistLength)\n",
    "    lag_pvf = PRICE_VOLUME_FIT(df=df.shift(DeltaDist), HistLength=HistLength)\n",
    "    df_stat = current_pvf - lag_pvf\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:]['Price_Volume_Fit'].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:]['Price_Volume_Fit'].values)\n",
    "    df_stat = pd.Series(df_stat.values.reshape(-1, ), index=df_stat.index)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Delta_PVF']\n",
    "    return df_stat\n",
    "\n",
    "def ON_BALANCE_VOLUME(df, HistLength):\n",
    "\n",
    "    bool1 = (df['close'] > df['close'].shift(1)).astype(int)\n",
    "    volume1 = df['volume'] * bool1\n",
    "    signed_volume1 = volume1.rolling(window=HistLength).sum()\n",
    "\n",
    "    bool2 = (df['close'] < df['close'].shift(1)).astype(int)\n",
    "    volume2 = df['volume'] * bool2\n",
    "    signed_volume2 = volume2.rolling(window=HistLength).sum()\n",
    "\n",
    "    signed_volume = signed_volume1 - signed_volume2\n",
    "\n",
    "    total_volume = df['volume'].rolling(window=HistLength).sum()\n",
    "\n",
    "    df_stat = signed_volume / total_volume\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = pd.Series(df_stat.values.reshape(-1, ), index=df_stat.index)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['On_Balance_Volume']\n",
    "    return df_stat\n",
    "\n",
    "def DELTA_ON_BALANCE_VOLUME(df, HistLength, DeltaDist):\n",
    "\n",
    "    current_obv = ON_BALANCE_VOLUME(df, HistLength)\n",
    "    lag_obv = ON_BALANCE_VOLUME(df=df.shift(DeltaDist), HistLength=HistLength)\n",
    "    df_stat = current_obv - lag_obv\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:]['On_Balance_Volume'].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:]['On_Balance_Volume'].values)\n",
    "    df_stat = pd.Series(df_stat.values.reshape(-1, ), index=df_stat.index)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Delta_OBV']\n",
    "    return df_stat\n",
    "\n",
    "def POSITIVE_VOLUME_INDICATOR(df, HistLength):\n",
    "\n",
    "    price_change = (df['close'] - df['close'].shift(1)) / df['close'].shift(1)\n",
    "    is_increased = (df['volume'] > df['volume'].shift(1))\n",
    "    price_change = price_change * is_increased\n",
    "    df_stat = price_change.rolling(window=HistLength).mean()\n",
    "\n",
    "    std_length = np.max([2*HistLength, 250])\n",
    "    std_price_change = price_change.rolling(window=std_length).std()\n",
    "    df_stat = df_stat / std_price_change\n",
    "\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Positive_Volume']\n",
    "    return df_stat\n",
    "\n",
    "def DELTA_POSITIVE_VOLUME_INDICATOR(df, HistLength, DeltaDist):\n",
    "\n",
    "    current_pv = POSITIVE_VOLUME_INDICATOR(df, HistLength)\n",
    "    lag_pv = POSITIVE_VOLUME_INDICATOR(df=df.shift(DeltaDist), HistLength=HistLength)\n",
    "    df_stat = current_pv - lag_pv\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:]['Positive_Volume'].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:]['Positive_Volume'].values)\n",
    "    df_stat = pd.Series(df_stat.values.reshape(-1, ), index=df_stat.index)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Delta_Positive_Volume']\n",
    "    return df_stat\n",
    "\n",
    "def NEGATIVE_VOLUME_INDICATOR(df, HistLength):\n",
    "\n",
    "    price_change = (df['close'] - df['close'].shift(1)) / df['close'].shift(1)\n",
    "    is_decreased = (df['volume'] < df['volume'].shift(1))\n",
    "    price_change = price_change * is_decreased\n",
    "    df_stat = price_change.rolling(window=HistLength).mean()\n",
    "\n",
    "    std_length = np.max([2*HistLength, 250])\n",
    "    std_price_change = price_change.rolling(window=std_length).std()\n",
    "    df_stat = df_stat / std_price_change\n",
    "\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Negative_Volume']\n",
    "    return df_stat\n",
    "\n",
    "def DELTA_NEGATIVE_VOLUME_INDICATOR(df, HistLength, DeltaDist):\n",
    "\n",
    "    current_pv = NEGATIVE_VOLUME_INDICATOR(df, HistLength)\n",
    "    lag_pv = NEGATIVE_VOLUME_INDICATOR(df=df.shift(DeltaDist), HistLength=HistLength)\n",
    "    df_stat = current_pv - lag_pv\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:]['Negative_Volume'].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:]['Negative_Volume'].values)\n",
    "    df_stat = pd.Series(df_stat.values.reshape(-1, ), index=df_stat.index)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Delta_Negative_Volume']\n",
    "    return df_stat\n",
    "\n",
    "def PRODUCT_PRICE_VOLUME(df, HistLength):\n",
    "\n",
    "    median_volume = df['volume'].rolling(window=250).median()\n",
    "    normalized_volume = df['volume'] / median_volume\n",
    "\n",
    "    price_changes = np.log(df['close']/df['close'].shift(1))\n",
    "    median_price_changes = price_changes.rolling(window=250).median()\n",
    "    quantile25 = price_changes.rolling(window=250).quantile(0.25)\n",
    "    quantile75 = price_changes.rolling(window=250).quantile(0.75)\n",
    "    iqr_price_changes = quantile75 - quantile25\n",
    "    normalized_price_changes = (price_changes - median_price_changes) / iqr_price_changes\n",
    "\n",
    "    precursor = normalized_volume * normalized_price_changes\n",
    "\n",
    "    df_stat = precursor.rolling(window=HistLength).mean()\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Product_Price_Volume']\n",
    "    return df_stat\n",
    "\n",
    "def SUM_PRICE_VOLUME(df, HistLength):\n",
    "\n",
    "    median_volume = df['volume'].rolling(window=250).median()\n",
    "    normalized_volume = df['volume'] / median_volume\n",
    "\n",
    "    price_changes = np.log(df['close']/df['close'].shift(1))\n",
    "    median_price_changes = price_changes.rolling(window=250).median()\n",
    "    quantile25 = price_changes.rolling(window=250).quantile(0.25)\n",
    "    quantile75 = price_changes.rolling(window=250).quantile(0.75)\n",
    "    iqr_price_changes = quantile75 - quantile25\n",
    "    normalized_price_changes = (price_changes - median_price_changes) / iqr_price_changes\n",
    "\n",
    "    sum_sign = np.array(list(map(lambda x: -1 if x<0 else 1, normalized_price_changes)))\n",
    "    precursor = (normalized_volume + np.abs(normalized_price_changes)) * sum_sign\n",
    "\n",
    "    df_stat = precursor.rolling(window=HistLength).mean()\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Sum_Price_Volume']\n",
    "    return df_stat\n",
    "\n",
    "def DELTA_PRODUCT_PRICE_VOLUME(df, HistLen, DeltaDist):\n",
    "\n",
    "    current_ppv = PRODUCT_PRICE_VOLUME(df, HistLen)\n",
    "    lag_ppv = PRODUCT_PRICE_VOLUME(df=df.shift(DeltaDist), HistLength=HistLen)\n",
    "    df_stat = current_ppv - lag_ppv\n",
    "    period = HistLen\n",
    "    x_median = df_stat.iloc[-period:]['Product_Price_Volume'].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:]['Product_Price_Volume'].values)\n",
    "    df_stat = pd.Series(df_stat.values.reshape(-1, ), index=df_stat.index)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Delta_PPV']\n",
    "    return df_stat\n",
    "\n",
    "def DELTA_SUM_PRICE_VOLUME(df, HistLen, DeltaDist):\n",
    "\n",
    "    current_ppv = SUM_PRICE_VOLUME(df, HistLen)\n",
    "    lag_ppv = SUM_PRICE_VOLUME(df=df.shift(DeltaDist), HistLength=HistLen)\n",
    "    df_stat = current_ppv - lag_ppv\n",
    "    period = HistLen\n",
    "    x_median = df_stat.iloc[-period:]['Sum_Price_Volume'].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:]['Sum_Price_Volume'].values)\n",
    "    df_stat = pd.Series(df_stat.values.reshape(-1, ), index=df_stat.index)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Delta_SPV']\n",
    "    return df_stat\n",
    "\n",
    "# Creating functions for entropy and mutual information indicators/variables\n",
    "\n",
    "@njit\n",
    "def get_entropy(x):\n",
    "\n",
    "    entropy = 0\n",
    "\n",
    "    for i in prange(len(x)):\n",
    "        p = x[i] / np.sum(x)\n",
    "        entropy += -p * np.log2(p)\n",
    "\n",
    "    return entropy\n",
    "\n",
    "def PRICE_ENTROPY(df, WordLength):\n",
    "\n",
    "    length = 10 * (2 ** WordLength)\n",
    "\n",
    "    bool_list = []\n",
    "\n",
    "    for i in range(length):\n",
    "        price_bool1 = ((df['close'].shift(i) > df['close'].shift(i+1)).astype(int)).astype(str)\n",
    "        price_bool2 = ((df['close'].shift(i+1) > df['close'].shift(i+2)).astype(int)).astype(str)\n",
    "        price_bool = price_bool1 + price_bool2\n",
    "\n",
    "        bool_list.append(price_bool.values)\n",
    "\n",
    "        del price_bool1, price_bool2, price_bool\n",
    "        gc.collect()\n",
    "\n",
    "    bool_list = np.array(bool_list).T.tolist()\n",
    "\n",
    "    temp_df = pd.Series(bool_list, index=df.index).apply(lambda x: np.unique(x, return_counts=True)[1])\n",
    "    df_stat = temp_df.apply(get_entropy)\n",
    "    period = length\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Price_Entropy']\n",
    "    return df_stat\n",
    "\n",
    "def VOLUME_ENTROPY(df, WordLength):\n",
    "\n",
    "    length = 10 * (2 ** WordLength)\n",
    "\n",
    "    bool_list = []\n",
    "\n",
    "    for i in range(length):\n",
    "        volume_bool1 = ((df['volume'].shift(i) > df['volume'].shift(i+1)).astype(int)).astype(str)\n",
    "        volume_bool2 = ((df['volume'].shift(i+1) > df['volume'].shift(i+2)).astype(int)).astype(str)\n",
    "        volume_bool = volume_bool1 + volume_bool2\n",
    "\n",
    "        bool_list.append(volume_bool.values)\n",
    "\n",
    "        del volume_bool1, volume_bool2, volume_bool\n",
    "        gc.collect()  \n",
    "\n",
    "    bool_list = np.array(bool_list).T.tolist()\n",
    "\n",
    "    temp_df = pd.Series(bool_list, index=df.index).apply(lambda x: np.unique(x, return_counts=True)[1])\n",
    "    df_stat = temp_df.apply(get_entropy)\n",
    "    period = length\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Volume_Entropy']\n",
    "    return df_stat\n",
    "\n",
    "@njit\n",
    "def get_mi_data(x, length):\n",
    "    \n",
    "    xc = []\n",
    "    x1 = []\n",
    "    x2 = []\n",
    "    x3 = []\n",
    "\n",
    "    for i in prange(length, len(x)):\n",
    "\n",
    "        xc.append(x[i-length:i])\n",
    "        x1.append(x[i-length:i-1])\n",
    "        x2.append(x[i-length:i-2])\n",
    "        x3.append(x[i-length:i-3])\n",
    "\n",
    "    return xc, x1, x2, x3\n",
    "\n",
    "@njit\n",
    "def get_mi(c, x, y, z):\n",
    "\n",
    "    bool1 = np.where(c[1:] > x, 1, 0)\n",
    "    bool2 = np.where(x[1:] > y, 1, 0)\n",
    "    bool3 = np.where(y[1:] > z, 1, 0)\n",
    "\n",
    "    var23 = np.zeros(len(bool3), dtype='int')\n",
    "    var123 = np.zeros(len(bool3), dtype='int')\n",
    "\n",
    "    for i in prange(len(bool3)):\n",
    "\n",
    "        if bool2[i+1] == 0 and bool3[i] == 0:\n",
    "\n",
    "            var23[i] = 1\n",
    "\n",
    "            if bool1[i+3] == 0:\n",
    "                var123[i] = 1\n",
    "            else:\n",
    "                var123[i] = 2\n",
    "\n",
    "        elif bool2[i+1] == 1 and bool3[i] == 0:\n",
    "\n",
    "            var23[i] = 2\n",
    "\n",
    "            if bool1[i+3] == 0:\n",
    "                var123[i] = 3\n",
    "            else:\n",
    "                var123[i] = 4\n",
    "\n",
    "        elif bool2[i+1] == 0 and bool3[i] == 1:\n",
    "\n",
    "            var23[i] = 3\n",
    "\n",
    "            if bool1[i+3] == 0:\n",
    "                var123[i] = 5\n",
    "            else:\n",
    "                var123[i] = 6\n",
    "\n",
    "        else:\n",
    "\n",
    "            var23[i] = 4\n",
    "\n",
    "            if bool1[i+3] == 0:\n",
    "                var123[i] = 7\n",
    "            else:\n",
    "                var123[i] = 8\n",
    "    \n",
    "    prob1 = np.zeros(2)\n",
    "    for i in prange(2):\n",
    "        prob1[i] = np.sum(np.where(bool1==i, 1, 0))/ len(bool1)\n",
    "\n",
    "    prob23 = np.zeros(4)\n",
    "    for i in prange(1, 5):\n",
    "        prob23[i] = np.sum(np.where(var23==i, 1, 0))/ len(var23)\n",
    "\n",
    "    prob123 = np.zeros(8)\n",
    "    for i in prange(1, 9):\n",
    "        prob123[i] = np.sum(np.where(var123==i, 1, 0))/ len(var123)\n",
    "\n",
    "\n",
    "    mi = 0\n",
    "\n",
    "    for i in prange(2):\n",
    "        for j in prange(2):\n",
    "            for k in prange(2):\n",
    "                \n",
    "                if j == 0 and k == 0:\n",
    "\n",
    "                    py = prob23[0]\n",
    "\n",
    "                    if i == 0:\n",
    "                        pxy = prob123[0]\n",
    "                        px = prob1[0]\n",
    "                    else:\n",
    "                        pxy = prob123[1]\n",
    "                        px = prob1[1]\n",
    "\n",
    "                elif j == 1 and k == 0:\n",
    "\n",
    "                    py = prob23[1]\n",
    "\n",
    "                    if i == 0:\n",
    "                        pxy = prob123[2]\n",
    "                        px = prob1[0]\n",
    "                    else:\n",
    "                        pxy = prob123[3]\n",
    "                        px = prob1[1]\n",
    "\n",
    "                elif j == 0 and k == 1:\n",
    "\n",
    "                    py = prob23[2]\n",
    "\n",
    "                    if i == 0:\n",
    "                        pxy = prob123[4]\n",
    "                        px = prob1[0]\n",
    "                    else:\n",
    "                        pxy = prob123[5]\n",
    "                        px = prob1[1]\n",
    "\n",
    "                else:\n",
    "\n",
    "                    py = prob23[3]\n",
    "\n",
    "                    if i == 0:\n",
    "                        pxy = prob123[6]\n",
    "                        px = prob1[0]\n",
    "                    else:\n",
    "                        pxy = prob123[7]\n",
    "                        px = prob1[1]\n",
    "\n",
    "                if px * py == 0:\n",
    "                    mi += 0\n",
    "                else:\n",
    "                    mi += pxy * np.log(pxy/(px*py))\n",
    "\n",
    "    return mi\n",
    "\n",
    "def PRICE_MUTUAL_INFORMATION(df, WordLength):\n",
    "\n",
    "    length = 10 * (2 ** (1 + WordLength))\n",
    "\n",
    "    xc, x1, x2, x3 = get_mi_data(x=df['close'].values, length=length)\n",
    "    temp_df = pd.Series(xc, index=df.index[length:])\n",
    "    temp_df = temp_df.to_frame()\n",
    "    temp_df.columns = ['price']\n",
    "    temp_df['price_lag1'] = x1\n",
    "    temp_df['price_lag2'] = x2\n",
    "    temp_df['price_lag3'] = x3\n",
    "    df_stat = temp_df.apply(\n",
    "        lambda x: get_mi(\n",
    "            c=x['price'], \n",
    "            x=x['price_lag1'], \n",
    "            y=x['price_lag2'], \n",
    "            z=x['price_lag3']\n",
    "        ), \n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    period = length\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Price_MI']\n",
    "    return df_stat\n",
    "\n",
    "def VOLUME_MUTUAL_INFORMATION(df, WordLength):\n",
    "\n",
    "    length = 10 * (2 ** (1 + WordLength))\n",
    "\n",
    "    xc, x1, x2, x3 = get_mi_data(x=df['volume'].values, length=length)\n",
    "    temp_df = pd.Series(xc, index=df.index[length:])\n",
    "    temp_df = temp_df.to_frame()\n",
    "    temp_df.columns = ['volume']\n",
    "    temp_df['volume_lag1'] = x1\n",
    "    temp_df['volume_lag2'] = x2\n",
    "    temp_df['volume_lag3'] = x3\n",
    "    df_stat = temp_df.apply(\n",
    "        lambda x: get_mi(\n",
    "            c=x['volume'], \n",
    "            x=x['volume_lag1'], \n",
    "            y=x['volume_lag2'], \n",
    "            z=x['volume_lag3']\n",
    "        ), \n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    period = length\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Volume_MI']\n",
    "    return df_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot set a DataFrame with multiple columns to the single column sell",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_38852\\749834881.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     68\u001b[0m   \u001b[0mdrawdowns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_drawdowns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mequity_curve_arr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m   \u001b[0mavg_drawdown\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrawdowns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdrawdowns\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrawdowns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdrawdowns\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m   \u001b[0mfitness\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtotal_pnl\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mavg_drawdown\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mfitness\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m \u001b[0mfitness\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_38852\\749834881.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(price_data)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mmax\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdrawdowns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m   \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprice_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m   \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'buy'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m7\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'open'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m   \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sell'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'high'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mMA_DIFFERENCE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mShortLength\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLongLength\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLag\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m   \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'hold'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'low'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'low'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m   \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'signal'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'buy'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sell'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'hold'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m   \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'signal'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'signal'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\vchar\\anaconda3\\envs\\grammar_evol\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4077\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4078\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4079\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4080\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4081\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item_frame_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4082\u001b[0m         elif (\n\u001b[0;32m   4083\u001b[0m             \u001b[0mis_list_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4084\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\vchar\\anaconda3\\envs\\grammar_evol\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4236\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misetitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4238\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4239\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m   4240\u001b[0m                 \u001b[1;34m\"Cannot set a DataFrame with multiple columns to the single \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4241\u001b[0m                 \u001b[1;34mf\"column {key}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4242\u001b[0m             )\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot set a DataFrame with multiple columns to the single column sell"
     ]
    }
   ],
   "source": [
    "def fun(price_data):\n",
    "  from numba import njit\n",
    "  @njit\n",
    "  def merge_pnl(arr1, arr2):\n",
    "    out = np.zeros((len(arr1) + len(arr2)))\n",
    "    idx = 1\n",
    "    for i in range(len(arr1) + len(arr2)):\n",
    "      if i % 2 == 0:\n",
    "        out[i] = arr1[int(i/2)]\n",
    "      else:\n",
    "        out[i] = arr2[i-idx]\n",
    "        idx += 1\n",
    "    return out\n",
    "  @njit\n",
    "  def get_drawdowns(arr):\n",
    "    drawdowns = np.zeros((len(arr)))\n",
    "    max = arr[0]\n",
    "    for i in range(1, len(drawdowns)-1):\n",
    "      if arr[i-1] > arr[i] and arr[i] < arr[i+1]:\n",
    "        min = arr[i]\n",
    "        drawdowns[i] = max - min\n",
    "      elif arr[i-1] < arr[i] and arr[i] > arr[i+1]:\n",
    "        max = arr[i]\n",
    "    return drawdowns\n",
    "  df = price_data.copy()\n",
    "  df['buy'] = (7 == df['open']).astype(int)\n",
    "  df['sell'] = (df['high'].to_frame() // MA_DIFFERENCE(df=data, ShortLength=8, LongLength=5, Lag=7) > 0.6).astype(int)\n",
    "  df['hold'] = (df['low'] == df['low']).astype(int)\n",
    "  df['signal'] = df['buy'] + df['sell'] + df['hold']\n",
    "  df['signal'] = df['signal'].apply(lambda x: 1 if x==1 else 0)\n",
    "  df['hold'] = df['hold'].apply(lambda x: 1 if x==0 else 0)\n",
    "  df['signal'] = df['signal'] * df['hold']\n",
    "  df['sell'] = df['sell'] * (-1)\n",
    "  df['signal'] = df['signal'] * df['sell']\n",
    "  df['signal'] = df['signal'] * df['buy']\n",
    "  df.drop(columns=['buy', 'sell', 'hold'], inplace=True)\n",
    "  buy_idxs = []\n",
    "  sell_idxs = []\n",
    "  is_buy = 0\n",
    "  is_sell = 0\n",
    "  for i, row in enumerate(df.itertuples()):\n",
    "    if row.signal == 1 and is_buy == 0:\n",
    "      buy_idxs.append(i+1)\n",
    "      is_buy = 1\n",
    "      is_sell = 0\n",
    "    elif row.signal == -1 and is_sell == 0:\n",
    "      sell_idxs.append(i+1)\n",
    "      is_sell = 1\n",
    "      is_buy = 0\n",
    "  buy_prices = df[df.index.isin(buy_idxs)][open].values\n",
    "  sell_prices = df[df.index.isin(sell_idxs)][open].values\n",
    "  if buy_idxs[0] < sell_idxs[0]:\n",
    "    buy_pnl = np.sum(sell_prices - buy_prices)\n",
    "    sell_pnl = np.sum(sell_prices[:-1] - buy_prices[1:])\n",
    "  else:\n",
    "    sell_pnl = np.sum(sell_prices - buy_prices)\n",
    "    buy_pnl = np.sum(sell_prices[1:] - buy_prices[:-1])\n",
    "  total_pnl = buy_pnl + sell_pnl\n",
    "  if buy_idxs[0] < sell_idxs[0]:\n",
    "    buy_arr = sell_prices - buy_prices\n",
    "    sell_arr = sell_prices[:-1] - buy_prices[1:]\n",
    "    all_arr = merge_pnl(buy_arr, sell_arr)\n",
    "  else:\n",
    "    sell_arr = sell_prices - buy_prices\n",
    "    buy_arr = sell_prices[1:] - buy_prices[:-1]\n",
    "    all_arr = merge_pnl(sell_arr, buy_arr)\n",
    "  equity_curve_arr = np.cumsum(all_arr)\n",
    "  drawdowns = get_drawdowns(equity_curve_arr)\n",
    "  avg_drawdown = np.sum(drawdowns[drawdowns!=0]) / len(drawdowns[drawdowns!=0])\n",
    "  fitness = total_pnl / avg_drawdown\n",
    "  return fitness\n",
    "fitness = fun(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10075</th>\n",
       "      <td>3665.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10076</th>\n",
       "      <td>78531.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10077</th>\n",
       "      <td>-7054.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10078</th>\n",
       "      <td>-4350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10079</th>\n",
       "      <td>-3243.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10080 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          high\n",
       "0          NaN\n",
       "1          NaN\n",
       "2          NaN\n",
       "3          NaN\n",
       "4          NaN\n",
       "...        ...\n",
       "10075   3665.0\n",
       "10076  78531.0\n",
       "10077  -7054.0\n",
       "10078  -4350.0\n",
       "10079  -3243.0\n",
       "\n",
       "[10080 rows x 1 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['high'].to_frame() // MA_DIFFERENCE(df=data, ShortLength=8, LongLength=5, Lag=7).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MA_Diff</th>\n",
       "      <th>high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10075</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10076</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10077</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10078</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10079</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10080 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MA_Diff   high\n",
       "0        False  False\n",
       "1        False  False\n",
       "2        False  False\n",
       "3        False  False\n",
       "4        False  False\n",
       "...        ...    ...\n",
       "10075    False  False\n",
       "10076    False  False\n",
       "10077    False  False\n",
       "10078    False  False\n",
       "10079    False  False\n",
       "\n",
       "[10080 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['high'].to_frame() // MA_DIFFERENCE(df=data, ShortLength=8, LongLength=5, Lag=7) > 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Pandas' object has no attribute 'signal'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 72\u001b[0m\n\u001b[0;32m     70\u001b[0m   fitness \u001b[38;5;241m=\u001b[39m total_pnl \u001b[38;5;241m/\u001b[39m avg_drawdown\n\u001b[0;32m     71\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fitness\n\u001b[1;32m---> 72\u001b[0m fitness \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[26], line 42\u001b[0m, in \u001b[0;36mfun\u001b[1;34m(price_data)\u001b[0m\n\u001b[0;32m     40\u001b[0m is_sell \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(df\u001b[38;5;241m.\u001b[39mitertuples()):\n\u001b[1;32m---> 42\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignal\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_buy \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     43\u001b[0m     buy_idxs\u001b[38;5;241m.\u001b[39mappend(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     44\u001b[0m     is_buy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Pandas' object has no attribute 'signal'"
     ]
    }
   ],
   "source": [
    "def fun(price_data):\n",
    "  from numba import njit\n",
    "  @njit\n",
    "  def merge_pnl(arr1, arr2):\n",
    "    out = np.zeros((len(arr1) + len(arr2)))\n",
    "    idx = 1\n",
    "    for i in range(len(arr1) + len(arr2)):\n",
    "      if i % 2 == 0:\n",
    "        out[i] = arr1[int(i/2)]\n",
    "      else:\n",
    "        out[i] = arr2[i-idx]\n",
    "        idx += 1\n",
    "    return out\n",
    "  @njit\n",
    "  def get_drawdowns(arr):\n",
    "    drawdowns = np.zeros((len(arr)))\n",
    "    max = arr[0]\n",
    "    for i in range(1, len(drawdowns)-1):\n",
    "      if arr[i-1] > arr[i] and arr[i] < arr[i+1]:\n",
    "        min = arr[i]\n",
    "        drawdowns[i] = max - min\n",
    "      elif arr[i-1] < arr[i] and arr[i] > arr[i+1]:\n",
    "        max = arr[i]\n",
    "    return drawdowns\n",
    "  df = price_data.copy()\n",
    "  df.buy = (df.open % df.open < 0.1).astype(int)\n",
    "  df.sell = (0.5 == df.close).astype(int)\n",
    "  df.hold = (df.open % df.close > 1.7).astype(int)\n",
    "  df.signal = df.buy + df.sell + df.hold\n",
    "  df.signal = df.signal.apply(lambda x: 1 if x==1 else 0)\n",
    "  df.hold = df.hold.apply(lambda x: 1 if x==0 else 0)\n",
    "  df.signal = df.signal * df.hold\n",
    "  df.sell = df.sell * (-1)\n",
    "  df.signal = df.signal * df.sell\n",
    "  df.signal = df.signal * df.buy\n",
    "#   df.drop(columns=[buy, sell, hold], inplace=True)\n",
    "  buy_idxs = []\n",
    "  sell_idxs = []\n",
    "  is_buy = 0\n",
    "  is_sell = 0\n",
    "  for i, row in enumerate(df.itertuples()):\n",
    "    if row.signal == 1 and is_buy == 0:\n",
    "      buy_idxs.append(i+1)\n",
    "      is_buy = 1\n",
    "      is_sell = 0\n",
    "    elif row.signal == -1 and is_sell == 0:\n",
    "      sell_idxs.append(i+1)\n",
    "      is_sell = 1\n",
    "      is_buy = 0\n",
    "  buy_prices = df[df.index.isin(buy_idxs)].open.values\n",
    "  sell_prices = df[df.index.isin(sell_idxs)].open.values\n",
    "  if buy_idxs[0] < sell_idxs[0]:\n",
    "    buy_pnl = np.sum(sell_prices - buy_prices)\n",
    "    sell_pnl = np.sum(sell_prices[:-1] - buy_prices[1:])\n",
    "  else:\n",
    "    sell_pnl = np.sum(sell_prices - buy_prices)\n",
    "    buy_pnl = np.sum(sell_prices[1:] - buy_prices[:-1])\n",
    "  total_pnl = buy_pnl + sell_pnl\n",
    "  if buy_idxs[0] < sell_idxs[0]:\n",
    "    buy_arr = sell_prices - buy_prices\n",
    "    sell_arr = sell_prices[:-1] - buy_prices[1:]\n",
    "    all_arr = merge_pnl(buy_arr, sell_arr)\n",
    "  else:\n",
    "    sell_arr = sell_prices - buy_prices\n",
    "    buy_arr = sell_prices[1:] - buy_prices[:-1]\n",
    "    all_arr = merge_pnl(sell_arr, buy_arr)\n",
    "  equity_curve_arr = np.cumsum(all_arr)\n",
    "  drawdowns = get_drawdowns(equity_curve_arr)\n",
    "  avg_drawdown = np.sum(drawdowns[drawdowns!=0]) / len(drawdowns[drawdowns!=0])\n",
    "  fitness = total_pnl / avg_drawdown\n",
    "  return fitness\n",
    "fitness = fun(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()\n",
    "df.buy = (df.open % df.open < 0.1).astype(int)\n",
    "df.sell = (0.5 == df.close).astype(int)\n",
    "df.hold = (df.open % df.close > 1.7).astype(int)\n",
    "df.signal = df.buy + df.sell + df.hold\n",
    "df.signal = df.signal.apply(lambda x: 1 if x==1 else 0)\n",
    "df.hold = df.hold.apply(lambda x: 1 if x==0 else 0)\n",
    "df.signal = df.signal * df.hold\n",
    "df.sell = df.sell * (-1)\n",
    "df.signal = df.signal * df.sell\n",
    "df.signal = df.signal * df.buy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 72\u001b[0m\n\u001b[0;32m     70\u001b[0m   fitness \u001b[38;5;241m=\u001b[39m total_pnl \u001b[38;5;241m/\u001b[39m avg_drawdown\n\u001b[0;32m     71\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fitness\n\u001b[1;32m---> 72\u001b[0m fitness \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[36], line 52\u001b[0m, in \u001b[0;36mfun\u001b[1;34m(price_data)\u001b[0m\n\u001b[0;32m     50\u001b[0m buy_prices \u001b[38;5;241m=\u001b[39m df[df\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39misin(buy_idxs)]\u001b[38;5;241m.\u001b[39mopen\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m     51\u001b[0m sell_prices \u001b[38;5;241m=\u001b[39m df[df\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39misin(sell_idxs)]\u001b[38;5;241m.\u001b[39mopen\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m---> 52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mbuy_idxs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m<\u001b[39m sell_idxs[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m     53\u001b[0m   buy_pnl \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(sell_prices \u001b[38;5;241m-\u001b[39m buy_prices)\n\u001b[0;32m     54\u001b[0m   sell_pnl \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(sell_prices[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m buy_prices[\u001b[38;5;241m1\u001b[39m:])\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "def fun(price_data):\n",
    "  from numba import njit\n",
    "  @njit\n",
    "  def merge_pnl(arr1, arr2):\n",
    "    out = np.zeros((len(arr1) + len(arr2)))\n",
    "    idx = 1\n",
    "    for i in range(len(arr1) + len(arr2)):\n",
    "      if i % 2 == 0:\n",
    "        out[i] = arr1[int(i/2)]\n",
    "      else:\n",
    "        out[i] = arr2[i-idx]\n",
    "        idx += 1\n",
    "    return out\n",
    "  @njit\n",
    "  def get_drawdowns(arr):\n",
    "    drawdowns = np.zeros((len(arr)))\n",
    "    max = arr[0]\n",
    "    for i in range(1, len(drawdowns)-1):\n",
    "      if arr[i-1] > arr[i] and arr[i] < arr[i+1]:\n",
    "        min = arr[i]\n",
    "        drawdowns[i] = max - min\n",
    "      elif arr[i-1] < arr[i] and arr[i] > arr[i+1]:\n",
    "        max = arr[i]\n",
    "    return drawdowns\n",
    "  df = price_data.copy()\n",
    "  df['buy'] = (df.open % df.open < 0.1).astype(int)\n",
    "  df['sell'] = (0.5 == df.close).astype(int)\n",
    "  df['hold'] = (df.open % df.close > 1.7).astype(int)\n",
    "  df['signal'] = df['buy'] + df['sell'] + df.hold\n",
    "  df['signal'] = df['signal'].apply(lambda x: 1 if x==1 else 0)\n",
    "  df['hold'] = df.hold.apply(lambda x: 1 if x==0 else 0)\n",
    "  df['signal'] = df['signal'] * df['hold']\n",
    "  df['sell'] = df['sell'] * (-1)\n",
    "  df['signal'] = df['signal'] * df['sell']\n",
    "  df['signal'] = df['signal'] * df['buy']\n",
    "#   df.drop(columns=[buy, sell, hold], inplace=True)\n",
    "  buy_idxs = []\n",
    "  sell_idxs = []\n",
    "  is_buy = 0\n",
    "  is_sell = 0\n",
    "  for i, row in enumerate(df.itertuples()):\n",
    "    if row.signal == 1 and is_buy == 0:\n",
    "      buy_idxs.append(i+1)\n",
    "      is_buy = 1\n",
    "      is_sell = 0\n",
    "    elif row.signal == -1 and is_sell == 0:\n",
    "      sell_idxs.append(i+1)\n",
    "      is_sell = 1\n",
    "      is_buy = 0\n",
    "  buy_prices = df[df.index.isin(buy_idxs)].open.values\n",
    "  sell_prices = df[df.index.isin(sell_idxs)].open.values\n",
    "  if buy_idxs[0] < sell_idxs[0]:\n",
    "    buy_pnl = np.sum(sell_prices - buy_prices)\n",
    "    sell_pnl = np.sum(sell_prices[:-1] - buy_prices[1:])\n",
    "  else:\n",
    "    sell_pnl = np.sum(sell_prices - buy_prices)\n",
    "    buy_pnl = np.sum(sell_prices[1:] - buy_prices[:-1])\n",
    "  total_pnl = buy_pnl + sell_pnl\n",
    "  if buy_idxs[0] < sell_idxs[0]:\n",
    "    buy_arr = sell_prices - buy_prices\n",
    "    sell_arr = sell_prices[:-1] - buy_prices[1:]\n",
    "    all_arr = merge_pnl(buy_arr, sell_arr)\n",
    "  else:\n",
    "    sell_arr = sell_prices - buy_prices\n",
    "    buy_arr = sell_prices[1:] - buy_prices[:-1]\n",
    "    all_arr = merge_pnl(sell_arr, buy_arr)\n",
    "  equity_curve_arr = np.cumsum(all_arr)\n",
    "  drawdowns = get_drawdowns(equity_curve_arr)\n",
    "  avg_drawdown = np.sum(drawdowns[drawdowns!=0]) / len(drawdowns[drawdowns!=0])\n",
    "  fitness = total_pnl / avg_drawdown\n",
    "  return fitness\n",
    "fitness = fun(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit\n",
    "@njit\n",
    "def merge_pnl(arr1, arr2):\n",
    "    out = np.zeros((len(arr1) + len(arr2)))\n",
    "    idx = 1\n",
    "    for i in range(len(arr1) + len(arr2)):\n",
    "        if i % 2 == 0:\n",
    "            out[i] = arr1[int(i/2)]\n",
    "        else:\n",
    "            out[i] = arr2[i-idx]\n",
    "            idx += 1\n",
    "    return out\n",
    "\n",
    "@njit\n",
    "def get_drawdowns(arr):\n",
    "    drawdowns = np.zeros((len(arr)))\n",
    "    max = arr[0]\n",
    "    for i in range(1, len(drawdowns)-1):\n",
    "        if arr[i-1] > arr[i] and arr[i] < arr[i+1]:\n",
    "            min = arr[i]\n",
    "            drawdowns[i] = max - min\n",
    "        elif arr[i-1] < arr[i] and arr[i] > arr[i+1]:\n",
    "            max = arr[i]\n",
    "    return drawdowns\n",
    "\n",
    "df = data.copy()\n",
    "# df_buy = (RSI(df, HistLength=5) < 20).astype(int).values\n",
    "df = df.assign(buy=(RSI(df, HistLength=10) < 20).astype(int).values)\n",
    "# df_sell = (RSI(df, HistLength=5) > 80).astype(int).values\n",
    "df = df.assign(sell=(RSI(df, HistLength=10) > 80).astype(int).values)\n",
    "# df_hold = ((RSI(df, HistLength=5)>20) & (RSI(df, HistLength=5)<80)).astype(int).values\n",
    "# df = df.assign(hold=((RSI(df, HistLength=10)>=20) & (RSI(df, HistLength=10)<=80)).astype(int).values)\n",
    "df = df.assign(signal = (df.buy + df.sell).values)\n",
    "df.signal = df.signal.apply(lambda x: 1 if x==1 else 0)\n",
    "# # df_signal = np.where(df_signal == 1, 1, 0)\n",
    "# df.hold = df.hold.apply(lambda x: 1 if x==0 else 0)\n",
    "# # df_hold = np.where(df_hold == 0, 1, 0)\n",
    "# df.signal = df.signal * df.hold\n",
    "df.sell = df.sell * (-1)\n",
    "df.signal = df.signal * df.sell\n",
    "df.signal = df.signal + df.buy\n",
    "#   df.drop(columns=[buy, sell, hold], inplace=True)\n",
    "# del df_buy, df_sell, df_hold\n",
    "buy_idxs = []\n",
    "sell_idxs = []\n",
    "is_buy = 0\n",
    "is_sell = 0\n",
    "for i, row in enumerate(df.itertuples()):\n",
    "    if row.signal == 1 and is_buy == 0:\n",
    "        buy_idxs.append(i+1)\n",
    "        is_buy = 1\n",
    "        is_sell = 0\n",
    "    elif row.signal == -1 and is_sell == 0:\n",
    "        sell_idxs.append(i+1)\n",
    "        is_sell = 1\n",
    "        is_buy = 0\n",
    "# for i, row in enumerate(df.signal):\n",
    "#     if row == 1 and is_buy == 0:\n",
    "#         buy_idxs.append(i+1)\n",
    "#         is_buy = 1\n",
    "#         is_sell = 0\n",
    "#     elif row == -1 and is_sell == 0:\n",
    "#         sell_idxs.append(i+1)\n",
    "#         is_sell = 1\n",
    "#         is_buy = 0\n",
    "buy_prices = df[df.index.isin(buy_idxs)].open.values\n",
    "sell_prices = df[df.index.isin(sell_idxs)].open.values\n",
    "if buy_idxs[0] < sell_idxs[0]:\n",
    "    buy_pnl = np.sum(sell_prices - buy_prices)\n",
    "    sell_pnl = np.sum(sell_prices[:-1] - buy_prices[1:])\n",
    "else:\n",
    "    sell_pnl = np.sum(sell_prices - buy_prices)\n",
    "    buy_pnl = np.sum(sell_prices[1:] - buy_prices[:-1])\n",
    "total_pnl = buy_pnl + sell_pnl\n",
    "if buy_idxs[0] < sell_idxs[0]:\n",
    "    buy_arr = sell_prices - buy_prices\n",
    "    sell_arr = sell_prices[:-1] - buy_prices[1:]\n",
    "    all_arr = merge_pnl(buy_arr, sell_arr)\n",
    "else:\n",
    "    sell_arr = sell_prices - buy_prices\n",
    "    buy_arr = sell_prices[1:] - buy_prices[:-1]\n",
    "    all_arr = merge_pnl(sell_arr, buy_arr)\n",
    "equity_curve_arr = np.cumsum(all_arr)\n",
    "drawdowns = get_drawdowns(equity_curve_arr)\n",
    "avg_drawdown = np.sum(drawdowns[drawdowns!=0]) / len(drawdowns[drawdowns!=0])\n",
    "fitness = total_pnl / avg_drawdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.55282632656368"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>buy</th>\n",
       "      <th>sell</th>\n",
       "      <th>signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-30 22:05:00</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>16583.4</td>\n",
       "      <td>16583.4</td>\n",
       "      <td>4741.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-30 22:06:00</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-30 22:07:00</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>16583.4</td>\n",
       "      <td>16583.4</td>\n",
       "      <td>34811.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-30 22:08:00</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-30 22:09:00</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>5783.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime     open     high      low    close   volume  buy  sell  \\\n",
       "0 2022-12-30 22:05:00  16583.5  16583.5  16583.4  16583.4   4741.0    0     0   \n",
       "1 2022-12-30 22:06:00  16583.5  16583.5  16583.5  16583.5     22.0    0     0   \n",
       "2 2022-12-30 22:07:00  16583.5  16583.5  16583.4  16583.4  34811.0    0     0   \n",
       "3 2022-12-30 22:08:00  16583.5  16583.5  16583.5  16583.5     20.0    0     0   \n",
       "4 2022-12-30 22:09:00  16583.5  16583.5  16583.5  16583.5   5783.0    0     0   \n",
       "\n",
       "   signal  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "557"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.buy.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-580"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sell.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "534"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.signal.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>buy</th>\n",
       "      <th>sell</th>\n",
       "      <th>signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2023-01-06 20:40:00</td>\n",
       "      <td>16937.5</td>\n",
       "      <td>16946.6</td>\n",
       "      <td>16937.5</td>\n",
       "      <td>16938.4</td>\n",
       "      <td>663549.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>2023-01-06 20:41:00</td>\n",
       "      <td>16938.5</td>\n",
       "      <td>16942.0</td>\n",
       "      <td>16938.1</td>\n",
       "      <td>16939.6</td>\n",
       "      <td>355226.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>2023-01-06 20:42:00</td>\n",
       "      <td>16939.7</td>\n",
       "      <td>16939.7</td>\n",
       "      <td>16935.9</td>\n",
       "      <td>16935.9</td>\n",
       "      <td>76556.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>2023-01-06 20:43:00</td>\n",
       "      <td>16935.8</td>\n",
       "      <td>16935.8</td>\n",
       "      <td>16926.8</td>\n",
       "      <td>16927.5</td>\n",
       "      <td>260468.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>2023-01-06 20:44:00</td>\n",
       "      <td>16927.5</td>\n",
       "      <td>16927.6</td>\n",
       "      <td>16927.3</td>\n",
       "      <td>16927.3</td>\n",
       "      <td>93071.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                datetime     open     high      low    close    volume  buy  \\\n",
       "9995 2023-01-06 20:40:00  16937.5  16946.6  16937.5  16938.4  663549.0    0   \n",
       "9996 2023-01-06 20:41:00  16938.5  16942.0  16938.1  16939.6  355226.0    0   \n",
       "9997 2023-01-06 20:42:00  16939.7  16939.7  16935.9  16935.9   76556.0    0   \n",
       "9998 2023-01-06 20:43:00  16935.8  16935.8  16926.8  16927.5  260468.0    0   \n",
       "9999 2023-01-06 20:44:00  16927.5  16927.6  16927.3  16927.3   93071.0    0   \n",
       "\n",
       "      sell  signal  \n",
       "9995     0       0  \n",
       "9996     0       0  \n",
       "9997     0       0  \n",
       "9998     0       0  \n",
       "9999     0       0  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grammar_evol",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
