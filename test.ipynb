{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data():\n",
    "    df = pd.read_csv(Path(r'C:/\\Users/\\vchar/\\OneDrive/\\Desktop/\\ML Projects/\\Upwork/\\AlgoT_ML_Dev/\\GrammarEvolution/\\PonyGE2/\\datasets/\\BTCUSD_ohlcv.csv'))\n",
    "    # df = pd.read_csv('/kaggle/input/btcusd-test/BTCUSD_ohlcv.csv')\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "    df = df.iloc[-10080:]\n",
    "    df.sort_values('datetime', ascending=True, inplace=True)\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-30 20:45:00</td>\n",
       "      <td>16534.6</td>\n",
       "      <td>16537.5</td>\n",
       "      <td>16534.6</td>\n",
       "      <td>16537.5</td>\n",
       "      <td>36187.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-30 20:46:00</td>\n",
       "      <td>16537.5</td>\n",
       "      <td>16538.2</td>\n",
       "      <td>16535.6</td>\n",
       "      <td>16538.2</td>\n",
       "      <td>101860.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-30 20:47:00</td>\n",
       "      <td>16538.2</td>\n",
       "      <td>16538.2</td>\n",
       "      <td>16538.1</td>\n",
       "      <td>16538.2</td>\n",
       "      <td>102265.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-30 20:48:00</td>\n",
       "      <td>16538.2</td>\n",
       "      <td>16538.4</td>\n",
       "      <td>16538.1</td>\n",
       "      <td>16538.2</td>\n",
       "      <td>71347.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-30 20:49:00</td>\n",
       "      <td>16538.2</td>\n",
       "      <td>16538.2</td>\n",
       "      <td>16535.8</td>\n",
       "      <td>16535.9</td>\n",
       "      <td>57985.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime     open     high      low    close    volume\n",
       "0 2022-12-30 20:45:00  16534.6  16537.5  16534.6  16537.5   36187.0\n",
       "1 2022-12-30 20:46:00  16537.5  16538.2  16535.6  16538.2  101860.0\n",
       "2 2022-12-30 20:47:00  16538.2  16538.2  16538.1  16538.2  102265.0\n",
       "3 2022-12-30 20:48:00  16538.2  16538.4  16538.1  16538.2   71347.0\n",
       "4 2022-12-30 20:49:00  16538.2  16538.2  16535.8  16535.9   57985.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = generate_data()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numba import prange, njit, types\n",
    "from numba.typed import Dict\n",
    "import pandas_ta as ta\n",
    "import itertools\n",
    "import gc\n",
    "import time\n",
    "from scipy.stats import norm, iqr, chi2, chi2_contingency\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_observation(x, x_median, x_iqr, is_centered=True, is_scaled=True):\n",
    "\n",
    "    if is_centered:\n",
    "        new_x = x - x_median\n",
    "    else:\n",
    "        new_x = x.copy()\n",
    "\n",
    "    if is_scaled:\n",
    "        new_x = 100 * norm.cdf(0.25 * new_x / x_iqr) - 50\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    return new_x\n",
    "\n",
    "# Creating functions for trend indicators/variables\n",
    "\n",
    "def MA_DIFFERENCE(df, ShortLength, LongLength, Lag):\n",
    "    short_ma = ta.sma(df['close'], length=ShortLength)\n",
    "    long_ma = ta.sma(df['close'].shift(Lag), length=LongLength)\n",
    "    ma_diff = short_ma - long_ma\n",
    "    df_atr = ta.atr(high=df['high'], low=df['low'], close=df['close'], length=LongLength+Lag)\n",
    "    df_stat = ma_diff / df_atr\n",
    "    period = LongLength+Lag\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['MA_Diff']\n",
    "    return df_stat\n",
    "\n",
    "def get_ls_slope(y, length):\n",
    "    # X = np.vstack([np.arange(1, length+1), np.ones(length, dtype='int')]).T\n",
    "    # m, c = np.linalg.lstsq(X, y, rcond=None)[0]\n",
    "    x = np.arange(1, length+1)\n",
    "    # np.polyfit(x, y, 1)\n",
    "    return np.polyfit(x, y, 1)[0] #m #* np.arange(1, length+1) + c\n",
    "\n",
    "def LINEAR_PER_ATR(df, HistLength, ATRlength):\n",
    "    df_log_mean = np.log(df[['high', 'low', 'open', 'close']].mean(axis=1))\n",
    "    df_atr = ta.atr(high=df['high'], low=df['low'], close=df['close'], length=ATRlength)\n",
    "    df_slope = df_log_mean.rolling(window=HistLength).apply(lambda x: get_ls_slope(y=x, length=len(x)))\n",
    "    df_stat = df_slope / df_atr\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Price_Velocity']\n",
    "    return df_stat\n",
    "\n",
    "def get_quad_slope(y, length):\n",
    "    # X = np.vstack([np.arange(1, length+1), np.ones(length, dtype='int')]).T\n",
    "    # m, c = np.linalg.lstsq(X, y, rcond=None)[0]\n",
    "    x = np.arange(1, length+1)\n",
    "    # np.polyfit(x, y, 1)\n",
    "    return np.polyfit(x, y, 2)[0] #m #* np.arange(1, length+1) + c\n",
    "\n",
    "def QUADRATIC_PER_ATR(df, HistLength, ATRlength):\n",
    "    df_log_mean = np.log(df[['high', 'low', 'open', 'close']].mean(axis=1))\n",
    "    df_atr = ta.atr(high=df['high'], low=df['low'], close=df['close'], length=ATRlength)\n",
    "    df_slope = df_log_mean.rolling(window=HistLength).apply(lambda x: get_quad_slope(y=x, length=len(x)))\n",
    "    df_stat = df_slope / df_atr\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Price_Acceleration']\n",
    "    return df_stat\n",
    "\n",
    "def get_cubic_slope(y, length):\n",
    "    # X = np.vstack([np.arange(1, length+1), np.ones(length, dtype='int')]).T\n",
    "    # m, c = np.linalg.lstsq(X, y, rcond=None)[0]\n",
    "    x = np.arange(1, length+1)\n",
    "    # np.polyfit(x, y, 1)\n",
    "    return np.polyfit(x, y, 3)[0] #m #* np.arange(1, length+1) + c\n",
    "\n",
    "def CUBIC_PER_ATR(df, HistLength, ATRlength):\n",
    "    df_log_mean = np.log(df[['high', 'low', 'open', 'close']].mean(axis=1))\n",
    "    df_atr = ta.atr(high=df['high'], low=df['low'], close=df['close'], length=ATRlength)\n",
    "    df_slope = df_log_mean.rolling(window=HistLength).apply(lambda x: get_cubic_slope(y=x, length=len(x)))\n",
    "    df_stat = df_slope / df_atr\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Acceleration_Rate_of_Change']\n",
    "    return df_stat\n",
    "\n",
    "def RSI(df, HistLength):\n",
    "    rsi_df = ta.rsi(df['close'], length=HistLength).to_frame()\n",
    "    rsi_df.columns = ['RSI']\n",
    "    return rsi_df\n",
    "\n",
    "def STOCHASTIC_K(df, fastk_period, slowk_period, slowd_period):\n",
    "\n",
    "\tdf_stat = ta.stoch(\n",
    "\t\tdf[\"high\"], df[\"low\"], df[\"close\"], \n",
    "\t\tfastk_period, slowk_period, slowd_period)[f'STOCHk_{fastk_period}_{slowk_period}_{slowd_period}']\n",
    "\tdf_stat = df_stat.to_frame()\n",
    "\tdf_stat.columns = ['STOCHASTIC_K']\n",
    "\treturn df_stat\n",
    "\n",
    "def STOCHASTIC_D(df, fastk_period, slowk_period, slowd_period):\n",
    "\tdf_stat = ta.stoch(\n",
    "\t\tdf[\"high\"], df[\"low\"], df[\"close\"], \n",
    "\t\tfastk_period, slowk_period, slowd_period)[f'STOCHd_{fastk_period}_{slowk_period}_{slowd_period}']\n",
    "\tdf_stat = df_stat.to_frame()\n",
    "\tdf_stat.columns = ['STOCHASTIC_D']\n",
    "\treturn df_stat\n",
    "\n",
    "def PRICE_MOMENTUM(df, HistLength, StdDevLength):\n",
    "\n",
    "    df_stat = df['close'] / df['close'].shift(HistLength)\n",
    "    df_std = df['close'].rolling(window=StdDevLength).std()\n",
    "    df_stat = df_stat / df_std\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Price_Momentum']\n",
    "    return df_stat\n",
    "\n",
    "def ADX(df, HistLength):\n",
    "\tdf_stat = ta.adx(\n",
    "\t\thigh=df['high'], \n",
    "\t\tlow=df['low'], \n",
    "\t\tclose=df['close'], \n",
    "\t\tlength=HistLength\n",
    "\t)[f'ADX_{HistLength}']\n",
    "\n",
    "\tdf_stat = df_stat.to_frame()\n",
    "\tdf_stat.columns = ['ADX']\n",
    "\treturn df_stat\n",
    "\n",
    "def MIN_ADX(df, HistLength, MinLength):\n",
    "\n",
    "    adx_list = []\n",
    "\n",
    "    for i in range(MinLength):\n",
    "        temp_adx = ta.adx(\n",
    "            high=df['high'].shift(i), \n",
    "            low=df['low'].shift(i), \n",
    "            close=df['close'].shift(i), \n",
    "            length=HistLength\n",
    "        )[f'ADX_{HistLength}']\n",
    "\n",
    "        adx_list.append(temp_adx.values)\n",
    "\n",
    "    df_stat = pd.Series(np.min(np.array(adx_list), axis=0), index=temp_adx.index)\n",
    "    df_stat = df_stat.to_frame()  \n",
    "    df_stat.columns = ['Min_ADX']\n",
    "    return df_stat\n",
    "\n",
    "def RESIDUAL_MIN_ADX(df, HistLength, MinLength):\n",
    "\n",
    "    current_adx = ta.adx(\n",
    "        high=df['high'], \n",
    "        low=df['low'], \n",
    "        close=df['close'], \n",
    "        length=HistLength\n",
    "    )[f'ADX_{HistLength}']\n",
    "\n",
    "    min_adx = MIN_ADX(df, HistLength, MinLength)\n",
    "\n",
    "    df_stat = current_adx - min_adx\n",
    "\n",
    "    return df_stat\n",
    "\n",
    "def MAX_ADX(df, HistLength, MaxLength):\n",
    "\n",
    "    adx_list = []\n",
    "\n",
    "    for i in range(MaxLength):\n",
    "        temp_adx = ta.adx(\n",
    "            high=df['high'].shift(i), \n",
    "            low=df['low'].shift(i), \n",
    "            close=df['close'].shift(i), \n",
    "            length=HistLength\n",
    "        )[f'ADX_{HistLength}']\n",
    "\n",
    "        adx_list.append(temp_adx.values)\n",
    "\n",
    "    df_stat = pd.DataFrame(np.max(np.array(adx_list), axis=0), index=df.index)\n",
    "    df_stat.columns = ['MAX_ADX']\n",
    "    return df_stat\n",
    "\n",
    "def RESIDUAL_MAX_ADX(df, HistLength, MaxLength):\n",
    "\n",
    "    current_adx = ta.adx(\n",
    "        high=df['high'], \n",
    "        low=df['low'], \n",
    "        close=df['close'], \n",
    "        length=HistLength\n",
    "    )[f'ADX_{HistLength}']\n",
    "\n",
    "    max_adx = MAX_ADX(df, HistLength, MaxLength)\n",
    "\n",
    "    df_stat = max_adx - current_adx\n",
    "\n",
    "    return df_stat\n",
    "\n",
    "def DELTA_ADX(df, HistLength,  DeltaLength):\n",
    "\n",
    "    current_adx = ta.adx(\n",
    "        high=df['high'], \n",
    "        low=df['low'], \n",
    "        close=df['close'], \n",
    "        length=HistLength\n",
    "    )[f'ADX_{HistLength}']\n",
    "\n",
    "    lag_adx = ta.adx(\n",
    "        high=df['high'].shift(DeltaLength), \n",
    "        low=df['low'].shift(DeltaLength), \n",
    "        close=df['close'].shift(DeltaLength), \n",
    "        length=HistLength\n",
    "    )[f'ADX_{HistLength}']\n",
    "\n",
    "    df_stat = current_adx - lag_adx\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['ADX_Velocity']\n",
    "    return df_stat\n",
    "\n",
    "def ACCEL_ADX(df, HistLength, DeltaLength):\n",
    "\n",
    "    current_adx = ta.adx(\n",
    "        high=df['high'], \n",
    "        low=df['low'], \n",
    "        close=df['close'], \n",
    "        length=HistLength\n",
    "    )[f'ADX_{HistLength}']\n",
    "\n",
    "    lag_adx1 = ta.adx(\n",
    "        high=df['high'].shift(DeltaLength), \n",
    "        low=df['low'].shift(DeltaLength), \n",
    "        close=df['close'].shift(DeltaLength), \n",
    "        length=HistLength\n",
    "    )[f'ADX_{HistLength}']\n",
    "\n",
    "    lag_adx2 = ta.adx(\n",
    "        high=df['high'].shift(2*DeltaLength), \n",
    "        low=df['low'].shift(2*DeltaLength), \n",
    "        close=df['close'].shift(2*DeltaLength), \n",
    "        length=HistLength\n",
    "    )[f'ADX_{HistLength}']\n",
    "\n",
    "    df_stat = current_adx + lag_adx2 - 2 * lag_adx1\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['ADX_Acceleration']\n",
    "    return df_stat\n",
    "\n",
    "def INTRADAY_INTENSITY(df, HistLength):\n",
    "\n",
    "    diff1 = df['high'] - df['low']\n",
    "    diff2 = df['high'] - df['close'].shift(1)\n",
    "    diff3 = df['close'].shift(1) - df['low']\n",
    "\n",
    "    true_range = np.max(\n",
    "        np.array(\n",
    "            [\n",
    "                diff1.values, \n",
    "                diff2.values, \n",
    "                diff3.values\n",
    "             ]\n",
    "        ), \n",
    "    axis=0\n",
    "    )\n",
    "\n",
    "    current_change = df['close'] - df['open']\n",
    "\n",
    "    df_stat = current_change / true_range\n",
    "    df_stat = df_stat.rolling(window=HistLength).mean()\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Intraday_Intensity']\n",
    "    return df_stat\n",
    "\n",
    "def DELTA_INTRADAY_INTENSITY(df, HistLength, DeltaLength):\n",
    "\n",
    "    current_inten = INTRADAY_INTENSITY(df, HistLength)\n",
    "    lag_inten = INTRADAY_INTENSITY(df=df.shift(DeltaLength), HistLength=HistLength)\n",
    "    df_stat = current_inten - lag_inten\n",
    "    df_stat.columns = ['Delta_Intraday_Intensity']\n",
    "    return df_stat\n",
    "\n",
    "def REACTIVITY(df, HistLength):\n",
    "\n",
    "    price_change = df['close'] - df['close'].shift(HistLength)\n",
    "\n",
    "    max_price = df['high'].rolling(window=HistLength).max()\n",
    "    min_price = df['low'].rolling(window=HistLength).min()\n",
    "    price_range = max_price - min_price\n",
    "\n",
    "    total_volume = df['volume'].rolling(window=HistLength).sum()\n",
    "\n",
    "    ema_price_range = ta.ema(close=price_range, length=8*HistLength)\n",
    "    ema_total_volume = ta.ema(close=total_volume, length=8*HistLength)\n",
    "    aspect_ratio = (price_range / ema_price_range) / (total_volume / ema_total_volume)\n",
    "\n",
    "    raw_reactivity = price_change * aspect_ratio\n",
    "    df_stat = raw_reactivity / ema_price_range\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Reactivity']\n",
    "    return df_stat\n",
    "\n",
    "def DELTA_REACTIVITY(df, HistLength, DeltaDist):\n",
    "\n",
    "    current_reactivity = REACTIVITY(df, HistLength)\n",
    "    lag_reactivity = REACTIVITY(df=df.shift(DeltaDist), HistLength=HistLength)\n",
    "\n",
    "    stat_values = (current_reactivity - lag_reactivity).values.reshape(-1, )\n",
    "\n",
    "    df_stat = pd.Series(stat_values, index=df.index)\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Delta_Reactivity']\n",
    "    return df_stat\n",
    "\n",
    "def MIN_REACTIVITY(df, HistLength, Dist):\n",
    "\n",
    "    reactivity_list = []\n",
    "    for i in range(Dist):\n",
    "        reactivity_list.append(REACTIVITY(df=df.shift(i), HistLength=HistLength).values)\n",
    "\n",
    "    stat_values = np.min(np.array(reactivity_list), axis=0).reshape(-1, )\n",
    "\n",
    "    df_stat = pd.Series(stat_values, index=df.index)\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Min_Reactivity']\n",
    "    return df_stat\n",
    "\n",
    "def MAX_REACTIVITY(df, HistLength, Dist):\n",
    "\n",
    "    reactivity_list = []\n",
    "    for i in range(Dist):\n",
    "        reactivity_list.append(REACTIVITY(df=df.shift(i), HistLength=HistLength).values)\n",
    "\n",
    "    stat_values = np.max(np.array(reactivity_list), axis=0).reshape(-1, )\n",
    "\n",
    "    df_stat = pd.Series(stat_values, index=df.index)\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Max_Reactivity']\n",
    "    return df_stat\n",
    "\n",
    "# Creating functions for trend like indicators/variables\n",
    "\n",
    "def CLOSE_TO_CLOSE(df):\n",
    "\n",
    "    df_stat = 100 * np.log(df['close'] / df['close'].shift(1))\n",
    "    df_stat = df_stat.to_frame()\n",
    "    df_stat.columns = ['Close_to_Close']\n",
    "    return df_stat\n",
    "\n",
    "@njit\n",
    "def get_n_day_high(x, y):\n",
    "\n",
    "    N = len(x) + 1\n",
    "\n",
    "    for i in prange(len(x)-1, -1, -1):\n",
    "        if x[i] > y:\n",
    "            N = i + 1\n",
    "            break\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    return 100 * (N-1) / len(x) - 50\n",
    "\n",
    "@njit\n",
    "def get_hist_values(x, length):\n",
    "\n",
    "    hist_values = []\n",
    "\n",
    "    for i in prange(length, len(x)+1):\n",
    "\n",
    "        hist_values.append(x[i-length: i])\n",
    "\n",
    "    return hist_values\n",
    "\n",
    "def N_DAY_HIGH(df, HistLength):\n",
    "\n",
    "    list_of_values = get_hist_values(x=df['high'].values, length=HistLength)\n",
    "    # df['high'].rolling(window=HistLength, closed='left').apply(\n",
    "    #     lambda x: list_of_values.append(x.values) or 0, \n",
    "    #     raw=False\n",
    "    # )\n",
    "\n",
    "    temp_df = pd.Series(list_of_values, index=df.iloc[HistLength-1:].index)\n",
    "    temp_df = temp_df.to_frame()\n",
    "    temp_df.columns = ['high_list']\n",
    "    temp_df['high'] = df.iloc[HistLength:]['high']\n",
    "\n",
    "    df_stat = temp_df.apply(lambda x: get_n_day_high(x=x['high_list'], y=x['high']), axis=1)\n",
    "    df_stat = df_stat.to_frame()\n",
    "    df_stat.columns = ['N_Day_High']\n",
    "    return df_stat\n",
    "\n",
    "@njit\n",
    "def get_n_day_low(x, y):\n",
    "\n",
    "    N = len(x) + 1\n",
    "\n",
    "    for i in prange(len(x)-1, -1, -1):\n",
    "        if x[i] < y:\n",
    "            N = i + 1\n",
    "            break\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    return 100 * (N-1) / len(x) - 50\n",
    "\n",
    "def N_DAY_LOW(df, HistLength):\n",
    "\n",
    "    list_of_values = get_hist_values(x=df['low'].values, length=HistLength)\n",
    "    # df['low'].rolling(window=HistLength, closed='left').apply(\n",
    "    #     lambda x: list_of_values.append(x.values) or 0, \n",
    "    #     raw=False\n",
    "    # )\n",
    "\n",
    "    temp_df = pd.Series(list_of_values, index=df.iloc[HistLength-1:].index)\n",
    "    temp_df = temp_df.to_frame()\n",
    "    temp_df.columns = ['low_list']\n",
    "    temp_df['low'] = df.iloc[HistLength:]['low']\n",
    "\n",
    "    df_stat = temp_df.apply(lambda x: get_n_day_low(x=x['low_list'], y=x['low']), axis=1)\n",
    "    df_stat = df_stat.to_frame()\n",
    "    df_stat.columns = ['N_Day_Low']\n",
    "    return df_stat\n",
    "\n",
    "# Creating functions for indicators/variables of deviations from trend\n",
    "\n",
    "def CLOSE_MINUS_MOVING_AVERAGE(df, HistLen, ATRlen):\n",
    "\n",
    "    close_ratio = np.log(df['close'] / df['close'].rolling(window=HistLen).mean())\n",
    "    atr = ta.atr(high=df['high'], low=df['low'], close=df['close'], length=ATRlen)\n",
    "    df_stat = close_ratio / atr\n",
    "    period = HistLen\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['CMMA']\n",
    "    return df_stat\n",
    "\n",
    "def get_ls_fit(y):\n",
    "    length = len(y)\n",
    "    x = np.arange(1, length+1)\n",
    "    result = np.polyfit(x, y, 1)\n",
    "    y_fit = result[1] + length * result[0]\n",
    "    std_dev = np.sum((y - y_fit)**2)\n",
    "    std_error = (std_dev / (length-1)) ** 0.5\n",
    "    return [y_fit, std_error]\n",
    "\n",
    "def LINEAR_DEVIATION(df, HistLength):\n",
    "\n",
    "    df_log_mean = np.log(df[['high', 'low', 'open', 'close']].mean(axis=1))\n",
    "\n",
    "    list_of_values = get_hist_values(x=df_log_mean.values, length=HistLength)\n",
    "    # df_log_mean.rolling(window=HistLength, closed='both').apply(\n",
    "    #     lambda x: list_of_values.append(x.values) or 0, \n",
    "    #     raw=False\n",
    "    # )\n",
    "\n",
    "    temp_df = pd.Series(list_of_values, index=df.iloc[HistLength-1:].index)\n",
    "    temp_df = temp_df.apply(lambda x: get_ls_fit(y=x))\n",
    "    temp_df = pd.DataFrame(temp_df.to_list(), columns=['fit','std_error'])\n",
    "    temp_df.index = df.iloc[HistLength-1:].index\n",
    "    temp_df['log_price'] = df_log_mean.iloc[HistLength-1:]\n",
    "\n",
    "    df_stat = (temp_df['log_price'] - temp_df['fit']) / temp_df['std_error']\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Linear_Deviation']\n",
    "    return df_stat\n",
    "\n",
    "def get_quadratic_fit(y):\n",
    "    length = len(y)\n",
    "    x = np.arange(1, length+1)\n",
    "    result = np.polyfit(x, y, 2)\n",
    "    y_fit = result[2] + length * result[1] + (length**2) * result[0]\n",
    "    std_dev = np.sum((y - y_fit)**2)\n",
    "    std_error = (std_dev / (length-1)) ** 0.5\n",
    "    return [y_fit, std_error]\n",
    "\n",
    "def QUADRATIC_DEVIATION(df, HistLength):\n",
    "\n",
    "    df_log_mean = np.log(df[['high', 'low', 'open', 'close']].mean(axis=1))\n",
    "\n",
    "    # list_of_values = []\n",
    "    # df_log_mean.rolling(window=HistLength, closed='both').apply(\n",
    "    #     lambda x: list_of_values.append(x.values) or 0, \n",
    "    #     raw=False\n",
    "    # )\n",
    "    list_of_values = get_hist_values(x=df_log_mean.values, length=HistLength)\n",
    "\n",
    "    temp_df = pd.Series(list_of_values, index=df.iloc[HistLength-1:].index)\n",
    "    temp_df = temp_df.apply(lambda x: get_quadratic_fit(y=x))\n",
    "    temp_df = pd.DataFrame(temp_df.to_list(), columns=['fit','std_error'])\n",
    "    temp_df.index = df.iloc[HistLength-1:].index\n",
    "    temp_df['log_price'] = df_log_mean.iloc[HistLength-1:]\n",
    "\n",
    "    df_stat = (temp_df['log_price'] - temp_df['fit']) / temp_df['std_error']\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Quadratic_Deviation']\n",
    "    return df_stat\n",
    "\n",
    "def get_cubic_fit(y):\n",
    "    length = len(y)\n",
    "    x = np.arange(1, length+1)\n",
    "    result = np.polyfit(x, y, 3)\n",
    "    y_fit = result[3] + length * result[2] + (length**2) * result[1] + (length**3) * result[0]\n",
    "    std_dev = np.sum((y - y_fit)**2)\n",
    "    std_error = (std_dev / (length-1)) ** 0.5\n",
    "    return [y_fit, std_error]\n",
    "\n",
    "def CUBIC_DEVIATION(df, HistLength):\n",
    "\n",
    "    df_log_mean = np.log(df[['high', 'low', 'open', 'close']].mean(axis=1))\n",
    "\n",
    "    # list_of_values = []\n",
    "    # df_log_mean.rolling(window=HistLength, closed='both').apply(\n",
    "    #     lambda x: list_of_values.append(x.values) or 0, \n",
    "    #     raw=False\n",
    "    # )\n",
    "    list_of_values = get_hist_values(x=df_log_mean.values, length=HistLength)\n",
    "\n",
    "    temp_df = pd.Series(list_of_values, index=df.iloc[HistLength-1:].index)\n",
    "    temp_df = temp_df.apply(lambda x: get_cubic_fit(y=x))\n",
    "    temp_df = pd.DataFrame(temp_df.to_list(), columns=['fit','std_error'])\n",
    "    temp_df.index = df.iloc[HistLength-1:].index\n",
    "    temp_df['log_price'] = df_log_mean.iloc[HistLength-1:]\n",
    "\n",
    "    df_stat = (temp_df['log_price'] - temp_df['fit']) / temp_df['std_error']\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Cubic_Deviation']\n",
    "    return df_stat\n",
    "\n",
    "def get_ls_fit2(x, y):\n",
    "    result = np.polyfit(x, y, 1)\n",
    "    y_fit = result[1] + x[-1] * result[0]\n",
    "    return y_fit\n",
    "\n",
    "def DETRENDED_RSI(df, DetrendedLength, DetrenderLength, Lookback):\n",
    "\n",
    "    rsi_y = ta.rsi(df['close'], length=DetrendedLength)\n",
    "\n",
    "    if DetrendedLength == 2:\n",
    "        rsi_y = 1 / (1 + np.exp(-rsi_y))\n",
    "\n",
    "    rsi_x = ta.rsi(df['close'], length=DetrenderLength)\n",
    "\n",
    "    rsi_array = np.vstack([rsi_y.values, rsi_x.values]).T\n",
    "    rsi_df = pd.DataFrame(rsi_array, columns=['rsi_y', 'rsi_x'], index=rsi_y.index)\n",
    "    rsi_df.dropna(inplace=True)\n",
    "\n",
    "    # list_of_rsi_y = []\n",
    "    # rsi_df['rsi_y'].rolling(window=Lookback, closed='both').apply(\n",
    "    #     lambda x: list_of_rsi_y.append(x.values) or 0, \n",
    "    #     raw=False\n",
    "    # )\n",
    "    list_of_rsi_y = get_hist_values(x=rsi_df['rsi_y'].values, length=Lookback)\n",
    "\n",
    "    # list_of_rsi_x = []\n",
    "    # rsi_df['rsi_x'].rolling(window=Lookback, closed='both').apply(\n",
    "    #     lambda x: list_of_rsi_x.append(x.values) or 0, \n",
    "    #     raw=False\n",
    "    # )\n",
    "    list_of_rsi_x = get_hist_values(x=rsi_df['rsi_x'].values, length=Lookback)\n",
    "\n",
    "    temp_df = pd.Series(list_of_rsi_x, index=df.iloc[Lookback-1+DetrenderLength:].index)\n",
    "    temp_df = temp_df.to_frame()\n",
    "    temp_df.columns = ['rsi_x']\n",
    "    temp_df['rsi_y'] = list_of_rsi_y\n",
    "\n",
    "    temp_df['fit'] = temp_df.apply(lambda x: get_ls_fit2(x=x['rsi_x'], y=x['rsi_y']), axis=1)\n",
    "    temp_df['rsi_y'] = rsi_y.iloc[Lookback-1:]\n",
    "\n",
    "    df_stat = (temp_df['rsi_y'] - temp_df['fit'])\n",
    "    df_stat = df_stat.to_frame()\n",
    "    df_stat.columns = ['Detrended_RSI']\n",
    "    return df_stat\n",
    "\n",
    "# Creating functions for volatility indicators/variables\n",
    "\n",
    "def ABS_PRICE_CHANGE_OSCILLATOR(df, ShortLen, Multiplier):\n",
    "\n",
    "    price_changes = np.abs(np.log(df['close']/df['close'].shift(1)))\n",
    "    short_ma = price_changes.rolling(window=ShortLen).mean()\n",
    "    long_ma = price_changes.rolling(window=ShortLen*Multiplier).mean()\n",
    "    atr = ta.atr(high=df['high'], low=df['low'], close=df['close'], length=ShortLen*Multiplier)\n",
    "    df_stat = (short_ma - long_ma) / atr\n",
    "    period = ShortLen\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['APCO']\n",
    "    return df_stat\n",
    "\n",
    "def PRICE_VARIANCE_RATIO(df, HistLength, Multiplier):\n",
    "\n",
    "    log_prices = np.log(df['close'])\n",
    "    short_var = log_prices.rolling(window=HistLength).var()\n",
    "    long_var = log_prices.rolling(window=HistLength*Multiplier).var()\n",
    "    df_stat = short_var / long_var\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['PVR']\n",
    "    return df_stat\n",
    "\n",
    "def MIN_PRICE_VARIANCE_RATIO(df, HistLen, Mult, Mlength):\n",
    "\n",
    "    pvr_list = []\n",
    "\n",
    "    for i in range(Mlength):\n",
    "\n",
    "        pvr_list.append(PRICE_VARIANCE_RATIO(df=df.shift(i), HistLength=HistLen, Multiplier=Mult))\n",
    "\n",
    "    df_stat = np.min(np.array(pvr_list), axis=0)\n",
    "    df_stat = pd.DataFrame(df_stat, index=df.index)\n",
    "    df_stat.columns = ['MinPVR']\n",
    "    return df_stat\n",
    "\n",
    "def MAX_PRICE_VARIANCE_RATIO(df, HistLen, Mult, Mlength):\n",
    "\n",
    "    pvr_list = []\n",
    "\n",
    "    for i in range(Mlength):\n",
    "\n",
    "        pvr_list.append(PRICE_VARIANCE_RATIO(df=df.shift(i), HistLength=HistLen, Multiplier=Mult))\n",
    "\n",
    "    df_stat = np.max(np.array(pvr_list), axis=0)\n",
    "    df_stat = pd.DataFrame(df_stat, index=df.index)\n",
    "    df_stat.columns = ['MaxPVR']\n",
    "    return df_stat\n",
    "\n",
    "def CHANGE_VARIANCE_RATIO(df, HistLength, Multiplier):\n",
    "\n",
    "    log_prices = np.log(df['close']/df['close'].shift(1))\n",
    "    short_var = log_prices.rolling(window=HistLength).var()\n",
    "    long_var = log_prices.rolling(window=HistLength*Multiplier).var()\n",
    "    df_stat = short_var / long_var\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['CVR']\n",
    "    return df_stat\n",
    "\n",
    "def MIN_CHANGE_VARIANCE_RATIO(df, HistLen, Mult, Mlen):\n",
    "\n",
    "    pvr_list = []\n",
    "\n",
    "    for i in range(Mlen):\n",
    "\n",
    "        pvr_list.append(CHANGE_VARIANCE_RATIO(df=df.shift(i), HistLength=HistLen, Multiplier=Mult))\n",
    "\n",
    "    df_stat = np.min(np.array(pvr_list), axis=0)\n",
    "    df_stat = pd.DataFrame(df_stat, index=df.index)\n",
    "    df_stat.columns = ['MinCVR']\n",
    "    return df_stat\n",
    "\n",
    "def MAX_CHANGE_VARIANCE_RATIO(df, HistLen, Mult, Mlength):\n",
    "\n",
    "    pvr_list = []\n",
    "\n",
    "    for i in range(Mlength):\n",
    "\n",
    "        pvr_list.append(CHANGE_VARIANCE_RATIO(df=df.shift(i), HistLength=HistLen, Multiplier=Mult))\n",
    "\n",
    "    df_stat = np.max(np.array(pvr_list), axis=0)\n",
    "    df_stat = pd.DataFrame(df_stat, index=df.index)\n",
    "    df_stat.columns = ['MaxCVR']\n",
    "    return df_stat\n",
    "\n",
    "def ATR_RATIO(df, HistLength, Multiplier):\n",
    "\n",
    "    short_atr = ta.atr(high=df['high'], low=df['low'], close=df['close'], length=HistLength)\n",
    "    long_atr = ta.atr(high=df['high'], low=df['low'], close=df['close'], length=HistLength*Multiplier)\n",
    "    df_stat = short_atr / long_atr\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['ATR_Ratio']\n",
    "    return df_stat\n",
    "\n",
    "def DELTA_PRICE_VARIANCE_RATIO(df, HistLength, Multiplier):\n",
    "\n",
    "    current_pvr = PRICE_VARIANCE_RATIO(df, HistLength, Multiplier)\n",
    "    lag_value = HistLength * Multiplier\n",
    "    lag_pvr = PRICE_VARIANCE_RATIO(df=df.shift(lag_value), HistLength=HistLength, Multiplier=Multiplier)\n",
    "    df_stat = current_pvr - lag_pvr\n",
    "    df_stat.columns = ['DPVR']\n",
    "    return df_stat\n",
    "\n",
    "def DELTA_CHANGE_VARIANCE_RATIO(df, HistLength, Multiplier):\n",
    "\n",
    "    current_pvr = CHANGE_VARIANCE_RATIO(df, HistLength, Multiplier)\n",
    "    lag_value = HistLength * Multiplier\n",
    "    lag_pvr = CHANGE_VARIANCE_RATIO(df=df.shift(lag_value), HistLength=HistLength, Multiplier=Multiplier)\n",
    "    df_stat = current_pvr - lag_pvr\n",
    "    df_stat.columns = ['DCVR']\n",
    "    return df_stat\n",
    "\n",
    "def DELTA_ATR_RATIO(df, HistLength, Multiplier):\n",
    "\n",
    "    current_pvr = ATR_RATIO(df, HistLength, Multiplier)\n",
    "    lag_value = HistLength * Multiplier\n",
    "    lag_pvr = ATR_RATIO(df=df.shift(lag_value), HistLength=HistLength, Multiplier=Multiplier)\n",
    "    df_stat = current_pvr - lag_pvr\n",
    "    df_stat.columns = ['Delta_ATR_Ration']\n",
    "    return df_stat\n",
    "\n",
    "def BOLLINGER_WIDTH(df, HistLength):\n",
    "\n",
    "    mean = df['close'].rolling(window=HistLength).mean()\n",
    "    std = df['close'].rolling(window=HistLength).std()\n",
    "    df_stat = np.log(std / mean)\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Bollinger_Width']\n",
    "    return df_stat\n",
    "\n",
    "def DELTA_BOLLINGER_WIDTH(df, HistLength, DeltaLength):\n",
    "\n",
    "    current_bw = BOLLINGER_WIDTH(df, HistLength)\n",
    "    lag_bw = BOLLINGER_WIDTH(df=df.shift(DeltaLength), HistLength=HistLength)\n",
    "    df_stat = current_bw - lag_bw\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:]['Bollinger_Width'].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:]['Bollinger_Width'].values)\n",
    "    df_stat = pd.Series(df_stat.values.reshape(-1, ), index=df_stat.index)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Delta_Bollinger_Width']\n",
    "    return df_stat\n",
    "\n",
    "@njit\n",
    "def get_n_day_narrower(x, y):\n",
    "\n",
    "    N = len(x) + 1\n",
    "\n",
    "    for i in prange(len(x)-1, -1, -1):\n",
    "        if x[i] < y:\n",
    "            N = i + 1\n",
    "            break\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    return 100 * (N-1) / len(x) - 50\n",
    "\n",
    "def N_DAY_NARROWER(df, HistLength):\n",
    "\n",
    "    diff1 = df['high'] - df['low']\n",
    "    diff2 = df['high'] - df['close'].shift(1)\n",
    "    diff3 = df['close'].shift(1) - df['low']\n",
    "\n",
    "    true_range = np.max(\n",
    "        np.array(\n",
    "            [\n",
    "                diff1.values, \n",
    "                diff2.values, \n",
    "                diff3.values\n",
    "             ]\n",
    "        ), \n",
    "    axis=0\n",
    "    )\n",
    "\n",
    "    true_range = pd.Series(true_range, index=df.index)\n",
    "\n",
    "    # list_of_values = []\n",
    "    # true_range.rolling(window=HistLength, closed='left').apply(\n",
    "    #     lambda x: list_of_values.append(x.values) or 0, \n",
    "    #     raw=False\n",
    "    # )\n",
    "    list_of_values = get_hist_values(x=true_range.values, length=HistLength)\n",
    "\n",
    "    temp_df = pd.Series(list_of_values, index=df.iloc[HistLength-1:].index)\n",
    "    temp_df = temp_df.to_frame()\n",
    "    temp_df.columns = ['tr_list']\n",
    "    temp_df['tr'] = true_range.iloc[HistLength+1:]\n",
    "\n",
    "    df_stat = temp_df.apply(lambda x: get_n_day_narrower(x=x['tr_list'], y=x['tr']), axis=1)\n",
    "    df_stat = df_stat.to_frame()\n",
    "    df_stat.columns = ['N_Day_Narrower']\n",
    "    return df_stat\n",
    "\n",
    "@njit\n",
    "def get_n_day_wider(x, y):\n",
    "\n",
    "    N = len(x) + 1\n",
    "\n",
    "    for i in prange(len(x)-1, -1, -1):\n",
    "        if x[i] > y:\n",
    "            N = i + 1\n",
    "            break\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    return 100 * (N-1) / len(x) - 50\n",
    "\n",
    "def N_DAY_WIDER(df, HistLength):\n",
    "\n",
    "    diff1 = df['high'] - df['low']\n",
    "    diff2 = df['high'] - df['close'].shift(1)\n",
    "    diff3 = df['close'].shift(1) - df['low']\n",
    "\n",
    "    true_range = np.max(\n",
    "        np.array(\n",
    "            [\n",
    "                diff1.values, \n",
    "                diff2.values, \n",
    "                diff3.values\n",
    "             ]\n",
    "        ), \n",
    "    axis=0\n",
    "    )\n",
    "\n",
    "    true_range = pd.Series(true_range, index=df.index)\n",
    "\n",
    "    # list_of_values = []\n",
    "    # true_range.rolling(window=HistLength, closed='left').apply(\n",
    "    #     lambda x: list_of_values.append(x.values) or 0, \n",
    "    #     raw=False\n",
    "    # )\n",
    "    list_of_values = get_hist_values(x=true_range.values, length=HistLength)\n",
    "\n",
    "    temp_df = pd.Series(list_of_values, index=df.iloc[HistLength-1:].index)\n",
    "    temp_df = temp_df.to_frame()\n",
    "    temp_df.columns = ['tr_list']\n",
    "    temp_df['tr'] = true_range.iloc[HistLength+1:]\n",
    "\n",
    "    df_stat = temp_df.apply(lambda x: get_n_day_wider(x=x['tr_list'], y=x['tr']), axis=1)\n",
    "    df_stat = df_stat.to_frame()\n",
    "    df_stat.columns = ['N_Day_Wider']\n",
    "    return df_stat\n",
    "\n",
    "# Creating functions for basic price distribution statistics\n",
    "\n",
    "def PRICE_SKEWNESS(df, HistLength, Multiplier):\n",
    "\n",
    "    short_skew = df['close'].rolling(window=HistLength).skew()\n",
    "\n",
    "    if Multiplier > 1:\n",
    "        long_skew = df['close'].rolling(window=HistLength*Multiplier).skew()\n",
    "        df_stat = short_skew / long_skew\n",
    "    else:\n",
    "        df_stat = short_skew\n",
    "\n",
    "    df_stat = df_stat.to_frame()\n",
    "    df_stat.columns = ['Price_Skewness']\n",
    "    return df_stat\n",
    "\n",
    "def CHANGE_SKEWNESS(df, HistLength, Multiplier):\n",
    "\n",
    "    price_change = df['close'] / df['close'].shift(1)\n",
    "\n",
    "    short_skew = price_change.rolling(window=HistLength).skew()\n",
    "\n",
    "    if Multiplier > 1:\n",
    "        long_skew = price_change.rolling(window=HistLength*Multiplier).skew()\n",
    "        df_stat = short_skew / long_skew\n",
    "    else:\n",
    "        df_stat = short_skew\n",
    "\n",
    "    df_stat = df_stat.to_frame()\n",
    "    df_stat.columns = ['Change_Skewness']\n",
    "    return df_stat\n",
    "\n",
    "def PRICE_KURTOSIS(df, HistLength, Multiplier):\n",
    "\n",
    "    short_kurtosis = df['close'].rolling(window=HistLength).kurt()\n",
    "\n",
    "    if Multiplier > 1:\n",
    "        long_kurtosis = df['close'].rolling(window=HistLength*Multiplier).kurt()\n",
    "        df_stat = short_kurtosis / long_kurtosis\n",
    "    else:\n",
    "        df_stat = short_kurtosis\n",
    "\n",
    "    df_stat = df_stat.to_frame()\n",
    "    df_stat.columns = ['Price_Kurtosis']\n",
    "    return df_stat\n",
    "\n",
    "def CHANGE_KURTOSIS(df, HistLength, Multiplier):\n",
    "\n",
    "    price_change = df['close'] / df['close'].shift(1)\n",
    "\n",
    "    short_kurtosis = price_change.rolling(window=HistLength).kurt()\n",
    "\n",
    "    if Multiplier > 1:\n",
    "        long_kurtosis = price_change.rolling(window=HistLength*Multiplier).kurt()\n",
    "        df_stat = short_kurtosis / long_kurtosis\n",
    "    else:\n",
    "        df_stat = short_kurtosis\n",
    "\n",
    "    df_stat = df_stat.to_frame()\n",
    "    df_stat.columns = ['Change_Kurtosis']\n",
    "    return df_stat\n",
    "\n",
    "def DELTA_PRICE_SKEWNESS(df, HistLen, Multiplier, DeltaLen):\n",
    "\n",
    "    current_ps = PRICE_SKEWNESS(df, HistLen, Multiplier)\n",
    "    lag_ps = PRICE_SKEWNESS(df=df.shift(DeltaLen), HistLength=HistLen, Multiplier=Multiplier)\n",
    "    df_stat = current_ps - lag_ps\n",
    "    df_stat.columns = ['Delta_Price_Skewness']\n",
    "    return df_stat\n",
    "\n",
    "def DELTA_CHANGE_SKEWNESS(df, HistLen, Multiplier, DeltaLen):\n",
    "\n",
    "    current_cs = CHANGE_SKEWNESS(df, HistLen, Multiplier)\n",
    "    lag_cs = CHANGE_SKEWNESS(df=df.shift(DeltaLen), HistLength=HistLen, Multiplier=Multiplier)\n",
    "    df_stat = current_cs - lag_cs\n",
    "    df_stat.columns = ['Delta_Change_Skewness']\n",
    "    return df_stat\n",
    "\n",
    "def DELTA_PRICE_KURTOSIS(df, HistLen, Multiplier, DeltaLen):\n",
    "\n",
    "    current_pk = PRICE_KURTOSIS(df, HistLen, Multiplier)\n",
    "    lag_pk = PRICE_KURTOSIS(df=df.shift(DeltaLen), HistLength=HistLen, Multiplier=Multiplier)\n",
    "    df_stat = current_pk - lag_pk\n",
    "    df_stat.columns = ['Delta_Price_Kurtosis']\n",
    "    return df_stat\n",
    "\n",
    "def DELTA_CHANGE_KURTOSIS(df, HistLen, Multiplier, DeltaLen):\n",
    "\n",
    "    current_ck = CHANGE_KURTOSIS(df, HistLen, Multiplier)\n",
    "    lag_ck = CHANGE_KURTOSIS(df=df.shift(DeltaLen), HistLength=HistLen, Multiplier=Multiplier)\n",
    "    df_stat = current_ck - lag_ck\n",
    "    df_stat.columns = ['Delta_Change_Kurtosis']\n",
    "    return df_stat\n",
    "\n",
    "# Creating functions for indicators/variables that significantly involve volume\n",
    "\n",
    "def VOLUME_MOMENTUM(df, HistLength, Multiplier):\n",
    "\n",
    "    short_ma = df['volume'].rolling(window=HistLength).mean()\n",
    "    long_ma = df['volume'].rolling(window=HistLength*Multiplier).mean()\n",
    "    df_stat = short_ma / long_ma\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Volume_Momentum']\n",
    "    return df_stat\n",
    "\n",
    "def DELTA_VOLUME_MOMENTUM(df, HistLen, Multiplier, DeltaLen):\n",
    "\n",
    "    current_vm = CHANGE_KURTOSIS(df, HistLen, Multiplier)\n",
    "    lag_vm = CHANGE_KURTOSIS(df=df.shift(DeltaLen), HistLength=HistLen, Multiplier=Multiplier)\n",
    "    df_stat = current_vm - lag_vm\n",
    "    period = HistLen\n",
    "    x_median = df_stat.iloc[-period:]['Change_Kurtosis'].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:]['Change_Kurtosis'].values)\n",
    "    df_stat = pd.Series(df_stat.values.reshape(-1, ), index=df_stat.index)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Delta_Volume_Momentum']\n",
    "    return df_stat\n",
    "\n",
    "def VOLUME_WEIGHTED_MA_OVER_MA(df, HistLength):\n",
    "\n",
    "    volume_sum = df['volume'].rolling(window=HistLength).sum()\n",
    "    vp = df['close'] * df['volume']\n",
    "    vp_sum = vp.rolling(window=HistLength).sum()\n",
    "    ma_vw = vp_sum / volume_sum\n",
    "\n",
    "    simple_ma = df['close'].rolling(window=HistLength).mean()\n",
    "\n",
    "    df_stat = np.log(ma_vw / simple_ma)\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['VWMOM']\n",
    "    return df_stat\n",
    "\n",
    "def DIFF_VOLUME_WEIGHTED_MA_OVER_MA(df, ShortDist, LongDist):\n",
    "\n",
    "    short_vwmom = VOLUME_WEIGHTED_MA_OVER_MA(df, HistLength=ShortDist)\n",
    "    long_vwmom = VOLUME_WEIGHTED_MA_OVER_MA(df, HistLength=LongDist)\n",
    "    df_stat = short_vwmom - long_vwmom\n",
    "    period = ShortDist\n",
    "    x_median = df_stat.iloc[-period:]['VWMOM'].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:]['VWMOM'].values)\n",
    "    df_stat = pd.Series(df_stat.values.reshape(-1, ), index=df_stat.index)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Diff_VWMOM']\n",
    "    return df_stat\n",
    "\n",
    "def get_ls_slope2(x, y):\n",
    "    result = np.polyfit(x, y, 1)\n",
    "    return result[0]\n",
    "\n",
    "@njit\n",
    "def get_hist_values(x, length):\n",
    "\n",
    "    hist_values = []\n",
    "\n",
    "    for i in prange(length, len(x)+1):\n",
    "\n",
    "        hist_values.append(x[i-length: i])\n",
    "\n",
    "    return hist_values\n",
    "\n",
    "def PRICE_VOLUME_FIT(df, HistLength):\n",
    "\n",
    "    log_price = np.log(df['close'])\n",
    "\n",
    "    log_volume = np.log(df['volume']).replace(-np.inf, 0)\n",
    "\n",
    "    log_array = np.vstack([log_price.values, log_volume.values]).T\n",
    "    log_df = pd.DataFrame(log_array, columns=['log_price', 'log_volume'], index=log_price.index)\n",
    "    log_df.dropna(inplace=True)\n",
    "\n",
    "    list_of_log_price = get_hist_values(x=log_df['log_price'].values, length=HistLength)\n",
    "\n",
    "    list_of_log_volume = get_hist_values(x=log_df['log_volume'].values, length=HistLength)\n",
    "\n",
    "    index_length = len(list_of_log_volume)\n",
    "    temp_df = pd.Series(list_of_log_volume, index=df.iloc[-index_length:].index)\n",
    "    temp_df = temp_df.to_frame()\n",
    "    temp_df.columns = ['log_volume']\n",
    "    temp_df['log_price'] = list_of_log_price\n",
    "\n",
    "    temp_df['slope'] = temp_df.apply(lambda x: get_ls_slope2(x=x['log_volume'], y=x['log_price']), axis=1)\n",
    "\n",
    "    df_stat = temp_df['slope']\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Price_Volume_Fit']\n",
    "    return df_stat\n",
    "\n",
    "def DIFF_PRICE_VOLUME_FIT(df, ShortDist, LongDist):\n",
    "\n",
    "    short_pvf = PRICE_VOLUME_FIT(df, HistLength=ShortDist)\n",
    "    long_pvf = PRICE_VOLUME_FIT(df, HistLength=LongDist)\n",
    "    df_stat = short_pvf - long_pvf\n",
    "    period = ShortDist\n",
    "    x_median = df_stat.iloc[-period:]['Price_Volume_Fit'].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:]['Price_Volume_Fit'].values)\n",
    "    df_stat = pd.Series(df_stat.values.reshape(-1, ), index=df_stat.index)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Diff_PVF']\n",
    "    return df_stat\n",
    "\n",
    "def DELTA_PRICE_VOLUME_FIT(df, HistLength, DeltaDist):\n",
    "\n",
    "    current_pvf = PRICE_VOLUME_FIT(df, HistLength)\n",
    "    lag_pvf = PRICE_VOLUME_FIT(df=df.shift(DeltaDist), HistLength=HistLength)\n",
    "    df_stat = current_pvf - lag_pvf\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:]['Price_Volume_Fit'].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:]['Price_Volume_Fit'].values)\n",
    "    df_stat = pd.Series(df_stat.values.reshape(-1, ), index=df_stat.index)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Delta_PVF']\n",
    "    return df_stat\n",
    "\n",
    "def ON_BALANCE_VOLUME(df, HistLength):\n",
    "\n",
    "    bool1 = (df['close'] > df['close'].shift(1)).astype(int)\n",
    "    volume1 = df['volume'] * bool1\n",
    "    signed_volume1 = volume1.rolling(window=HistLength).sum()\n",
    "\n",
    "    bool2 = (df['close'] < df['close'].shift(1)).astype(int)\n",
    "    volume2 = df['volume'] * bool2\n",
    "    signed_volume2 = volume2.rolling(window=HistLength).sum()\n",
    "\n",
    "    signed_volume = signed_volume1 - signed_volume2\n",
    "\n",
    "    total_volume = df['volume'].rolling(window=HistLength).sum()\n",
    "\n",
    "    df_stat = signed_volume / total_volume\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = pd.Series(df_stat.values.reshape(-1, ), index=df_stat.index)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['On_Balance_Volume']\n",
    "    return df_stat\n",
    "\n",
    "def DELTA_ON_BALANCE_VOLUME(df, HistLength, DeltaDist):\n",
    "\n",
    "    current_obv = ON_BALANCE_VOLUME(df, HistLength)\n",
    "    lag_obv = ON_BALANCE_VOLUME(df=df.shift(DeltaDist), HistLength=HistLength)\n",
    "    df_stat = current_obv - lag_obv\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:]['On_Balance_Volume'].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:]['On_Balance_Volume'].values)\n",
    "    df_stat = pd.Series(df_stat.values.reshape(-1, ), index=df_stat.index)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Delta_OBV']\n",
    "    return df_stat\n",
    "\n",
    "def POSITIVE_VOLUME_INDICATOR(df, HistLength):\n",
    "\n",
    "    price_change = (df['close'] - df['close'].shift(1)) / df['close'].shift(1)\n",
    "    is_increased = (df['volume'] > df['volume'].shift(1))\n",
    "    price_change = price_change * is_increased\n",
    "    df_stat = price_change.rolling(window=HistLength).mean()\n",
    "\n",
    "    std_length = np.max([2*HistLength, 250])\n",
    "    std_price_change = price_change.rolling(window=std_length).std()\n",
    "    df_stat = df_stat / std_price_change\n",
    "\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Positive_Volume']\n",
    "    return df_stat\n",
    "\n",
    "def DELTA_POSITIVE_VOLUME_INDICATOR(df, HistLength, DeltaDist):\n",
    "\n",
    "    current_pv = POSITIVE_VOLUME_INDICATOR(df, HistLength)\n",
    "    lag_pv = POSITIVE_VOLUME_INDICATOR(df=df.shift(DeltaDist), HistLength=HistLength)\n",
    "    df_stat = current_pv - lag_pv\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:]['Positive_Volume'].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:]['Positive_Volume'].values)\n",
    "    df_stat = pd.Series(df_stat.values.reshape(-1, ), index=df_stat.index)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Delta_Positive_Volume']\n",
    "    return df_stat\n",
    "\n",
    "def NEGATIVE_VOLUME_INDICATOR(df, HistLength):\n",
    "\n",
    "    price_change = (df['close'] - df['close'].shift(1)) / df['close'].shift(1)\n",
    "    is_decreased = (df['volume'] < df['volume'].shift(1))\n",
    "    price_change = price_change * is_decreased\n",
    "    df_stat = price_change.rolling(window=HistLength).mean()\n",
    "\n",
    "    std_length = np.max([2*HistLength, 250])\n",
    "    std_price_change = price_change.rolling(window=std_length).std()\n",
    "    df_stat = df_stat / std_price_change\n",
    "\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Negative_Volume']\n",
    "    return df_stat\n",
    "\n",
    "def DELTA_NEGATIVE_VOLUME_INDICATOR(df, HistLength, DeltaDist):\n",
    "\n",
    "    current_pv = NEGATIVE_VOLUME_INDICATOR(df, HistLength)\n",
    "    lag_pv = NEGATIVE_VOLUME_INDICATOR(df=df.shift(DeltaDist), HistLength=HistLength)\n",
    "    df_stat = current_pv - lag_pv\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:]['Negative_Volume'].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:]['Negative_Volume'].values)\n",
    "    df_stat = pd.Series(df_stat.values.reshape(-1, ), index=df_stat.index)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Delta_Negative_Volume']\n",
    "    return df_stat\n",
    "\n",
    "def PRODUCT_PRICE_VOLUME(df, HistLength):\n",
    "\n",
    "    median_volume = df['volume'].rolling(window=250).median()\n",
    "    normalized_volume = df['volume'] / median_volume\n",
    "\n",
    "    price_changes = np.log(df['close']/df['close'].shift(1))\n",
    "    median_price_changes = price_changes.rolling(window=250).median()\n",
    "    quantile25 = price_changes.rolling(window=250).quantile(0.25)\n",
    "    quantile75 = price_changes.rolling(window=250).quantile(0.75)\n",
    "    iqr_price_changes = quantile75 - quantile25\n",
    "    normalized_price_changes = (price_changes - median_price_changes) / iqr_price_changes\n",
    "\n",
    "    precursor = normalized_volume * normalized_price_changes\n",
    "\n",
    "    df_stat = precursor.rolling(window=HistLength).mean()\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Product_Price_Volume']\n",
    "    return df_stat\n",
    "\n",
    "def SUM_PRICE_VOLUME(df, HistLength):\n",
    "\n",
    "    median_volume = df['volume'].rolling(window=250).median()\n",
    "    normalized_volume = df['volume'] / median_volume\n",
    "\n",
    "    price_changes = np.log(df['close']/df['close'].shift(1))\n",
    "    median_price_changes = price_changes.rolling(window=250).median()\n",
    "    quantile25 = price_changes.rolling(window=250).quantile(0.25)\n",
    "    quantile75 = price_changes.rolling(window=250).quantile(0.75)\n",
    "    iqr_price_changes = quantile75 - quantile25\n",
    "    normalized_price_changes = (price_changes - median_price_changes) / iqr_price_changes\n",
    "\n",
    "    sum_sign = np.array(list(map(lambda x: -1 if x<0 else 1, normalized_price_changes)))\n",
    "    precursor = (normalized_volume + np.abs(normalized_price_changes)) * sum_sign\n",
    "\n",
    "    df_stat = precursor.rolling(window=HistLength).mean()\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Sum_Price_Volume']\n",
    "    return df_stat\n",
    "\n",
    "def DELTA_PRODUCT_PRICE_VOLUME(df, HistLen, DeltaDist):\n",
    "\n",
    "    current_ppv = PRODUCT_PRICE_VOLUME(df, HistLen)\n",
    "    lag_ppv = PRODUCT_PRICE_VOLUME(df=df.shift(DeltaDist), HistLength=HistLen)\n",
    "    df_stat = current_ppv - lag_ppv\n",
    "    period = HistLen\n",
    "    x_median = df_stat.iloc[-period:]['Product_Price_Volume'].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:]['Product_Price_Volume'].values)\n",
    "    df_stat = pd.Series(df_stat.values.reshape(-1, ), index=df_stat.index)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Delta_PPV']\n",
    "    return df_stat\n",
    "\n",
    "def DELTA_SUM_PRICE_VOLUME(df, HistLen, DeltaDist):\n",
    "\n",
    "    current_ppv = SUM_PRICE_VOLUME(df, HistLen)\n",
    "    lag_ppv = SUM_PRICE_VOLUME(df=df.shift(DeltaDist), HistLength=HistLen)\n",
    "    df_stat = current_ppv - lag_ppv\n",
    "    period = HistLen\n",
    "    x_median = df_stat.iloc[-period:]['Sum_Price_Volume'].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:]['Sum_Price_Volume'].values)\n",
    "    df_stat = pd.Series(df_stat.values.reshape(-1, ), index=df_stat.index)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Delta_SPV']\n",
    "    return df_stat\n",
    "\n",
    "# Creating functions for entropy and mutual information indicators/variables\n",
    "\n",
    "@njit\n",
    "def get_entropy(x):\n",
    "\n",
    "    entropy = 0\n",
    "\n",
    "    for i in prange(len(x)):\n",
    "        p = x[i] / np.sum(x)\n",
    "        entropy += -p * np.log2(p)\n",
    "\n",
    "    return entropy\n",
    "\n",
    "def PRICE_ENTROPY(df, WordLength):\n",
    "\n",
    "    length = 10 * (2 ** WordLength)\n",
    "\n",
    "    bool_list = []\n",
    "\n",
    "    for i in range(length):\n",
    "        price_bool1 = ((df['close'].shift(i) > df['close'].shift(i+1)).astype(int)).astype(str)\n",
    "        price_bool2 = ((df['close'].shift(i+1) > df['close'].shift(i+2)).astype(int)).astype(str)\n",
    "        price_bool = price_bool1 + price_bool2\n",
    "\n",
    "        bool_list.append(price_bool.values)\n",
    "\n",
    "        del price_bool1, price_bool2, price_bool\n",
    "        gc.collect()\n",
    "\n",
    "    bool_list = np.array(bool_list).T.tolist()\n",
    "\n",
    "    temp_df = pd.Series(bool_list, index=df.index).apply(lambda x: np.unique(x, return_counts=True)[1])\n",
    "    df_stat = temp_df.apply(get_entropy)\n",
    "    period = length\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Price_Entropy']\n",
    "    return df_stat\n",
    "\n",
    "def VOLUME_ENTROPY(df, WordLength):\n",
    "\n",
    "    length = 10 * (2 ** WordLength)\n",
    "\n",
    "    bool_list = []\n",
    "\n",
    "    for i in range(length):\n",
    "        volume_bool1 = ((df['volume'].shift(i) > df['volume'].shift(i+1)).astype(int)).astype(str)\n",
    "        volume_bool2 = ((df['volume'].shift(i+1) > df['volume'].shift(i+2)).astype(int)).astype(str)\n",
    "        volume_bool = volume_bool1 + volume_bool2\n",
    "\n",
    "        bool_list.append(volume_bool.values)\n",
    "\n",
    "        del volume_bool1, volume_bool2, volume_bool\n",
    "        gc.collect()  \n",
    "\n",
    "    bool_list = np.array(bool_list).T.tolist()\n",
    "\n",
    "    temp_df = pd.Series(bool_list, index=df.index).apply(lambda x: np.unique(x, return_counts=True)[1])\n",
    "    df_stat = temp_df.apply(get_entropy)\n",
    "    period = length\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Volume_Entropy']\n",
    "    return df_stat\n",
    "\n",
    "@njit\n",
    "def get_mi_data(x, length):\n",
    "    \n",
    "    xc = []\n",
    "    x1 = []\n",
    "    x2 = []\n",
    "    x3 = []\n",
    "\n",
    "    for i in prange(length, len(x)):\n",
    "\n",
    "        xc.append(x[i-length:i])\n",
    "        x1.append(x[i-length:i-1])\n",
    "        x2.append(x[i-length:i-2])\n",
    "        x3.append(x[i-length:i-3])\n",
    "\n",
    "    return xc, x1, x2, x3\n",
    "\n",
    "@njit\n",
    "def get_mi(c, x, y, z):\n",
    "\n",
    "    bool1 = np.where(c[1:] > x, 1, 0)\n",
    "    bool2 = np.where(x[1:] > y, 1, 0)\n",
    "    bool3 = np.where(y[1:] > z, 1, 0)\n",
    "\n",
    "    var23 = np.zeros(len(bool3), dtype='int')\n",
    "    var123 = np.zeros(len(bool3), dtype='int')\n",
    "\n",
    "    for i in prange(len(bool3)):\n",
    "\n",
    "        if bool2[i+1] == 0 and bool3[i] == 0:\n",
    "\n",
    "            var23[i] = 1\n",
    "\n",
    "            if bool1[i+3] == 0:\n",
    "                var123[i] = 1\n",
    "            else:\n",
    "                var123[i] = 2\n",
    "\n",
    "        elif bool2[i+1] == 1 and bool3[i] == 0:\n",
    "\n",
    "            var23[i] = 2\n",
    "\n",
    "            if bool1[i+3] == 0:\n",
    "                var123[i] = 3\n",
    "            else:\n",
    "                var123[i] = 4\n",
    "\n",
    "        elif bool2[i+1] == 0 and bool3[i] == 1:\n",
    "\n",
    "            var23[i] = 3\n",
    "\n",
    "            if bool1[i+3] == 0:\n",
    "                var123[i] = 5\n",
    "            else:\n",
    "                var123[i] = 6\n",
    "\n",
    "        else:\n",
    "\n",
    "            var23[i] = 4\n",
    "\n",
    "            if bool1[i+3] == 0:\n",
    "                var123[i] = 7\n",
    "            else:\n",
    "                var123[i] = 8\n",
    "    \n",
    "    prob1 = np.zeros(2)\n",
    "    for i in prange(2):\n",
    "        prob1[i] = np.sum(np.where(bool1==i, 1, 0))/ len(bool1)\n",
    "\n",
    "    prob23 = np.zeros(4)\n",
    "    for i in prange(1, 5):\n",
    "        prob23[i] = np.sum(np.where(var23==i, 1, 0))/ len(var23)\n",
    "\n",
    "    prob123 = np.zeros(8)\n",
    "    for i in prange(1, 9):\n",
    "        prob123[i] = np.sum(np.where(var123==i, 1, 0))/ len(var123)\n",
    "\n",
    "\n",
    "    mi = 0\n",
    "\n",
    "    for i in prange(2):\n",
    "        for j in prange(2):\n",
    "            for k in prange(2):\n",
    "                \n",
    "                if j == 0 and k == 0:\n",
    "\n",
    "                    py = prob23[0]\n",
    "\n",
    "                    if i == 0:\n",
    "                        pxy = prob123[0]\n",
    "                        px = prob1[0]\n",
    "                    else:\n",
    "                        pxy = prob123[1]\n",
    "                        px = prob1[1]\n",
    "\n",
    "                elif j == 1 and k == 0:\n",
    "\n",
    "                    py = prob23[1]\n",
    "\n",
    "                    if i == 0:\n",
    "                        pxy = prob123[2]\n",
    "                        px = prob1[0]\n",
    "                    else:\n",
    "                        pxy = prob123[3]\n",
    "                        px = prob1[1]\n",
    "\n",
    "                elif j == 0 and k == 1:\n",
    "\n",
    "                    py = prob23[2]\n",
    "\n",
    "                    if i == 0:\n",
    "                        pxy = prob123[4]\n",
    "                        px = prob1[0]\n",
    "                    else:\n",
    "                        pxy = prob123[5]\n",
    "                        px = prob1[1]\n",
    "\n",
    "                else:\n",
    "\n",
    "                    py = prob23[3]\n",
    "\n",
    "                    if i == 0:\n",
    "                        pxy = prob123[6]\n",
    "                        px = prob1[0]\n",
    "                    else:\n",
    "                        pxy = prob123[7]\n",
    "                        px = prob1[1]\n",
    "\n",
    "                if px * py == 0:\n",
    "                    mi += 0\n",
    "                else:\n",
    "                    mi += pxy * np.log(pxy/(px*py))\n",
    "\n",
    "    return mi\n",
    "\n",
    "def PRICE_MUTUAL_INFORMATION(df, WordLength):\n",
    "\n",
    "    length = 10 * (2 ** (1 + WordLength))\n",
    "\n",
    "    xc, x1, x2, x3 = get_mi_data(x=df['close'].values, length=length)\n",
    "    temp_df = pd.Series(xc, index=df.index[length:])\n",
    "    temp_df = temp_df.to_frame()\n",
    "    temp_df.columns = ['price']\n",
    "    temp_df['price_lag1'] = x1\n",
    "    temp_df['price_lag2'] = x2\n",
    "    temp_df['price_lag3'] = x3\n",
    "    df_stat = temp_df.apply(\n",
    "        lambda x: get_mi(\n",
    "            c=x['price'], \n",
    "            x=x['price_lag1'], \n",
    "            y=x['price_lag2'], \n",
    "            z=x['price_lag3']\n",
    "        ), \n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    period = length\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Price_MI']\n",
    "    return df_stat\n",
    "\n",
    "def VOLUME_MUTUAL_INFORMATION(df, WordLength):\n",
    "\n",
    "    length = 10 * (2 ** (1 + WordLength))\n",
    "\n",
    "    xc, x1, x2, x3 = get_mi_data(x=df['volume'].values, length=length)\n",
    "    temp_df = pd.Series(xc, index=df.index[length:])\n",
    "    temp_df = temp_df.to_frame()\n",
    "    temp_df.columns = ['volume']\n",
    "    temp_df['volume_lag1'] = x1\n",
    "    temp_df['volume_lag2'] = x2\n",
    "    temp_df['volume_lag3'] = x3\n",
    "    df_stat = temp_df.apply(\n",
    "        lambda x: get_mi(\n",
    "            c=x['volume'], \n",
    "            x=x['volume_lag1'], \n",
    "            y=x['volume_lag2'], \n",
    "            z=x['volume_lag3']\n",
    "        ), \n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    period = length\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Volume_MI']\n",
    "    return df_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit\n",
    "\n",
    "@njit\n",
    "def merge_pnl(arr1, arr2):\n",
    "    out = np.zeros((len(arr1) + len(arr2)))\n",
    "    idx = 1\n",
    "    for i in range(len(arr1) + len(arr2)):\n",
    "        if i % 2 == 0:\n",
    "            out[i] = arr1[int(i/2)]\n",
    "        else:\n",
    "            out[i] = arr2[i-idx]\n",
    "        idx += 1\n",
    "    return out\n",
    "\n",
    "@njit\n",
    "def get_drawdowns(arr):\n",
    "    drawdowns = np.zeros((len(arr)))\n",
    "    max = arr[0]\n",
    "    for i in range(1, len(drawdowns)-1):\n",
    "        if arr[i-1] > arr[i] and arr[i] < arr[i+1]:\n",
    "            min = arr[i]\n",
    "            drawdowns[i] = max - min\n",
    "        elif arr[i-1] < arr[i] and arr[i] > arr[i+1]:\n",
    "            max = arr[i]\n",
    "    return drawdowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['buy'] = (MA_DIFFERENCE(df=data, ShortLength=9, LongLength=7, Lag=478).values <= df['open'].values.reshape(-1, 1)).astype(int)\n",
    "# df['sell'] = (RSI(df=data, HistLength=9).values + df['high'].values.reshape(-1, 1) >= 0.5).astype(int)\n",
    "# df['signal'] = df['buy'] + df['sell']\n",
    "# df['signal'] = df['signal'].apply(lambda x: 1 if x==1 else 0)\n",
    "# df['sell'] = df['sell'] * (-1)\n",
    "# df['signal'] = df['signal'] * df['sell']\n",
    "# df['signal'] = df['signal'] + df['buy']\n",
    "# df.drop(columns=['buy', 'sell'], inplace=True)\n",
    "\n",
    "# df = df.assign(buy=(df.open.values.reshape(-1, 1) >= df.volume.values.reshape(-1, 1)).astype(int))\n",
    "# df = df.assign(sell=(df.volume.values.reshape(-1, 1) * df.close.values.reshape(-1, 1) <= 8.3).astype(int))\n",
    "# df = df.assign(signal = (df.buy + df.sell).values)\n",
    "# df.signal = df.signal.apply(lambda x: 1 if x==1 else 0)\n",
    "# df.sell = df.sell * (-1)\n",
    "# df.signal = df.signal * df.sell\n",
    "# df.signal = df.signal + df.buy\n",
    "# df.drop(columns=['buy', 'sell'], inplace=True)\n",
    "\n",
    "# df['buy'] = (9.2 <= df['open'].values.reshape(-1, 1)).astype(int)\n",
    "# df['sell'] = (df['high'].values.reshape(-1, 1) // df['open'].values.reshape(-1, 1) >= 9.833).astype(int)\n",
    "# df['signal'] = df['buy'] + df['sell']\n",
    "# df['signal'] = df['signal'].apply(lambda x: 1 if x==1 else 0)\n",
    "# df['sell'] = df['sell'] * (-1)\n",
    "# df['signal'] = df['signal'] * df['sell']\n",
    "# df['signal'] = df['signal'] + df['buy']\n",
    "# df.drop(columns=['buy', 'sell'], inplace=True)\n",
    "\n",
    "df['buy'] = (RSI(df=data, HistLength=10).values < 30).astype(int)\n",
    "df['sell'] = (RSI(df=data, HistLength=10).values > 70).astype(int)\n",
    "# df['buy'] = (RSI(df=data, HistLength=10).values < 20).astype(int)\n",
    "# df['sell'] = (RSI(df=data, HistLength=10).values < 30).astype(int)\n",
    "df['signal'] = df['buy'] + df['sell']\n",
    "df['signal'] = df['signal'].apply(lambda x: 1 if x==1 else 0)\n",
    "df['sell'] = df['sell'] * (-1)\n",
    "df['signal'] = df['signal'] * df['sell']\n",
    "df['signal'] = df['signal'] + df['buy']\n",
    "df.drop(columns=['buy', 'sell'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_idxs = []\n",
    "sell_idxs = []\n",
    "is_buy = 0\n",
    "is_sell = 0\n",
    "for i, row in enumerate(df.itertuples()):\n",
    "    if row.signal == 1 and is_buy == 0:\n",
    "        buy_idxs.append(i+1)\n",
    "        is_buy = 1\n",
    "        is_sell = 0\n",
    "    elif row.signal == -1 and is_sell == 0:\n",
    "        sell_idxs.append(i+1)\n",
    "        is_sell = 1\n",
    "        is_buy = 0\n",
    "if len(buy_idxs) > len(sell_idxs):\n",
    "    buy_idxs = buy_idxs[:-(len(buy_idxs) - len(sell_idxs))]\n",
    "elif len(buy_idxs) < len(sell_idxs):\n",
    "    sell_idxs = sell_idxs[:-(len(sell_idxs) - len(buy_idxs))]\n",
    "if len(buy_idxs) == 0 or len(sell_idxs) == 0:\n",
    "    fitness = -999\n",
    "buy_prices = df[df.index.isin(buy_idxs)].open.values\n",
    "sell_prices = df[df.index.isin(sell_idxs)].open.values\n",
    "if buy_idxs[0] < sell_idxs[0]:\n",
    "    buy_pnl = np.sum(sell_prices - buy_prices)\n",
    "    sell_pnl = np.sum(sell_prices[:-1] - buy_prices[1:])\n",
    "else:\n",
    "    sell_pnl = np.sum(sell_prices - buy_prices)\n",
    "    buy_pnl = np.sum(sell_prices[1:] - buy_prices[:-1])\n",
    "total_pnl = buy_pnl + sell_pnl\n",
    "if buy_idxs[0] < sell_idxs[0]:\n",
    "    buy_arr = sell_prices - buy_prices\n",
    "    sell_arr = sell_prices[:-1] - buy_prices[1:]\n",
    "    all_arr = merge_pnl(buy_arr, sell_arr)\n",
    "else:\n",
    "    sell_arr = sell_prices - buy_prices\n",
    "    buy_arr = sell_prices[1:] - buy_prices[:-1]\n",
    "    all_arr = merge_pnl(sell_arr, buy_arr)\n",
    "equity_curve_arr = np.cumsum(all_arr)\n",
    "drawdowns = get_drawdowns(equity_curve_arr)\n",
    "avg_drawdown = np.sum(drawdowns[drawdowns!=0]) / len(drawdowns[drawdowns!=0])\n",
    "fitness = total_pnl / avg_drawdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.040e+01,  2.130e+01, -1.010e+01,  2.130e+01,  0.000e+00,\n",
       "        2.130e+01,  2.000e+00,  2.130e+01,  1.700e+00,  2.130e+01,\n",
       "       -1.240e+01,  2.130e+01,  1.590e+01,  2.130e+01, -1.780e+01,\n",
       "        2.130e+01,  5.600e+00,  2.130e+01, -2.470e+01,  2.130e+01,\n",
       "        1.460e+01,  2.130e+01,  5.400e+00,  2.130e+01,  1.500e+01,\n",
       "        2.130e+01,  8.600e+00,  2.130e+01,  5.600e+00,  2.130e+01,\n",
       "        1.230e+01,  2.130e+01,  1.350e+01,  2.130e+01,  5.700e+00,\n",
       "        2.130e+01,  2.260e+01,  2.130e+01,  1.360e+01,  2.130e+01,\n",
       "        2.620e+01,  2.130e+01, -7.300e+00,  2.130e+01,  6.500e+00,\n",
       "        2.130e+01, -7.600e+00,  2.130e+01,  1.380e+01,  2.130e+01,\n",
       "       -2.690e+01,  2.130e+01, -1.510e+01,  2.130e+01, -3.300e+00,\n",
       "        2.130e+01,  5.800e+00,  2.130e+01, -1.890e+01,  2.130e+01,\n",
       "       -1.180e+01,  2.130e+01, -4.100e+00,  2.130e+01,  1.240e+01,\n",
       "        2.130e+01,  5.600e+00,  2.130e+01, -1.240e+01,  2.130e+01,\n",
       "       -6.700e+00,  2.130e+01, -3.380e+01,  2.130e+01, -1.000e+01,\n",
       "        2.130e+01, -6.450e+01,  2.130e+01,  2.000e+01,  2.130e+01,\n",
       "        3.000e-01,  2.130e+01, -7.600e+00,  2.130e+01,  1.180e+01,\n",
       "        2.130e+01, -1.450e+01,  2.130e+01,  9.300e+00,  2.130e+01,\n",
       "        5.600e+00,  2.130e+01,  1.100e+00,  2.130e+01,  8.100e+00,\n",
       "        2.130e+01,  8.900e+00,  2.130e+01,  6.400e+00,  2.130e+01,\n",
       "       -2.300e+00,  2.130e+01,  2.000e-01,  2.130e+01, -6.800e+00,\n",
       "        2.130e+01, -3.270e+01,  2.130e+01,  1.000e-01,  2.130e+01,\n",
       "       -1.440e+01,  2.130e+01,  5.400e+00,  2.130e+01,  7.800e+00,\n",
       "        2.130e+01,  1.190e+01,  2.130e+01,  3.110e+01,  2.130e+01,\n",
       "        3.700e+01,  2.130e+01,  2.400e+00,  2.130e+01, -1.370e+01,\n",
       "        2.130e+01, -3.800e+00,  2.130e+01, -1.954e+02,  2.130e+01,\n",
       "        1.010e+01,  2.130e+01, -6.100e+00,  2.130e+01,  9.300e+00,\n",
       "        2.130e+01,  3.570e+01,  2.130e+01,  3.500e+00,  2.130e+01,\n",
       "        1.180e+01,  2.130e+01, -2.900e+00,  2.130e+01, -1.850e+01,\n",
       "        2.130e+01,  2.350e+01,  2.130e+01,  1.100e+00,  2.130e+01,\n",
       "        1.500e+00,  2.130e+01, -1.060e+01,  2.130e+01,  1.300e+01,\n",
       "        2.130e+01,  8.700e+00,  2.130e+01, -5.500e+00,  2.130e+01,\n",
       "        2.000e+00,  2.130e+01,  1.300e+01,  2.130e+01, -9.500e+00,\n",
       "        2.130e+01,  8.000e-01,  2.130e+01,  1.210e+01,  2.130e+01,\n",
       "        3.070e+01,  2.130e+01, -1.590e+01,  2.130e+01,  1.640e+01,\n",
       "        2.130e+01, -6.600e+00,  2.130e+01, -2.100e+00,  2.130e+01,\n",
       "        1.380e+01,  2.130e+01,  5.400e+00,  2.130e+01, -1.580e+01,\n",
       "        2.130e+01, -1.200e+00,  2.130e+01,  1.010e+01,  2.130e+01,\n",
       "       -6.100e+00,  2.130e+01, -7.400e+00,  2.130e+01, -2.900e+00,\n",
       "        2.130e+01,  4.740e+01,  2.130e+01,  6.300e+01,  2.130e+01,\n",
       "       -3.220e+01,  2.130e+01,  1.340e+01])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.523618229678396"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[70,\n",
       " 204,\n",
       " 383,\n",
       " 525,\n",
       " 608,\n",
       " 695,\n",
       " 728,\n",
       " 885,\n",
       " 917,\n",
       " 1078,\n",
       " 1123,\n",
       " 1195,\n",
       " 1228,\n",
       " 1304,\n",
       " 1340,\n",
       " 1360,\n",
       " 1392,\n",
       " 1439,\n",
       " 1534,\n",
       " 1646,\n",
       " 1672,\n",
       " 1797,\n",
       " 1884,\n",
       " 2061,\n",
       " 2130,\n",
       " 2270,\n",
       " 2428,\n",
       " 2517,\n",
       " 2557,\n",
       " 2638,\n",
       " 2765,\n",
       " 2822,\n",
       " 2880,\n",
       " 2970,\n",
       " 3092,\n",
       " 3281,\n",
       " 3383,\n",
       " 3467,\n",
       " 3557,\n",
       " 3609,\n",
       " 3700,\n",
       " 3836,\n",
       " 3941,\n",
       " 4088,\n",
       " 4162,\n",
       " 4199,\n",
       " 4240,\n",
       " 4278,\n",
       " 4342,\n",
       " 4423,\n",
       " 4568,\n",
       " 4683,\n",
       " 4780,\n",
       " 4916,\n",
       " 5005,\n",
       " 5127,\n",
       " 5169,\n",
       " 5219,\n",
       " 5284,\n",
       " 5408,\n",
       " 5527,\n",
       " 5667,\n",
       " 5850,\n",
       " 5957,\n",
       " 6249,\n",
       " 6300,\n",
       " 6410,\n",
       " 6429,\n",
       " 6464,\n",
       " 6662,\n",
       " 6801,\n",
       " 6962,\n",
       " 7036,\n",
       " 7099,\n",
       " 7292,\n",
       " 7334,\n",
       " 7432,\n",
       " 7516,\n",
       " 7581,\n",
       " 7760,\n",
       " 7895,\n",
       " 7973,\n",
       " 8075,\n",
       " 8128,\n",
       " 8169,\n",
       " 8278,\n",
       " 8352,\n",
       " 8436,\n",
       " 8565,\n",
       " 8618,\n",
       " 8677,\n",
       " 8751,\n",
       " 8917,\n",
       " 9075,\n",
       " 9220,\n",
       " 9302,\n",
       " 9373,\n",
       " 9483,\n",
       " 9695,\n",
       " 9720,\n",
       " 9813,\n",
       " 9871]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buy_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15,\n",
       " 121,\n",
       " 347,\n",
       " 494,\n",
       " 569,\n",
       " 650,\n",
       " 711,\n",
       " 800,\n",
       " 897,\n",
       " 972,\n",
       " 1106,\n",
       " 1178,\n",
       " 1206,\n",
       " 1288,\n",
       " 1328,\n",
       " 1353,\n",
       " 1371,\n",
       " 1416,\n",
       " 1525,\n",
       " 1610,\n",
       " 1663,\n",
       " 1706,\n",
       " 1870,\n",
       " 1983,\n",
       " 2100,\n",
       " 2193,\n",
       " 2294,\n",
       " 2477,\n",
       " 2551,\n",
       " 2578,\n",
       " 2674,\n",
       " 2777,\n",
       " 2860,\n",
       " 2945,\n",
       " 3007,\n",
       " 3212,\n",
       " 3289,\n",
       " 3412,\n",
       " 3504,\n",
       " 3571,\n",
       " 3682,\n",
       " 3775,\n",
       " 3929,\n",
       " 3990,\n",
       " 4126,\n",
       " 4179,\n",
       " 4202,\n",
       " 4262,\n",
       " 4303,\n",
       " 4374,\n",
       " 4534,\n",
       " 4635,\n",
       " 4719,\n",
       " 4831,\n",
       " 4978,\n",
       " 5058,\n",
       " 5161,\n",
       " 5209,\n",
       " 5261,\n",
       " 5300,\n",
       " 5474,\n",
       " 5600,\n",
       " 5699,\n",
       " 5888,\n",
       " 6020,\n",
       " 6277,\n",
       " 6310,\n",
       " 6415,\n",
       " 6446,\n",
       " 6628,\n",
       " 6757,\n",
       " 6832,\n",
       " 6997,\n",
       " 7060,\n",
       " 7237,\n",
       " 7303,\n",
       " 7358,\n",
       " 7487,\n",
       " 7565,\n",
       " 7649,\n",
       " 7868,\n",
       " 7958,\n",
       " 7999,\n",
       " 8091,\n",
       " 8149,\n",
       " 8252,\n",
       " 8293,\n",
       " 8425,\n",
       " 8496,\n",
       " 8578,\n",
       " 8664,\n",
       " 8708,\n",
       " 8857,\n",
       " 9011,\n",
       " 9199,\n",
       " 9280,\n",
       " 9321,\n",
       " 9433,\n",
       " 9661,\n",
       " 9710,\n",
       " 9738,\n",
       " 9836]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sell_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202.90000000011423"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_pnl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.523618229678396"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>buy</th>\n",
       "      <th>sell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-30 22:05:00</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>16583.4</td>\n",
       "      <td>16583.4</td>\n",
       "      <td>4741.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-30 22:06:00</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-30 22:07:00</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>16583.4</td>\n",
       "      <td>16583.4</td>\n",
       "      <td>34811.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-30 22:08:00</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-30 22:09:00</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>5783.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime     open     high      low    close   volume  buy  sell\n",
       "0 2022-12-30 22:05:00  16583.5  16583.5  16583.4  16583.4   4741.0    0     0\n",
       "1 2022-12-30 22:06:00  16583.5  16583.5  16583.5  16583.5     22.0    0     0\n",
       "2 2022-12-30 22:07:00  16583.5  16583.5  16583.4  16583.4  34811.0    0     0\n",
       "3 2022-12-30 22:08:00  16583.5  16583.5  16583.5  16583.5     20.0    0     0\n",
       "4 2022-12-30 22:09:00  16583.5  16583.5  16583.5  16583.5   5783.0    0     0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['buy'].sum(), df['sell'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([44.6])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equity_curve_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(np.arange(len(equity_curve_arr)), equity_curve_arr)\n",
    "for i in range(len(drawdowns)):\n",
    "    if drawdowns[i] != 0:\n",
    "        plt.plot(i, equity_curve_arr[i] - 10, marker='^', color='orange')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.874277777777778"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "17547.4 / (60 * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BTC and ETH merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>btc_open</th>\n",
       "      <th>btc_high</th>\n",
       "      <th>btc_low</th>\n",
       "      <th>btc_close</th>\n",
       "      <th>btc_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-09-04 17:50:00</td>\n",
       "      <td>58052.27</td>\n",
       "      <td>58055.91</td>\n",
       "      <td>57961.70</td>\n",
       "      <td>57975.48</td>\n",
       "      <td>6.286958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-09-04 17:51:00</td>\n",
       "      <td>57975.48</td>\n",
       "      <td>58014.30</td>\n",
       "      <td>57945.01</td>\n",
       "      <td>57948.03</td>\n",
       "      <td>13.541664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-09-04 17:52:00</td>\n",
       "      <td>57948.03</td>\n",
       "      <td>57948.03</td>\n",
       "      <td>57888.06</td>\n",
       "      <td>57892.97</td>\n",
       "      <td>11.412409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-09-04 17:53:00</td>\n",
       "      <td>57889.36</td>\n",
       "      <td>57898.18</td>\n",
       "      <td>57836.55</td>\n",
       "      <td>57857.49</td>\n",
       "      <td>6.163645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-09-04 17:54:00</td>\n",
       "      <td>57857.51</td>\n",
       "      <td>57915.60</td>\n",
       "      <td>57857.51</td>\n",
       "      <td>57912.29</td>\n",
       "      <td>8.040556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime  btc_open  btc_high   btc_low  btc_close  btc_volume\n",
       "0 2024-09-04 17:50:00  58052.27  58055.91  57961.70   57975.48    6.286958\n",
       "1 2024-09-04 17:51:00  57975.48  58014.30  57945.01   57948.03   13.541664\n",
       "2 2024-09-04 17:52:00  57948.03  57948.03  57888.06   57892.97   11.412409\n",
       "3 2024-09-04 17:53:00  57889.36  57898.18  57836.55   57857.49    6.163645\n",
       "4 2024-09-04 17:54:00  57857.51  57915.60  57857.51   57912.29    8.040556"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_btc = pd.read_csv(Path(r'C:/\\Users/\\vchar/\\OneDrive/\\Desktop/\\ML Projects/\\Upwork/\\AlgoT_ML_Dev/\\GrammarEvolution/\\PonyGE2/\\datasets/\\BTC-1m.csv'))\n",
    "# df_btc = pd.read_csv('/kaggle/input/btcusd-test/BTCUSD_ohlcv.csv')\n",
    "df_btc['datetime'] = pd.to_datetime(df_btc['datetime'])\n",
    "df_btc = df_btc.iloc[-10000:]\n",
    "df_btc.sort_values('datetime', ascending=True, inplace=True)\n",
    "df_btc.reset_index(inplace=True, drop=True)\n",
    "df_btc.rename(\n",
    "    columns={\n",
    "        'open': 'btc_open', \n",
    "        'close': 'btc_close', \n",
    "        'low': 'btc_low', \n",
    "        'high': 'btc_high', \n",
    "        'volume': 'btc_volume'\n",
    "    },\n",
    "    inplace=True\n",
    ")\n",
    "df_btc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>btc_open</th>\n",
       "      <th>btc_high</th>\n",
       "      <th>btc_low</th>\n",
       "      <th>btc_close</th>\n",
       "      <th>btc_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2024-09-11 16:25:00</td>\n",
       "      <td>56864.38</td>\n",
       "      <td>56923.75</td>\n",
       "      <td>56847.32</td>\n",
       "      <td>56903.83</td>\n",
       "      <td>12.777984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>2024-09-11 16:26:00</td>\n",
       "      <td>56904.37</td>\n",
       "      <td>56916.37</td>\n",
       "      <td>56788.22</td>\n",
       "      <td>56808.40</td>\n",
       "      <td>10.192957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>2024-09-11 16:27:00</td>\n",
       "      <td>56804.54</td>\n",
       "      <td>56821.79</td>\n",
       "      <td>56787.89</td>\n",
       "      <td>56798.19</td>\n",
       "      <td>2.912109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>2024-09-11 16:28:00</td>\n",
       "      <td>56798.19</td>\n",
       "      <td>56831.83</td>\n",
       "      <td>56793.29</td>\n",
       "      <td>56830.72</td>\n",
       "      <td>3.706732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>2024-09-11 16:29:00</td>\n",
       "      <td>56828.08</td>\n",
       "      <td>56864.97</td>\n",
       "      <td>56828.08</td>\n",
       "      <td>56848.40</td>\n",
       "      <td>3.865301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                datetime  btc_open  btc_high   btc_low  btc_close  btc_volume\n",
       "9995 2024-09-11 16:25:00  56864.38  56923.75  56847.32   56903.83   12.777984\n",
       "9996 2024-09-11 16:26:00  56904.37  56916.37  56788.22   56808.40   10.192957\n",
       "9997 2024-09-11 16:27:00  56804.54  56821.79  56787.89   56798.19    2.912109\n",
       "9998 2024-09-11 16:28:00  56798.19  56831.83  56793.29   56830.72    3.706732\n",
       "9999 2024-09-11 16:29:00  56828.08  56864.97  56828.08   56848.40    3.865301"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_btc.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>eth_open</th>\n",
       "      <th>eth_high</th>\n",
       "      <th>eth_low</th>\n",
       "      <th>eth_close</th>\n",
       "      <th>eth_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-09-07 14:22:00</td>\n",
       "      <td>2295.48</td>\n",
       "      <td>2295.48</td>\n",
       "      <td>2292.22</td>\n",
       "      <td>2292.22</td>\n",
       "      <td>8.133025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-09-07 14:23:00</td>\n",
       "      <td>2292.23</td>\n",
       "      <td>2293.17</td>\n",
       "      <td>2291.09</td>\n",
       "      <td>2292.84</td>\n",
       "      <td>18.279947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-09-07 14:24:00</td>\n",
       "      <td>2292.75</td>\n",
       "      <td>2293.33</td>\n",
       "      <td>2291.55</td>\n",
       "      <td>2292.98</td>\n",
       "      <td>12.682892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-09-07 14:25:00</td>\n",
       "      <td>2292.98</td>\n",
       "      <td>2293.07</td>\n",
       "      <td>2291.24</td>\n",
       "      <td>2292.00</td>\n",
       "      <td>29.546565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-09-07 14:26:00</td>\n",
       "      <td>2291.81</td>\n",
       "      <td>2294.84</td>\n",
       "      <td>2291.80</td>\n",
       "      <td>2294.80</td>\n",
       "      <td>7.415414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime  eth_open  eth_high  eth_low  eth_close  eth_volume\n",
       "0 2024-09-07 14:22:00   2295.48   2295.48  2292.22    2292.22    8.133025\n",
       "1 2024-09-07 14:23:00   2292.23   2293.17  2291.09    2292.84   18.279947\n",
       "2 2024-09-07 14:24:00   2292.75   2293.33  2291.55    2292.98   12.682892\n",
       "3 2024-09-07 14:25:00   2292.98   2293.07  2291.24    2292.00   29.546565\n",
       "4 2024-09-07 14:26:00   2291.81   2294.84  2291.80    2294.80    7.415414"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eth = pd.read_csv(Path(r'C:/\\Users/\\vchar/\\OneDrive/\\Desktop/\\ML Projects/\\Upwork/\\AlgoT_ML_Dev/\\GrammarEvolution/\\PonyGE2/\\datasets/\\ETH-1m.csv'))\n",
    "# df_eth = pd.read_csv('/kaggle/input/btcusd-test/BTCUSD_ohlcv.csv')\n",
    "df_eth['datetime'] = pd.to_datetime(df_eth['datetime'])\n",
    "df_eth = df_eth.iloc[-10000:]\n",
    "df_eth.sort_values('datetime', ascending=True, inplace=True)\n",
    "df_eth.reset_index(inplace=True, drop=True)\n",
    "df_eth.rename(\n",
    "    columns={\n",
    "        'open': 'eth_open', \n",
    "        'close': 'eth_close', \n",
    "        'low': 'eth_low', \n",
    "        'high': 'eth_high', \n",
    "        'volume': 'eth_volume'\n",
    "    },\n",
    "    inplace=True\n",
    ")\n",
    "df_eth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>eth_open</th>\n",
       "      <th>eth_high</th>\n",
       "      <th>eth_low</th>\n",
       "      <th>eth_close</th>\n",
       "      <th>eth_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2024-09-14 12:57:00</td>\n",
       "      <td>2421.30</td>\n",
       "      <td>2421.45</td>\n",
       "      <td>2420.28</td>\n",
       "      <td>2421.45</td>\n",
       "      <td>37.802834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>2024-09-14 12:58:00</td>\n",
       "      <td>2421.39</td>\n",
       "      <td>2421.44</td>\n",
       "      <td>2421.02</td>\n",
       "      <td>2421.24</td>\n",
       "      <td>3.580702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>2024-09-14 12:59:00</td>\n",
       "      <td>2421.24</td>\n",
       "      <td>2421.70</td>\n",
       "      <td>2421.12</td>\n",
       "      <td>2421.44</td>\n",
       "      <td>15.611558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>2024-09-14 13:00:00</td>\n",
       "      <td>2421.46</td>\n",
       "      <td>2421.52</td>\n",
       "      <td>2420.57</td>\n",
       "      <td>2421.40</td>\n",
       "      <td>10.753724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>2024-09-14 13:01:00</td>\n",
       "      <td>2421.26</td>\n",
       "      <td>2421.29</td>\n",
       "      <td>2420.61</td>\n",
       "      <td>2420.61</td>\n",
       "      <td>4.673591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                datetime  eth_open  eth_high  eth_low  eth_close  eth_volume\n",
       "9995 2024-09-14 12:57:00   2421.30   2421.45  2420.28    2421.45   37.802834\n",
       "9996 2024-09-14 12:58:00   2421.39   2421.44  2421.02    2421.24    3.580702\n",
       "9997 2024-09-14 12:59:00   2421.24   2421.70  2421.12    2421.44   15.611558\n",
       "9998 2024-09-14 13:00:00   2421.46   2421.52  2420.57    2421.40   10.753724\n",
       "9999 2024-09-14 13:01:00   2421.26   2421.29  2420.61    2420.61    4.673591"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eth.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>sol_open</th>\n",
       "      <th>sol_high</th>\n",
       "      <th>sol_low</th>\n",
       "      <th>sol_close</th>\n",
       "      <th>sol_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-11-22 12:01:00</td>\n",
       "      <td>54.50</td>\n",
       "      <td>54.52</td>\n",
       "      <td>54.47</td>\n",
       "      <td>54.51</td>\n",
       "      <td>475.244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-11-22 12:02:00</td>\n",
       "      <td>54.52</td>\n",
       "      <td>54.52</td>\n",
       "      <td>54.49</td>\n",
       "      <td>54.52</td>\n",
       "      <td>371.520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-11-22 12:03:00</td>\n",
       "      <td>54.50</td>\n",
       "      <td>54.63</td>\n",
       "      <td>54.50</td>\n",
       "      <td>54.63</td>\n",
       "      <td>538.134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-11-22 12:04:00</td>\n",
       "      <td>54.63</td>\n",
       "      <td>54.72</td>\n",
       "      <td>54.54</td>\n",
       "      <td>54.72</td>\n",
       "      <td>87.496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-11-22 12:05:00</td>\n",
       "      <td>54.72</td>\n",
       "      <td>54.72</td>\n",
       "      <td>54.70</td>\n",
       "      <td>54.70</td>\n",
       "      <td>4112.125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime  sol_open  sol_high  sol_low  sol_close  sol_volume\n",
       "0 2023-11-22 12:01:00     54.50     54.52    54.47      54.51     475.244\n",
       "1 2023-11-22 12:02:00     54.52     54.52    54.49      54.52     371.520\n",
       "2 2023-11-22 12:03:00     54.50     54.63    54.50      54.63     538.134\n",
       "3 2023-11-22 12:04:00     54.63     54.72    54.54      54.72      87.496\n",
       "4 2023-11-22 12:05:00     54.72     54.72    54.70      54.70    4112.125"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sol = pd.read_csv(Path(r'C:/\\Users/\\vchar/\\OneDrive/\\Desktop/\\ML Projects/\\Upwork/\\AlgoT_ML_Dev/\\GrammarEvolution/\\PonyGE2/\\datasets/\\SOL-1m.csv'))\n",
    "# df_sol = pd.read_csv('/kaggle/input/btcusd-test/BTCUSD_ohlcv.csv')\n",
    "df_sol['datetime'] = pd.to_datetime(df_sol['datetime'])\n",
    "df_sol = df_sol.iloc[-10000:]\n",
    "df_sol.sort_values('datetime', ascending=True, inplace=True)\n",
    "df_sol.reset_index(inplace=True, drop=True)\n",
    "df_sol.rename(\n",
    "    columns={\n",
    "        'open': 'sol_open', \n",
    "        'close': 'sol_close', \n",
    "        'low': 'sol_low', \n",
    "        'high': 'sol_high', \n",
    "        'volume': 'sol_volume'\n",
    "    },\n",
    "    inplace=True\n",
    ")\n",
    "df_sol.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>sol_open</th>\n",
       "      <th>sol_high</th>\n",
       "      <th>sol_low</th>\n",
       "      <th>sol_close</th>\n",
       "      <th>sol_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2023-11-29 10:40:00</td>\n",
       "      <td>60.21</td>\n",
       "      <td>60.31</td>\n",
       "      <td>60.04</td>\n",
       "      <td>60.31</td>\n",
       "      <td>2471.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>2023-11-29 10:41:00</td>\n",
       "      <td>60.32</td>\n",
       "      <td>60.32</td>\n",
       "      <td>60.22</td>\n",
       "      <td>60.26</td>\n",
       "      <td>417.767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>2023-11-29 10:42:00</td>\n",
       "      <td>60.28</td>\n",
       "      <td>60.30</td>\n",
       "      <td>60.22</td>\n",
       "      <td>60.30</td>\n",
       "      <td>541.638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>2023-11-29 10:43:00</td>\n",
       "      <td>60.32</td>\n",
       "      <td>60.45</td>\n",
       "      <td>60.29</td>\n",
       "      <td>60.33</td>\n",
       "      <td>1013.428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>2023-11-29 10:44:00</td>\n",
       "      <td>60.26</td>\n",
       "      <td>60.31</td>\n",
       "      <td>60.16</td>\n",
       "      <td>60.19</td>\n",
       "      <td>1979.268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                datetime  sol_open  sol_high  sol_low  sol_close  sol_volume\n",
       "9995 2023-11-29 10:40:00     60.21     60.31    60.04      60.31    2471.730\n",
       "9996 2023-11-29 10:41:00     60.32     60.32    60.22      60.26     417.767\n",
       "9997 2023-11-29 10:42:00     60.28     60.30    60.22      60.30     541.638\n",
       "9998 2023-11-29 10:43:00     60.32     60.45    60.29      60.33    1013.428\n",
       "9999 2023-11-29 10:44:00     60.26     60.31    60.16      60.19    1979.268"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sol.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>btc_open</th>\n",
       "      <th>btc_high</th>\n",
       "      <th>btc_low</th>\n",
       "      <th>btc_close</th>\n",
       "      <th>btc_volume</th>\n",
       "      <th>eth_open</th>\n",
       "      <th>eth_high</th>\n",
       "      <th>eth_low</th>\n",
       "      <th>eth_close</th>\n",
       "      <th>eth_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-09-07 14:22:00</td>\n",
       "      <td>54626.71</td>\n",
       "      <td>54626.71</td>\n",
       "      <td>54575.54</td>\n",
       "      <td>54587.68</td>\n",
       "      <td>3.029570</td>\n",
       "      <td>2295.48</td>\n",
       "      <td>2295.48</td>\n",
       "      <td>2292.22</td>\n",
       "      <td>2292.22</td>\n",
       "      <td>8.133025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-09-07 14:23:00</td>\n",
       "      <td>54579.67</td>\n",
       "      <td>54596.70</td>\n",
       "      <td>54557.25</td>\n",
       "      <td>54588.69</td>\n",
       "      <td>4.557107</td>\n",
       "      <td>2292.23</td>\n",
       "      <td>2293.17</td>\n",
       "      <td>2291.09</td>\n",
       "      <td>2292.84</td>\n",
       "      <td>18.279947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-09-07 14:24:00</td>\n",
       "      <td>54585.02</td>\n",
       "      <td>54605.49</td>\n",
       "      <td>54568.01</td>\n",
       "      <td>54605.49</td>\n",
       "      <td>3.003662</td>\n",
       "      <td>2292.75</td>\n",
       "      <td>2293.33</td>\n",
       "      <td>2291.55</td>\n",
       "      <td>2292.98</td>\n",
       "      <td>12.682892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-09-07 14:25:00</td>\n",
       "      <td>54605.49</td>\n",
       "      <td>54609.63</td>\n",
       "      <td>54581.65</td>\n",
       "      <td>54587.49</td>\n",
       "      <td>0.997784</td>\n",
       "      <td>2292.98</td>\n",
       "      <td>2293.07</td>\n",
       "      <td>2291.24</td>\n",
       "      <td>2292.00</td>\n",
       "      <td>29.546565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-09-07 14:26:00</td>\n",
       "      <td>54586.10</td>\n",
       "      <td>54658.16</td>\n",
       "      <td>54586.10</td>\n",
       "      <td>54658.16</td>\n",
       "      <td>2.026429</td>\n",
       "      <td>2291.81</td>\n",
       "      <td>2294.84</td>\n",
       "      <td>2291.80</td>\n",
       "      <td>2294.80</td>\n",
       "      <td>7.415414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime  btc_open  btc_high   btc_low  btc_close  btc_volume  \\\n",
       "0 2024-09-07 14:22:00  54626.71  54626.71  54575.54   54587.68    3.029570   \n",
       "1 2024-09-07 14:23:00  54579.67  54596.70  54557.25   54588.69    4.557107   \n",
       "2 2024-09-07 14:24:00  54585.02  54605.49  54568.01   54605.49    3.003662   \n",
       "3 2024-09-07 14:25:00  54605.49  54609.63  54581.65   54587.49    0.997784   \n",
       "4 2024-09-07 14:26:00  54586.10  54658.16  54586.10   54658.16    2.026429   \n",
       "\n",
       "   eth_open  eth_high  eth_low  eth_close  eth_volume  \n",
       "0   2295.48   2295.48  2292.22    2292.22    8.133025  \n",
       "1   2292.23   2293.17  2291.09    2292.84   18.279947  \n",
       "2   2292.75   2293.33  2291.55    2292.98   12.682892  \n",
       "3   2292.98   2293.07  2291.24    2292.00   29.546565  \n",
       "4   2291.81   2294.84  2291.80    2294.80    7.415414  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_btc.set_index('datetime', inplace=True)\n",
    "# df_eth.set_index('datetime', inplace=True)\n",
    "\n",
    "df_m = pd.merge(df_btc, df_eth, on='datetime')\n",
    "df_m.sort_values('datetime', ascending=True)\n",
    "df_m.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5888 entries, 0 to 5887\n",
      "Data columns (total 11 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   datetime    5888 non-null   datetime64[ns]\n",
      " 1   btc_open    5888 non-null   float64       \n",
      " 2   btc_high    5888 non-null   float64       \n",
      " 3   btc_low     5888 non-null   float64       \n",
      " 4   btc_close   5888 non-null   float64       \n",
      " 5   btc_volume  5888 non-null   float64       \n",
      " 6   eth_open    5888 non-null   float64       \n",
      " 7   eth_high    5888 non-null   float64       \n",
      " 8   eth_low     5888 non-null   float64       \n",
      " 9   eth_close   5888 non-null   float64       \n",
      " 10  eth_volume  5888 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(10)\n",
      "memory usage: 506.1 KB\n"
     ]
    }
   ],
   "source": [
    "df_m.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m.to_csv(\n",
    "    Path(r'C:/\\Users/\\vchar/\\OneDrive/\\Desktop/\\ML Projects/\\Upwork/\\AlgoT_ML_Dev/\\GrammarEvolution/\\PonyGE2/\\datasets/\\BTC-ETH-1m.csv'),\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6E_1m_databento_symbol_final_1min.csv',\n",
       " 'AAPL_1m_databento.csv',\n",
       " 'AAV-1m-1000wks-data.csv',\n",
       " 'AMZN_1m_databento.csv',\n",
       " 'BTC-1m-1000wks-data.csv',\n",
       " 'CL_1m_databento_symbol_final_1min.csv',\n",
       " 'COIN_1m_databento.csv',\n",
       " 'DOG-1m-1000wks-data.csv',\n",
       " 'ES_1m_databento_symbol_final_1min.csv',\n",
       " 'ETH-1m-1000wks-data.csv_backup.csv',\n",
       " 'FET-1m-1000wks-data.csv_backup.csv',\n",
       " 'GC_1m_databento_symbol_final_1min.csv',\n",
       " 'GOOGL_1m_databento.csv',\n",
       " 'INJ-1m-1000wks-data.csv',\n",
       " 'LIN-1m-1000wks-data.csv_backup.csv',\n",
       " 'META_1m_databento.csv',\n",
       " 'MSFT_1m_databento.csv',\n",
       " 'NG_1m_databento_symbol_final_1min.csv',\n",
       " 'NQ_1m_databento_symbol_final_1min.csv',\n",
       " 'NVDA_1m_databento.csv',\n",
       " 'PLTR_1m_databento.csv',\n",
       " 'SOL-1m-1000wks-data.csv_backup.csv',\n",
       " 'SUI-1m-1000wks-data.csv',\n",
       " 'TIA-1m-1000wks-data.csv',\n",
       " 'TSLA_1m_databento.csv',\n",
       " 'XRP-1m-1000wks-data.csv',\n",
       " 'ZF_1m_databento_symbol_final_1min.csv',\n",
       " 'ZN_1m_databento_symbol_final_1min.csv']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_path = Path(r'C:/\\Users/\\vchar/\\Downloads/\\FULL DATA LIBRARY')\n",
    "\n",
    "files_list = os.listdir(main_path)\n",
    "files_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETH-1m-1000wks-data.csv_backup.csv doesn't contain overlapping data.\n",
      "SOL-1m-1000wks-data.csv_backup.csv doesn't contain overlapping data.\n"
     ]
    }
   ],
   "source": [
    "# final_df = pd.DataFrame()\n",
    "\n",
    "for i in range(len(files_list)):\n",
    "    if i in [9, 21]:\n",
    "        print(f\"{files_list[i]} doesn't contain overlapping data.\")\n",
    "        continue\n",
    "    temp_df = pd.read_csv(os.path.join(main_path, files_list[i]))\n",
    "    instrument_name = files_list[i].replace('-', '_').split('_')[0].lower()\n",
    "    temp_df['datetime'] = pd.to_datetime(temp_df['datetime'])\n",
    "    temp_df.sort_values('datetime', ascending=True, inplace=True)\n",
    "    # temp_df.set_index('datetime', inplace=True)\n",
    "    temp_df.reset_index(inplace=True, drop=True)\n",
    "    temp_df.rename(\n",
    "        columns={\n",
    "            'open': f'{instrument_name}_open', \n",
    "            'close': f'{instrument_name}_close', \n",
    "            'low': f'{instrument_name}_low', \n",
    "            'high': f'{instrument_name}_high', \n",
    "            'volume': f'{instrument_name}_volume'\n",
    "        },\n",
    "        inplace=True\n",
    "    )\n",
    "    # print(f\"{i}: {files_list[i]}: start_date = {temp_df.iloc[0]['datetime']} end_date = {temp_df.iloc[-1]['datetime']}\")\n",
    "    if i == 0:\n",
    "        final_df = temp_df.copy()\n",
    "    else:\n",
    "        final_df = pd.merge(final_df, temp_df, on='datetime')\n",
    "\n",
    "    if final_df.shape[0] == 0:\n",
    "        print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>6e_open</th>\n",
       "      <th>6e_high</th>\n",
       "      <th>6e_low</th>\n",
       "      <th>6e_close</th>\n",
       "      <th>6e_volume</th>\n",
       "      <th>aapl_open</th>\n",
       "      <th>aapl_high</th>\n",
       "      <th>aapl_low</th>\n",
       "      <th>aapl_close</th>\n",
       "      <th>...</th>\n",
       "      <th>zf_open</th>\n",
       "      <th>zf_high</th>\n",
       "      <th>zf_low</th>\n",
       "      <th>zf_close</th>\n",
       "      <th>zf_volume</th>\n",
       "      <th>zn_open</th>\n",
       "      <th>zn_high</th>\n",
       "      <th>zn_low</th>\n",
       "      <th>zn_close</th>\n",
       "      <th>zn_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-11-01 18:56:00</td>\n",
       "      <td>1.05600</td>\n",
       "      <td>1.05635</td>\n",
       "      <td>1.05590</td>\n",
       "      <td>1.05590</td>\n",
       "      <td>607</td>\n",
       "      <td>172.77</td>\n",
       "      <td>172.97</td>\n",
       "      <td>172.765</td>\n",
       "      <td>172.95</td>\n",
       "      <td>...</td>\n",
       "      <td>104.914062</td>\n",
       "      <td>104.945312</td>\n",
       "      <td>104.914062</td>\n",
       "      <td>104.937500</td>\n",
       "      <td>3727</td>\n",
       "      <td>106.812500</td>\n",
       "      <td>106.859375</td>\n",
       "      <td>106.796875</td>\n",
       "      <td>106.843750</td>\n",
       "      <td>11709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-11-01 18:58:00</td>\n",
       "      <td>1.05625</td>\n",
       "      <td>1.05640</td>\n",
       "      <td>1.05615</td>\n",
       "      <td>1.05630</td>\n",
       "      <td>396</td>\n",
       "      <td>173.10</td>\n",
       "      <td>173.27</td>\n",
       "      <td>173.060</td>\n",
       "      <td>173.25</td>\n",
       "      <td>...</td>\n",
       "      <td>104.937500</td>\n",
       "      <td>104.945312</td>\n",
       "      <td>104.921875</td>\n",
       "      <td>104.937500</td>\n",
       "      <td>3415</td>\n",
       "      <td>106.843750</td>\n",
       "      <td>106.859375</td>\n",
       "      <td>106.828125</td>\n",
       "      <td>106.859375</td>\n",
       "      <td>8757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-11-01 18:59:00</td>\n",
       "      <td>1.05630</td>\n",
       "      <td>1.05650</td>\n",
       "      <td>1.05605</td>\n",
       "      <td>1.05615</td>\n",
       "      <td>1569</td>\n",
       "      <td>173.24</td>\n",
       "      <td>173.24</td>\n",
       "      <td>173.090</td>\n",
       "      <td>173.19</td>\n",
       "      <td>...</td>\n",
       "      <td>104.937500</td>\n",
       "      <td>104.960938</td>\n",
       "      <td>104.929688</td>\n",
       "      <td>104.960938</td>\n",
       "      <td>13873</td>\n",
       "      <td>106.859375</td>\n",
       "      <td>106.875000</td>\n",
       "      <td>106.828125</td>\n",
       "      <td>106.875000</td>\n",
       "      <td>33414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-11-01 19:02:00</td>\n",
       "      <td>1.05650</td>\n",
       "      <td>1.05670</td>\n",
       "      <td>1.05640</td>\n",
       "      <td>1.05660</td>\n",
       "      <td>326</td>\n",
       "      <td>173.59</td>\n",
       "      <td>173.75</td>\n",
       "      <td>173.550</td>\n",
       "      <td>173.74</td>\n",
       "      <td>...</td>\n",
       "      <td>104.976562</td>\n",
       "      <td>105.015625</td>\n",
       "      <td>104.968750</td>\n",
       "      <td>105.007812</td>\n",
       "      <td>5523</td>\n",
       "      <td>106.906250</td>\n",
       "      <td>106.937500</td>\n",
       "      <td>106.890625</td>\n",
       "      <td>106.921875</td>\n",
       "      <td>7998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-11-01 19:03:00</td>\n",
       "      <td>1.05655</td>\n",
       "      <td>1.05675</td>\n",
       "      <td>1.05645</td>\n",
       "      <td>1.05665</td>\n",
       "      <td>327</td>\n",
       "      <td>173.72</td>\n",
       "      <td>173.73</td>\n",
       "      <td>173.650</td>\n",
       "      <td>173.72</td>\n",
       "      <td>...</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>105.023438</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>4571</td>\n",
       "      <td>106.921875</td>\n",
       "      <td>106.953125</td>\n",
       "      <td>106.906250</td>\n",
       "      <td>106.906250</td>\n",
       "      <td>9335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime  6e_open  6e_high   6e_low  6e_close  6e_volume  \\\n",
       "0 2023-11-01 18:56:00  1.05600  1.05635  1.05590   1.05590        607   \n",
       "1 2023-11-01 18:58:00  1.05625  1.05640  1.05615   1.05630        396   \n",
       "2 2023-11-01 18:59:00  1.05630  1.05650  1.05605   1.05615       1569   \n",
       "3 2023-11-01 19:02:00  1.05650  1.05670  1.05640   1.05660        326   \n",
       "4 2023-11-01 19:03:00  1.05655  1.05675  1.05645   1.05665        327   \n",
       "\n",
       "   aapl_open  aapl_high  aapl_low  aapl_close  ...     zf_open     zf_high  \\\n",
       "0     172.77     172.97   172.765      172.95  ...  104.914062  104.945312   \n",
       "1     173.10     173.27   173.060      173.25  ...  104.937500  104.945312   \n",
       "2     173.24     173.24   173.090      173.19  ...  104.937500  104.960938   \n",
       "3     173.59     173.75   173.550      173.74  ...  104.976562  105.015625   \n",
       "4     173.72     173.73   173.650      173.72  ...  105.000000  105.023438   \n",
       "\n",
       "       zf_low    zf_close  zf_volume     zn_open     zn_high      zn_low  \\\n",
       "0  104.914062  104.937500       3727  106.812500  106.859375  106.796875   \n",
       "1  104.921875  104.937500       3415  106.843750  106.859375  106.828125   \n",
       "2  104.929688  104.960938      13873  106.859375  106.875000  106.828125   \n",
       "3  104.968750  105.007812       5523  106.906250  106.937500  106.890625   \n",
       "4  105.000000  105.000000       4571  106.921875  106.953125  106.906250   \n",
       "\n",
       "     zn_close  zn_volume  \n",
       "0  106.843750      11709  \n",
       "1  106.859375       8757  \n",
       "2  106.875000      33414  \n",
       "3  106.921875       7998  \n",
       "4  106.906250       9335  \n",
       "\n",
       "[5 rows x 131 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>6e_open</th>\n",
       "      <th>6e_high</th>\n",
       "      <th>6e_low</th>\n",
       "      <th>6e_close</th>\n",
       "      <th>6e_volume</th>\n",
       "      <th>aapl_open</th>\n",
       "      <th>aapl_high</th>\n",
       "      <th>aapl_low</th>\n",
       "      <th>aapl_close</th>\n",
       "      <th>...</th>\n",
       "      <th>zf_open</th>\n",
       "      <th>zf_high</th>\n",
       "      <th>zf_low</th>\n",
       "      <th>zf_close</th>\n",
       "      <th>zf_volume</th>\n",
       "      <th>zn_open</th>\n",
       "      <th>zn_high</th>\n",
       "      <th>zn_low</th>\n",
       "      <th>zn_close</th>\n",
       "      <th>zn_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48886</th>\n",
       "      <td>2024-09-06 20:46:00</td>\n",
       "      <td>1.11335</td>\n",
       "      <td>1.11335</td>\n",
       "      <td>1.11335</td>\n",
       "      <td>1.11335</td>\n",
       "      <td>1</td>\n",
       "      <td>220.00</td>\n",
       "      <td>220.04</td>\n",
       "      <td>219.99</td>\n",
       "      <td>220.04</td>\n",
       "      <td>...</td>\n",
       "      <td>110.375000</td>\n",
       "      <td>110.375000</td>\n",
       "      <td>110.375000</td>\n",
       "      <td>110.375000</td>\n",
       "      <td>26</td>\n",
       "      <td>114.953125</td>\n",
       "      <td>114.968750</td>\n",
       "      <td>114.953125</td>\n",
       "      <td>114.953125</td>\n",
       "      <td>541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48887</th>\n",
       "      <td>2024-09-06 20:49:00</td>\n",
       "      <td>1.11335</td>\n",
       "      <td>1.11335</td>\n",
       "      <td>1.11330</td>\n",
       "      <td>1.11330</td>\n",
       "      <td>2</td>\n",
       "      <td>220.03</td>\n",
       "      <td>220.15</td>\n",
       "      <td>220.03</td>\n",
       "      <td>220.05</td>\n",
       "      <td>...</td>\n",
       "      <td>110.382812</td>\n",
       "      <td>110.398438</td>\n",
       "      <td>110.375000</td>\n",
       "      <td>110.390625</td>\n",
       "      <td>3449</td>\n",
       "      <td>114.968750</td>\n",
       "      <td>114.984375</td>\n",
       "      <td>114.968750</td>\n",
       "      <td>114.984375</td>\n",
       "      <td>3165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48888</th>\n",
       "      <td>2024-09-06 20:50:00</td>\n",
       "      <td>1.11330</td>\n",
       "      <td>1.11330</td>\n",
       "      <td>1.11330</td>\n",
       "      <td>1.11330</td>\n",
       "      <td>1</td>\n",
       "      <td>220.04</td>\n",
       "      <td>220.04</td>\n",
       "      <td>219.90</td>\n",
       "      <td>219.95</td>\n",
       "      <td>...</td>\n",
       "      <td>110.398438</td>\n",
       "      <td>110.406250</td>\n",
       "      <td>110.398438</td>\n",
       "      <td>110.406250</td>\n",
       "      <td>1568</td>\n",
       "      <td>114.984375</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>114.984375</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>2275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48889</th>\n",
       "      <td>2024-09-06 20:51:00</td>\n",
       "      <td>1.11335</td>\n",
       "      <td>1.11335</td>\n",
       "      <td>1.11335</td>\n",
       "      <td>1.11335</td>\n",
       "      <td>1</td>\n",
       "      <td>219.96</td>\n",
       "      <td>219.98</td>\n",
       "      <td>219.95</td>\n",
       "      <td>219.97</td>\n",
       "      <td>...</td>\n",
       "      <td>110.406250</td>\n",
       "      <td>110.406250</td>\n",
       "      <td>110.406250</td>\n",
       "      <td>110.406250</td>\n",
       "      <td>352</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>115.015625</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>1493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48890</th>\n",
       "      <td>2024-09-06 20:54:00</td>\n",
       "      <td>1.11330</td>\n",
       "      <td>1.11330</td>\n",
       "      <td>1.11330</td>\n",
       "      <td>1.11330</td>\n",
       "      <td>2</td>\n",
       "      <td>219.95</td>\n",
       "      <td>219.95</td>\n",
       "      <td>219.75</td>\n",
       "      <td>219.86</td>\n",
       "      <td>...</td>\n",
       "      <td>110.421875</td>\n",
       "      <td>110.429688</td>\n",
       "      <td>110.421875</td>\n",
       "      <td>110.421875</td>\n",
       "      <td>66</td>\n",
       "      <td>115.015625</td>\n",
       "      <td>115.015625</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>115.015625</td>\n",
       "      <td>2550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 datetime  6e_open  6e_high   6e_low  6e_close  6e_volume  \\\n",
       "48886 2024-09-06 20:46:00  1.11335  1.11335  1.11335   1.11335          1   \n",
       "48887 2024-09-06 20:49:00  1.11335  1.11335  1.11330   1.11330          2   \n",
       "48888 2024-09-06 20:50:00  1.11330  1.11330  1.11330   1.11330          1   \n",
       "48889 2024-09-06 20:51:00  1.11335  1.11335  1.11335   1.11335          1   \n",
       "48890 2024-09-06 20:54:00  1.11330  1.11330  1.11330   1.11330          2   \n",
       "\n",
       "       aapl_open  aapl_high  aapl_low  aapl_close  ...     zf_open  \\\n",
       "48886     220.00     220.04    219.99      220.04  ...  110.375000   \n",
       "48887     220.03     220.15    220.03      220.05  ...  110.382812   \n",
       "48888     220.04     220.04    219.90      219.95  ...  110.398438   \n",
       "48889     219.96     219.98    219.95      219.97  ...  110.406250   \n",
       "48890     219.95     219.95    219.75      219.86  ...  110.421875   \n",
       "\n",
       "          zf_high      zf_low    zf_close  zf_volume     zn_open     zn_high  \\\n",
       "48886  110.375000  110.375000  110.375000         26  114.953125  114.968750   \n",
       "48887  110.398438  110.375000  110.390625       3449  114.968750  114.984375   \n",
       "48888  110.406250  110.398438  110.406250       1568  114.984375  115.000000   \n",
       "48889  110.406250  110.406250  110.406250        352  115.000000  115.015625   \n",
       "48890  110.429688  110.421875  110.421875         66  115.015625  115.015625   \n",
       "\n",
       "           zn_low    zn_close  zn_volume  \n",
       "48886  114.953125  114.953125        541  \n",
       "48887  114.968750  114.984375       3165  \n",
       "48888  114.984375  115.000000       2275  \n",
       "48889  115.000000  115.000000       1493  \n",
       "48890  115.000000  115.015625       2550  \n",
       "\n",
       "[5 rows x 131 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48891, 131)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['6e', 'aapl', 'aav', 'amzn', 'btc', 'cl', 'coin', 'datetime',\n",
       "       'dog', 'es', 'fet', 'gc', 'googl', 'inj', 'lin', 'meta', 'msft',\n",
       "       'ng', 'nq', 'nvda', 'pltr', 'sui', 'tia', 'tsla', 'xrp', 'zf',\n",
       "       'zn'], dtype='<U8')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique([i.split('_')[0] for i in final_df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"all_data_1min.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_list = [\n",
    "    '6e', 'aapl', 'aav', 'amzn', 'btc', 'cl', 'coin',\n",
    "    'dog', 'es', 'fet', 'gc', 'googl', 'inj', 'lin', 'meta', 'msft',\n",
    "    'ng', 'nq', 'nvda', 'pltr', 'sui', 'tia', 'tsla', 'xrp', 'zf',\n",
    "    'zn'\n",
    "]\n",
    "\n",
    "prefix_txt = '{:{:'\n",
    "suffix_txt = ':}:}{::}'\n",
    "it_txt = '_{i}'\n",
    "\n",
    "for instrument in inst_list:\n",
    "\n",
    "    if instrument == 'btc':\n",
    "        continue\n",
    "\n",
    "    text_template = f'''{prefix_txt}df[f\"'\"{instrument}_close{it_txt}\"'\"] = df[\"'\"{instrument}_close\"'\"].shift(i){suffix_txt}\n",
    "    {prefix_txt}df[f\"'\"{instrument}_open{it_txt}\"'\"] = df[\"'\"{instrument}_open\"'\"].shift(i){suffix_txt}\n",
    "    {prefix_txt}df[f\"'\"{instrument}_high{it_txt}\"'\"] = df[\"'\"{instrument}_high\"'\"].shift(i){suffix_txt}\n",
    "    {prefix_txt}df[f\"'\"{instrument}_low{it_txt}\"'\"] = df[\"'\"{instrument}_low\"'\"].shift(i){suffix_txt}\n",
    "    {prefix_txt}df[f\"'\"{instrument}_volume{it_txt}\"'\"] = df[\"'\"{instrument}_volume\"'\"].shift(i){suffix_txt}'''\n",
    "\n",
    "    print(text_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_list = [\n",
    "    '6e', 'aapl', 'aav', 'amzn', 'btc', 'cl', 'coin',\n",
    "    'dog', 'es', 'fet', 'gc', 'googl', 'inj', 'lin', 'meta', 'msft',\n",
    "    'ng', 'nq', 'nvda', 'pltr', 'sui', 'tia', 'tsla', 'xrp', 'zf',\n",
    "    'zn'\n",
    "]\n",
    "\n",
    "for instrument in inst_list:\n",
    "\n",
    "    if instrument == 'btc':\n",
    "        continue\n",
    "\n",
    "    txt_temp = f'''| df[\"'\"{instrument}_close\"'\"].values.reshape(-1, 1) \n",
    "    | df[\"'\"{instrument}_open\"'\"].values.reshape(-1, 1) \n",
    "    | df[\"'\"{instrument}_high\"'\"].values.reshape(-1, 1) \n",
    "    | df[\"'\"{instrument}_low\"'\"].values.reshape(-1, 1)\n",
    "    | df[\"'\"{instrument}_volume\"'\"].values.reshape(-1, 1)\n",
    "    | df[\"'\"{instrument}_close_1\"'\"].values.reshape(-1, 1) \n",
    "    | df[\"'\"{instrument}_open_1\"'\"].values.reshape(-1, 1) \n",
    "    | df[\"'\"{instrument}_high_1\"'\"].values.reshape(-1, 1) \n",
    "    | df[\"'\"{instrument}_low_1\"'\"].values.reshape(-1, 1)\n",
    "    | df[\"'\"{instrument}_volume_1\"'\"].values.reshape(-1, 1)\n",
    "    | df[\"'\"{instrument}_close_2\"'\"].values.reshape(-1, 1) \n",
    "    | df[\"'\"{instrument}_open_2\"'\"].values.reshape(-1, 1) \n",
    "    | df[\"'\"{instrument}_high_2\"'\"].values.reshape(-1, 1) \n",
    "    | df[\"'\"{instrument}_low_2\"'\"].values.reshape(-1, 1)\n",
    "    | df[\"'\"{instrument}_volume_2\"'\"].values.reshape(-1, 1)\n",
    "    | df[\"'\"{instrument}_close_3\"'\"].values.reshape(-1, 1) \n",
    "    | df[\"'\"{instrument}_open_3\"'\"].values.reshape(-1, 1) \n",
    "    | df[\"'\"{instrument}_high_3\"'\"].values.reshape(-1, 1) \n",
    "    | df[\"'\"{instrument}_low_3\"'\"].values.reshape(-1, 1)\n",
    "    | df[\"'\"{instrument}_volume_3\"'\"].values.reshape(-1, 1)\n",
    "    | df[\"'\"{instrument}_close_4\"'\"].values.reshape(-1, 1) \n",
    "    | df[\"'\"{instrument}_open_4\"'\"].values.reshape(-1, 1) \n",
    "    | df[\"'\"{instrument}_high_4\"'\"].values.reshape(-1, 1) \n",
    "    | df[\"'\"{instrument}_low_4\"'\"].values.reshape(-1, 1)\n",
    "    | df[\"'\"{instrument}_volume_4\"'\"].values.reshape(-1, 1)\n",
    "    | df[\"'\"{instrument}_close_5\"'\"].values.reshape(-1, 1) \n",
    "    | df[\"'\"{instrument}_open_5\"'\"].values.reshape(-1, 1) \n",
    "    | df[\"'\"{instrument}_high_5\"'\"].values.reshape(-1, 1) \n",
    "    | df[\"'\"{instrument}_low_5\"'\"].values.reshape(-1, 1)\n",
    "    | df[\"'\"{instrument}_volume_5\"'\"].values.reshape(-1, 1)'''\n",
    "\n",
    "    print(txt_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting strategy from the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['indicators.RSI(df=data, HistLength=10).values < 20']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re \n",
    "\n",
    "text = '''def fun(price_data):\n",
    "  import pandas as pd\n",
    "  import numpy as np\n",
    "  from fitness.indicators import indicators\n",
    "  from numba import njit\n",
    "  @njit\n",
    "  def merge_pnl(arr1, arr2):\n",
    "    out = np.zeros((len(arr1) + len(arr2)))\n",
    "    idx = 1\n",
    "    for i in range(len(arr1) + len(arr2)):\n",
    "      if i % 2 == 0:\n",
    "        out[i] = arr1[int(i/2)]\n",
    "      else:\n",
    "        out[i] = arr2[i-idx]\n",
    "      idx += 1\n",
    "    return out\n",
    "  @njit\n",
    "  def get_drawdowns(arr):\n",
    "    drawdowns = np.zeros((len(arr)))\n",
    "    max = arr[0]\n",
    "    for i in range(1, len(drawdowns)-1):\n",
    "      if arr[i-1] > arr[i] and arr[i] < arr[i+1]:\n",
    "        min = arr[i]\n",
    "        drawdowns[i] = max - min\n",
    "      elif arr[i-1] < arr[i] and arr[i] > arr[i+1]:\n",
    "        max = arr[i]\n",
    "    return drawdowns\n",
    "  df = price_data.copy()\n",
    "  df['buy'] = (indicators.RSI(df=data, HistLength=10).values < 20).astype(int)\n",
    "  df['sell'] = (indicators.RSI(df=data, HistLength=10).values > 80).astype(int)\n",
    "  df['signal'] = df['buy'] + df['sell']\n",
    "  df['signal'] = df['signal'].apply(lambda x: 1 if x==1 else 0)\n",
    "  df['sell'] = df['sell'] * (-1)\n",
    "  df['signal'] = df['signal'] * df['sell']\n",
    "  df['signal'] = df['signal'] + df['buy']\n",
    "  df.drop(columns=['buy', 'sell'], inplace=True)\n",
    "  buy_idxs = []\n",
    "  sell_idxs = []\n",
    "  is_buy = 0\n",
    "  is_sell = 0\n",
    "  for i, row in enumerate(df.itertuples()):\n",
    "    if row.signal == 1 and is_buy == 0:\n",
    "      buy_idxs.append(i+1)\n",
    "      is_buy = 1\n",
    "      is_sell = 0\n",
    "    elif row.signal == -1 and is_sell == 0:\n",
    "      sell_idxs.append(i+1)\n",
    "      is_sell = 1\n",
    "      is_buy = 0\n",
    "  if len(buy_idxs) > len(sell_idxs):\n",
    "    buy_idxs = buy_idxs[:-(len(buy_idxs) - len(sell_idxs))]\n",
    "  elif len(buy_idxs) < len(sell_idxs):\n",
    "    sell_idxs = sell_idxs[:-(len(sell_idxs) - len(buy_idxs))]\n",
    "  if len(buy_idxs) == 0 or len(sell_idxs) == 0:\n",
    "    return 999\n",
    "  buy_prices = df[df.index.isin(buy_idxs)]['open'].values\n",
    "  sell_prices = df[df.index.isin(sell_idxs)]['open'].values\n",
    "  if buy_idxs[0] < sell_idxs[0]:\n",
    "    buy_pnl = np.sum(sell_prices - buy_prices)\n",
    "    sell_pnl = np.sum(sell_prices[:-1] - buy_prices[1:])\n",
    "    buy_arr = sell_prices - buy_prices\n",
    "    sell_arr = sell_prices[:-1] - buy_prices[1:]\n",
    "    all_arr = merge_pnl(buy_arr, sell_arr)\n",
    "  else:\n",
    "    sell_pnl = np.sum(sell_prices - buy_prices)\n",
    "    buy_pnl = np.sum(sell_prices[1:] - buy_prices[:-1])\n",
    "    sell_arr = sell_prices - buy_prices\n",
    "    buy_arr = sell_prices[1:] - buy_prices[:-1]\n",
    "    all_arr = merge_pnl(sell_arr, buy_arr)\n",
    "  total_pnl = buy_pnl + sell_pnl\n",
    "  equity_curve_arr = np.cumsum(all_arr)\n",
    "  drawdowns = get_drawdowns(equity_curve_arr)\n",
    "  avg_drawdown = np.sum(drawdowns[drawdowns!=0]) / len(drawdowns[drawdowns!=0])\n",
    "  fitness = total_pnl / avg_drawdown\n",
    "  if np.isnan(fitness):\n",
    "    return 999\n",
    "  return -fitness\n",
    "fitness = fun(data)'''\n",
    "\n",
    "re.findall(r\"df\\[\\'buy\\'\\] = \\((.*)\\)\\.astype\\(int\\)\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['indicators.RSI(df=data, HistLength=10).values > 80']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\"df\\[\\'sell\\'\\] = \\((.*)\\)\\.astype\\(int\\)\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(cache=True)\n",
    "def get_pnl(\n",
    "    trade_close_prices,\n",
    "    trade_open_prices,\n",
    "    commission=0.015,\n",
    "    slippage=0.05,\n",
    "    init_inv=20000,\n",
    "    trade_size=0.1,\n",
    "    is_buy=1\n",
    "):\n",
    "\n",
    "    pnl_list = np.zeros(len(trade_close_prices))\n",
    "\n",
    "    for i in range(len(trade_close_prices)):\n",
    "        \n",
    "        temp_n_assets = int(init_inv * trade_size / trade_open_prices[i])\n",
    "        if is_buy == 1:\n",
    "            temp_pnl = temp_n_assets * (trade_close_prices[i] - trade_open_prices[i] * (1 + slippage))\n",
    "        else:\n",
    "            temp_pnl = -temp_n_assets * (trade_close_prices[i] - trade_open_prices[i] * (1 - slippage))\n",
    "        temp_pnl = temp_pnl * (1 - commission)\n",
    "        init_inv += temp_pnl\n",
    "\n",
    "        pnl_list[i] = temp_pnl\n",
    "\n",
    "    return pnl_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(price_data):\n",
    "  import pandas as pd\n",
    "  import numpy as np\n",
    "  # from fitness.indicators import indicators\n",
    "  from numba import njit\n",
    "  COMMISSION = 0.015\n",
    "  SLIPPAGE = 0.00005\n",
    "  AVAILABLE_CAPITAL = 700000\n",
    "  TRADE_SIZE = 0.5\n",
    "  @njit\n",
    "  def merge_pnl(arr1, arr2):\n",
    "    out = np.zeros((len(arr1) + len(arr2)))\n",
    "    idx = 1\n",
    "    for i in range(len(arr1) + len(arr2)):\n",
    "      if i % 2 == 0:\n",
    "        out[i] = arr1[int(i/2)]\n",
    "      else:\n",
    "        out[i] = arr2[i-idx]\n",
    "      idx += 1\n",
    "    return out\n",
    "  @njit\n",
    "  def get_drawdowns(arr):\n",
    "    drawdowns = np.zeros((len(arr)))\n",
    "    max = arr[0]\n",
    "    for i in range(1, len(drawdowns)-1):\n",
    "      if arr[i-1] > arr[i] and arr[i] < arr[i+1]:\n",
    "        min = arr[i]\n",
    "        drawdowns[i] = max - min\n",
    "      elif arr[i-1] < arr[i] and arr[i] > arr[i+1]:\n",
    "        max = arr[i]\n",
    "    return drawdowns\n",
    "  @njit\n",
    "  def get_pnl(trade_close_prices, trade_open_prices, commission, slippage, init_inv, trade_size, is_buy):\n",
    "    pnl_list = np.zeros(len(trade_close_prices))\n",
    "    for i in range(len(trade_close_prices)):\n",
    "      temp_n_assets = int(init_inv * trade_size / trade_open_prices[i])\n",
    "      if is_buy == 1:\n",
    "        temp_pnl = temp_n_assets * (trade_close_prices[i] - trade_open_prices[i] * (1 + slippage))\n",
    "      else:\n",
    "        temp_pnl = -temp_n_assets * (trade_close_prices[i] - trade_open_prices[i] * (1 - slippage))\n",
    "      temp_pnl = temp_pnl * (1 - commission)\n",
    "      init_inv += temp_pnl\n",
    "      pnl_list[i] = temp_pnl\n",
    "    return pnl_list\n",
    "  df = price_data.copy()\n",
    "  for i in range(1, 6):\n",
    "    df[f'close_{i}'] = df['close'].shift(i)\n",
    "    df[f'open_{i}'] = df['open'].shift(i)\n",
    "    df[f'high_{i}'] = df['high'].shift(i)\n",
    "    df[f'low_{i}'] = df['low'].shift(i)\n",
    "    df[f'volume_{i}'] = df['volume'].shift(i)\n",
    "  df.dropna(inplace=True)\n",
    "  df.reset_index(drop=True, inplace=True)\n",
    "  df['buy'] = (RSI(df=df, HistLength=10).values < 20).astype(int)\n",
    "  df['sell'] = (RSI(df=df, HistLength=10).values > 80).astype(int)\n",
    "  df['signal'] = df['buy'] + df['sell']\n",
    "  df['signal'] = df['signal'].apply(lambda x: 1 if x==1 else 0)\n",
    "  df['sell'] = df['sell'] * (-1)\n",
    "  df['signal'] = df['signal'] * df['sell']\n",
    "  df['signal'] = df['signal'] + df['buy']\n",
    "  df.drop(columns=['buy', 'sell'], inplace=True)\n",
    "  buy_idxs = []\n",
    "  sell_idxs = []\n",
    "  is_buy = 0\n",
    "  is_sell = 0\n",
    "  for i, row in enumerate(df.itertuples()):\n",
    "    if row.signal == 1 and is_buy == 0:\n",
    "      buy_idxs.append(i+1)\n",
    "      is_buy = 1\n",
    "      is_sell = 0\n",
    "    elif row.signal == -1 and is_sell == 0:\n",
    "      sell_idxs.append(i+1)\n",
    "      is_sell = 1\n",
    "      is_buy = 0\n",
    "  if len(buy_idxs) > len(sell_idxs):\n",
    "    buy_idxs = buy_idxs[:-(len(buy_idxs) - len(sell_idxs))]\n",
    "  elif len(buy_idxs) < len(sell_idxs):\n",
    "    sell_idxs = sell_idxs[:-(len(sell_idxs) - len(buy_idxs))]\n",
    "  if len(buy_idxs) == 0 or len(sell_idxs) == 0:\n",
    "    return 999\n",
    "  buy_prices = df[df.index.isin(buy_idxs)]['open'].values\n",
    "  sell_prices = df[df.index.isin(sell_idxs)]['open'].values\n",
    "  if buy_idxs[0] < sell_idxs[0]:\n",
    "    buy_arr = get_pnl(sell_prices, buy_prices, COMMISSION, SLIPPAGE, AVAILABLE_CAPITAL, TRADE_SIZE, 1)\n",
    "    buy_pnl = np.sum(buy_arr)\n",
    "    sell_arr = get_pnl(buy_prices[1:], sell_prices[:-1], COMMISSION, SLIPPAGE, AVAILABLE_CAPITAL, TRADE_SIZE, 0)\n",
    "    sell_pnl = np.sum(sell_arr)\n",
    "    all_arr = merge_pnl(buy_arr, sell_arr)\n",
    "  else:\n",
    "    sell_arr = get_pnl(buy_prices, sell_prices, COMMISSION, SLIPPAGE, AVAILABLE_CAPITAL, TRADE_SIZE, 0)\n",
    "    sell_pnl = np.sum(sell_arr)\n",
    "    buy_arr = get_pnl(sell_prices[1:], buy_prices[:-1], COMMISSION, SLIPPAGE, AVAILABLE_CAPITAL, TRADE_SIZE, 1)\n",
    "    buy_pnl = np.sum(buy_arr)\n",
    "    all_arr = merge_pnl(sell_arr, buy_arr)\n",
    "  total_pnl = buy_pnl + sell_pnl\n",
    "  equity_curve_arr = np.cumsum(all_arr)\n",
    "  drawdowns = get_drawdowns(equity_curve_arr)\n",
    "  avg_drawdown = np.sum(drawdowns[drawdowns!=0]) / len(drawdowns[drawdowns!=0])\n",
    "  fitness = total_pnl / avg_drawdown\n",
    "  if np.isnan(fitness):\n",
    "    return -999\n",
    "  return -fitness\n",
    "# fitness = fun(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limited testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.fitness.indicators import indicators\n",
    "from numba import njit\n",
    "COMMISSION = 0.015\n",
    "SLIPPAGE = 0.00005\n",
    "AVAILABLE_CAPITAL = 700000\n",
    "TRADE_SIZE = 0.5\n",
    "\n",
    "@njit\n",
    "def merge_pnl(arr1, arr2):\n",
    "    out = np.zeros((len(arr1) + len(arr2)))\n",
    "    idx = 1\n",
    "    for i in range(len(arr1) + len(arr2)):\n",
    "        if i % 2 == 0:\n",
    "            out[i] = arr1[int(i/2)]\n",
    "        else:\n",
    "            out[i] = arr2[i-idx]\n",
    "        idx += 1\n",
    "    return out\n",
    "\n",
    "@njit\n",
    "def get_drawdowns(arr):\n",
    "    drawdowns = np.zeros((len(arr)))\n",
    "    max = arr[0]\n",
    "    for i in range(1, len(drawdowns)-1):\n",
    "        if arr[i-1] > arr[i] and arr[i] < arr[i+1]:\n",
    "            min = arr[i]\n",
    "            drawdowns[i] = max - min\n",
    "        elif arr[i-1] < arr[i] and arr[i] > arr[i+1]:\n",
    "            max = arr[i]\n",
    "    return drawdowns\n",
    "\n",
    "@njit\n",
    "def get_pnl(trade_close_prices, trade_open_prices, commission, slippage, init_inv, trade_size, is_buy):\n",
    "    pnl_list = np.zeros(len(trade_close_prices))\n",
    "    for i in range(len(trade_close_prices)):\n",
    "        temp_n_assets = int(init_inv * trade_size / trade_open_prices[i])\n",
    "        if is_buy == 1:\n",
    "            temp_pnl = temp_n_assets * (trade_close_prices[i] - trade_open_prices[i] * (1 + slippage))\n",
    "        else:\n",
    "            temp_pnl = -temp_n_assets * (trade_close_prices[i] - trade_open_prices[i] * (1 - slippage))\n",
    "        temp_pnl = temp_pnl * (1 - commission)\n",
    "        init_inv += temp_pnl\n",
    "        pnl_list[i] = temp_pnl\n",
    "    return pnl_list\n",
    "\n",
    "# df = price_data.copy()\n",
    "# for i in range(1, 6):\n",
    "#     df[f'close_{i}'] = df['close'].shift(i)\n",
    "#     df[f'open_{i}'] = df['open'].shift(i)\n",
    "#     df[f'high_{i}'] = df['high'].shift(i)\n",
    "#     df[f'low_{i}'] = df['low'].shift(i)\n",
    "#     df[f'volume_{i}'] = df['volume'].shift(i)\n",
    "# df.dropna(inplace=True)\n",
    "# df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df['buy'] = (indicators.RSI(df=df, HistLength=10).values < 20).astype(int)\n",
    "df['sell'] = (indicators.RSI(df=df, HistLength=10).values > 80).astype(int)\n",
    "df['signal'] = df['buy'] + df['sell']\n",
    "df['signal'] = df['signal'].apply(lambda x: 1 if x==1 else 0)\n",
    "df['sell'] = df['sell'] * (-1)\n",
    "df['signal'] = df['signal'] * df['sell']\n",
    "df['signal'] = df['signal'] + df['buy']\n",
    "df.drop(columns=['buy', 'sell'], inplace=True)\n",
    "\n",
    "buy_idxs = []\n",
    "sell_idxs = []\n",
    "is_buy = 0\n",
    "is_sell = 0\n",
    "for i, row in enumerate(df.itertuples()):\n",
    "    if row.signal == 1 and is_buy == 0:\n",
    "        buy_idxs.append(i+1)\n",
    "        is_buy = 1\n",
    "        is_sell = 0\n",
    "    elif row.signal == -1 and is_sell == 0:\n",
    "        sell_idxs.append(i+1)\n",
    "        is_sell = 1\n",
    "        is_buy = 0\n",
    "\n",
    "if len(buy_idxs) > len(sell_idxs):\n",
    "    buy_idxs = buy_idxs[:-(len(buy_idxs) - len(sell_idxs))]\n",
    "elif len(buy_idxs) < len(sell_idxs):\n",
    "    sell_idxs = sell_idxs[:-(len(sell_idxs) - len(buy_idxs))]\n",
    "\n",
    "if len(buy_idxs) == 0 or len(sell_idxs) == 0:\n",
    "    print(\"not enough signals\")\n",
    "\n",
    "buy_prices = df[df.index.isin(buy_idxs)]['open'].values\n",
    "sell_prices = df[df.index.isin(sell_idxs)]['open'].values\n",
    "\n",
    "if buy_idxs[0] < sell_idxs[0]:\n",
    "    buy_arr = get_pnl(sell_prices, buy_prices, COMMISSION, SLIPPAGE, AVAILABLE_CAPITAL, TRADE_SIZE, 1)\n",
    "    buy_pnl = np.sum(buy_arr)\n",
    "    sell_arr = get_pnl(buy_prices[1:], sell_prices[:-1], COMMISSION, SLIPPAGE, AVAILABLE_CAPITAL, TRADE_SIZE, 0)\n",
    "    sell_pnl = np.sum(sell_arr)\n",
    "    all_arr = merge_pnl(buy_arr, sell_arr)\n",
    "else:\n",
    "    sell_arr = get_pnl(buy_prices, sell_prices, COMMISSION, SLIPPAGE, AVAILABLE_CAPITAL, TRADE_SIZE, 0)\n",
    "    sell_pnl = np.sum(sell_arr)\n",
    "    buy_arr = get_pnl(sell_prices[1:], buy_prices[:-1], COMMISSION, SLIPPAGE, AVAILABLE_CAPITAL, TRADE_SIZE, 1)\n",
    "    buy_pnl = np.sum(buy_arr)\n",
    "    all_arr = merge_pnl(sell_arr, buy_arr)\n",
    "\n",
    "total_pnl = buy_pnl + sell_pnl\n",
    "equity_curve_arr = np.cumsum(all_arr)\n",
    "drawdowns = get_drawdowns(equity_curve_arr)\n",
    "avg_drawdown = np.sum(drawdowns[drawdowns!=0]) / len(drawdowns[drawdowns!=0])\n",
    "fitness = total_pnl / avg_drawdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[95, 396, 525, 609, 695, 732, 918, 1088, 1228, 1439, 1566, 1801, 1890, 2061, 2272, 2433, 2521, 2833, 2882, 2970, 3097, 3473, 3764, 3836, 4088, 4427, 4583, 4804, 4939, 5012, 5173, 5220, 5534, 5850, 5965, 6254, 6598, 6674, 6807, 7125, 7336, 7440, 7521, 7584, 7781, 7910, 8080, 8191, 8462, 8622, 8753, 8948, 9091, 9375, 9488]\n"
     ]
    }
   ],
   "source": [
    "print(buy_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15, 373, 496, 574, 651, 711, 801, 972, 1107, 1376, 1526, 1747, 1870, 1993, 2198, 2294, 2481, 2579, 2860, 2948, 3024, 3242, 3510, 3782, 3990, 4205, 4549, 4720, 4831, 4985, 5061, 5209, 5301, 5701, 5893, 6023, 6311, 6630, 6758, 6931, 7318, 7413, 7488, 7566, 7650, 7876, 8012, 8094, 8297, 8496, 8730, 8865, 9012, 9281, 9433]\n"
     ]
    }
   ],
   "source": [
    "print(sell_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55, 55)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(buy_idxs), len(sell_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15, 95, 373, 396, 496, 525, 574, 609, 651, 695, 711, 732, 801, 918, 972, 1088, 1107, 1228, 1376, 1439, 1526, 1566, 1747, 1801, 1870, 1890, 1993, 2061, 2198, 2272, 2294, 2433, 2481, 2521, 2579, 2833, 2860, 2882, 2948, 2970, 3024, 3097, 3242, 3473, 3510, 3764, 3782, 3836, 3990, 4088, 4205, 4427, 4549, 4583, 4720, 4804, 4831, 4939, 4985, 5012, 5061, 5173, 5209, 5220, 5301, 5534, 5701, 5850, 5893, 5965, 6023, 6254, 6311, 6598, 6630, 6674, 6758, 6807, 6931, 7125, 7318, 7336, 7413, 7440, 7488, 7521, 7566, 7584, 7650, 7781, 7876, 7910, 8012, 8080, 8094, 8191, 8297, 8462, 8496, 8622, 8730, 8753, 8865, 8948, 9012, 9091, 9281, 9375, 9433, 9488]\n"
     ]
    }
   ],
   "source": [
    "signal_idxs = buy_idxs.copy()\n",
    "signal_idxs.extend(sell_idxs)\n",
    "signal_idxs = sorted(signal_idxs)\n",
    "print(signal_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14, 94, 372, 395, 495, 524, 573, 608, 650, 694, 710, 731, 800, 917, 971, 1087, 1106, 1227, 1375, 1438, 1525, 1565, 1746, 1800, 1869, 1889, 1992, 2060, 2197, 2271, 2293, 2432, 2480, 2520, 2578, 2832, 2859, 2881, 2947, 2969, 3023, 3096, 3241, 3472, 3509, 3763, 3781, 3835, 3989, 4087, 4204, 4426, 4548, 4582, 4719, 4803, 4830, 4938, 4984, 5011, 5060, 5172, 5208, 5219, 5300, 5533, 5700, 5849, 5892, 5964, 6022, 6253, 6310, 6597, 6629, 6673, 6757, 6806, 6930, 7124, 7317, 7335, 7412, 7439, 7487, 7520, 7565, 7583, 7649, 7780, 7875, 7909, 8011, 8079, 8093, 8190, 8296, 8461, 8495, 8621, 8729, 8752, 8864, 8947, 9011, 9090, 9280, 9374, 9432, 9487]\n"
     ]
    }
   ],
   "source": [
    "signal_idxs_true = [i - 1 for i in signal_idxs]\n",
    "print(signal_idxs_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(signal_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['new_signal'] = 0\n",
    "df.loc[df.index.isin(signal_idxs_true), 'new_signal'] = df.loc[df.index.isin(signal_idxs_true), 'signal'].values\n",
    "# df.loc[~df.index.isin(signal_idxs), 'new_signal'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55, 8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['new_signal']==-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,\n",
       "        1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1,\n",
       "       -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,\n",
       "        1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1,\n",
       "       -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,\n",
       "        1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1,\n",
       "       -1,  1, -1,  1, -1,  1, -1,  1], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.index.isin(signal_idxs_true), 'signal'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['signal_prices'] = 0\n",
    "df.loc[df.index.isin(signal_idxs), 'signal_prices'] = df.loc[df.index.isin(signal_idxs), 'open'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16550. , 16569.6, 16568.5, 16554.5, 16536.9, 16532.7, 16543.3,\n",
       "       16531.5, 16539.6, 16550.4, 16563.7, 16543.6, 16541.3, 16558.2,\n",
       "       16561.6, 16570.8, 16599.9, 16569.1, 16568.7, 16548.6, 16548.2,\n",
       "       16458.4, 16531.8, 16526.2, 16518.8, 16507.5, 16517.5, 16513.5,\n",
       "       16496.3, 16515. , 16524.5, 16530.1, 16527.9, 16529.6, 16527.9,\n",
       "       16578.7, 16604.1, 16589. , 16587.5, 16580.3, 16589.1, 16583.1,\n",
       "       16564.4, 16630.3, 16685.1, 16706. , 16726.4, 16725.5, 16699.3,\n",
       "       16713.8, 16711.6, 16698.5, 16691.5, 16665.2, 16679.5, 16671.6,\n",
       "       16689.8, 16709.7, 16717.2, 16703.6, 16715.1, 16714.4, 16717.4,\n",
       "       16703. , 16716.4, 16606.1, 16640. , 16640.1, 16664.4, 16650.4,\n",
       "       16659.1, 16847.6, 16842.2, 16827. , 16842.5, 16828. , 16829. ,\n",
       "       16803.7, 16873.6, 16791.5, 16826. , 16803.6, 16862.2, 16836.1,\n",
       "       16834.1, 16812.5, 16829.1, 16816.5, 16819.6, 16821.1, 16812. ,\n",
       "       16797. , 16809.9, 16807. , 16816.3, 16799.1, 16820. , 16801.8,\n",
       "       16812. , 16829.9, 16837.5, 16828.6, 16826. , 16826.4, 16818.1,\n",
       "       16813.7, 16777.6, 16790.5, 16779.9, 16771.1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.index.isin(signal_idxs), 'open'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_list = np.zeros((2, df.shape[0]))\n",
    "signal_list[0][1:] = df['new_signal'].values[:-1]\n",
    "signal_list[1] = df['signal_prices'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15, 95, 373, 396, 496, 525, 574, 609, 651, 695, 711, 732, 801, 918, 972, 1088, 1107, 1228, 1376, 1439, 1526, 1566, 1747, 1801, 1870, 1890, 1993, 2061, 2198, 2272, 2294, 2433, 2481, 2521, 2579, 2833, 2860, 2882, 2948, 2970, 3024, 3097, 3242, 3473, 3510, 3764, 3782, 3836, 3990, 4088, 4205, 4427, 4549, 4583, 4720, 4804, 4831, 4939, 4985, 5012, 5061, 5173, 5209, 5220, 5301, 5534, 5701, 5850, 5893, 5965, 6023, 6254, 6311, 6598, 6630, 6674, 6758, 6807, 6931, 7125, 7318, 7336, 7413, 7440, 7488, 7521, 7566, 7584, 7650, 7781, 7876, 7910, 8012, 8080, 8094, 8191, 8297, 8462, 8496, 8622, 8730, 8753, 8865, 8948, 9012, 9091, 9281, 9375, 9433, 9488]\n"
     ]
    }
   ],
   "source": [
    "print([i for i in range(len(signal_list[0])) if signal_list[0][i] != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15, 95, 373, 396, 496, 525, 574, 609, 651, 695, 711, 732, 801, 918, 972, 1088, 1107, 1228, 1376, 1439, 1526, 1566, 1747, 1801, 1870, 1890, 1993, 2061, 2198, 2272, 2294, 2433, 2481, 2521, 2579, 2833, 2860, 2882, 2948, 2970, 3024, 3097, 3242, 3473, 3510, 3764, 3782, 3836, 3990, 4088, 4205, 4427, 4549, 4583, 4720, 4804, 4831, 4939, 4985, 5012, 5061, 5173, 5209, 5220, 5301, 5534, 5701, 5850, 5893, 5965, 6023, 6254, 6311, 6598, 6630, 6674, 6758, 6807, 6931, 7125, 7318, 7336, 7413, 7440, 7488, 7521, 7566, 7584, 7650, 7781, 7876, 7910, 8012, 8080, 8094, 8191, 8297, 8462, 8496, 8622, 8730, 8753, 8865, 8948, 9012, 9091, 9281, 9375, 9433, 9488]\n"
     ]
    }
   ],
   "source": [
    "print(signal_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entry testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed stop and target exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(cache=True)\n",
    "def get_exit_entry_testing1(\n",
    "    close_prices, \n",
    "    open_prices,  \n",
    "    signal_list,\n",
    "    stoploss_th,\n",
    "    takeprofit_th, \n",
    "    commission, \n",
    "    slippage, \n",
    "    init_inv, \n",
    "    trade_size\n",
    "):\n",
    "\n",
    "    exit_list = np.zeros((2, len(close_prices)))\n",
    "\n",
    "    for i in range(len(close_prices)-1):\n",
    "\n",
    "        if signal_list[1][i] == 0:\n",
    "\n",
    "            pass\n",
    "\n",
    "        else:\n",
    "\n",
    "            temp_n_assets = int(init_inv * trade_size / signal_list[1][i])\n",
    "            if signal_list[0][i] == 1:\n",
    "                temp_pnl = temp_n_assets * (close_prices[i] - signal_list[1][i] * (1 + slippage))\n",
    "            else:\n",
    "                temp_pnl = -temp_n_assets * (close_prices[i] - signal_list[1][i] * (1 - slippage))\n",
    "            temp_pnl = temp_pnl * (1 - commission)\n",
    "            init_inv += temp_pnl\n",
    "\n",
    "            if -temp_pnl >= stoploss_th or temp_pnl >= takeprofit_th:\n",
    "                exit_list[0][i+1] = -signal_list[0][i]\n",
    "                exit_list[1][i+1] = open_prices[i+1]\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "    return exit_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "exit_list = get_exit_entry_testing1(\n",
    "    close_prices=df['close'].values, \n",
    "    open_prices=df['open'].values,  \n",
    "    signal_list=signal_list,\n",
    "    stoploss_th=50,\n",
    "    takeprofit_th=100,\n",
    "    commission=COMMISSION, \n",
    "    slippage=SLIPPAGE, \n",
    "    init_inv=AVAILABLE_CAPITAL, \n",
    "    trade_size=TRADE_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8.0, 567961.2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(exit_list[0]), sum(exit_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 34)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.where(exit_list[0]!=0, 1, 0)), np.sum(np.where(exit_list[1]!=0, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16579. , 16538.8, 16569.5, 16562.8, 16562. , 16550. , 16490.6,\n",
       "       16526.3, 16585.7, 16587.5, 16628.7, 16721.4, 16713.5, 16710.3,\n",
       "       16716.5, 16685.4, 16633.6, 16636.5, 16668.5, 16844.7, 16844.9,\n",
       "       16801. , 16862.8, 16828.4, 16812.1, 16831.4, 16794.6, 16812.6,\n",
       "       16838.9, 16816. , 16827.3, 16819.9, 16798.8, 16761.2])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exit_list[1][exit_list[1]!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(cache=True)\n",
    "def get_signals(signal_list, exit_list):\n",
    "\n",
    "    start_idx = 0\n",
    "    exit_idx = 0\n",
    "   \n",
    "    for i in range(len(signal_list[0])):\n",
    "\n",
    "        if i == start_idx:\n",
    "\n",
    "            if signal_list[0][i] == 0:\n",
    "\n",
    "                start_idx += 1\n",
    "\n",
    "                exit_list[0][i] = 0\n",
    "\n",
    "            else:\n",
    "\n",
    "                for j in range(i+1, len(exit_list[0])):\n",
    "                    if exit_list[0][j] == -signal_list[0][i]:\n",
    "                        exit_idx = j\n",
    "                        break\n",
    "                    else:\n",
    "                        exit_idx = j\n",
    "\n",
    "                for k in range(i+1, exit_idx+1):\n",
    "                    if signal_list[0][k] == -signal_list[0][i]:\n",
    "                        exit_idx = k\n",
    "                        exit_list[1][k] = signal_list[1][k]\n",
    "                        break\n",
    "                    else:\n",
    "                        exit_idx = k\n",
    "\n",
    "                for p in range(i+1, exit_idx):\n",
    "                    signal_list[0][p] = 0\n",
    "                    exit_list[0][p] = 0\n",
    "                \n",
    "                if exit_idx == len(signal_list[0]) - 1 and exit_list[0][exit_idx] != -signal_list[0][i]:\n",
    "                    exit_list[0][exit_idx] = 0\n",
    "                    exit_list[0][i] = 0\n",
    "                    signal_list[0][exit_idx] = 0\n",
    "                else:\n",
    "                    exit_list[0][exit_idx] = -signal_list[0][i]\n",
    "                    exit_list[0][i] = 0\n",
    "                    signal_list[0][exit_idx] = 0\n",
    "                \n",
    "                start_idx = exit_idx + 1\n",
    "\n",
    "        else:\n",
    "\n",
    "            continue\n",
    "\n",
    "    if sum(np.abs(signal_list[0])) == sum(np.abs(exit_list[0])):\n",
    "\n",
    "        return signal_list, exit_list\n",
    "    \n",
    "    else:\n",
    "\n",
    "        for i in range(len(signal_list[0])):\n",
    "            if signal_list[0][-(i+1)] != 0:\n",
    "                signal_list[0][-(i+1)] = 0\n",
    "                break\n",
    "\n",
    "        return signal_list, exit_list\n",
    "    \n",
    "@njit(cache=True)\n",
    "def create_position_open_prices(signal_list, exit_list):\n",
    "\n",
    "    pos_open_prices = np.zeros(len(signal_list[0]))\n",
    "    pos_exit_prices = np.zeros(len(exit_list[0]))\n",
    "\n",
    "    start_idx = 0\n",
    "    price_idx = 0\n",
    "\n",
    "    for i in range(len(signal_list[0])):\n",
    "        if exit_list[0][i] != 0:\n",
    "            for j in range(start_idx, i):\n",
    "                if signal_list[0][j] != 0:\n",
    "                    price_idx = j\n",
    "                    break\n",
    "            pos_open_prices[i] = signal_list[1][price_idx]\n",
    "            pos_exit_prices[i] = exit_list[1][i]\n",
    "            start_idx = i\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    return pos_open_prices, pos_exit_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(cache=True)\n",
    "def get_pnl_testing(\n",
    "    trade_close_prices,\n",
    "    signal_list, \n",
    "    trade_open_prices,\n",
    "    commission=0.015,\n",
    "    slippage=0.05,\n",
    "    init_inv=20000,\n",
    "    trade_size=0.1\n",
    "):\n",
    "\n",
    "    pnl_list = np.zeros(len(trade_close_prices))\n",
    "\n",
    "    for i in range(len(trade_close_prices)):\n",
    "\n",
    "        if signal_list[i] == 0 or trade_open_prices[i] == 0:\n",
    "            pass\n",
    "        \n",
    "        # signal_list contains the points where exit occurs\n",
    "        elif signal_list[i] == -1: \n",
    "            temp_n_assets = int(init_inv * trade_size / trade_open_prices[i])\n",
    "            temp_pnl = temp_n_assets * (trade_close_prices[i] - trade_open_prices[i] * (1 + slippage)) \n",
    "            temp_pnl = temp_pnl * (1 - commission)\n",
    "            init_inv += temp_pnl\n",
    "\n",
    "        else:\n",
    "            temp_n_assets = int(init_inv * trade_size / trade_open_prices[i])\n",
    "            temp_pnl = temp_n_assets * (trade_open_prices[i] * (1 - slippage) - trade_close_prices[i])\n",
    "            temp_pnl = temp_pnl * (1 - commission)\n",
    "            init_inv += temp_pnl\n",
    "\n",
    "        pnl_list[i] = temp_pnl\n",
    "\n",
    "    return pnl_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.410714285714285"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_list, exit_list = get_signals(signal_list, exit_list)\n",
    "pos_open_prices, pos_exit_prices = create_position_open_prices(signal_list, exit_list)\n",
    "\n",
    "pnl_list = get_pnl_testing(\n",
    "    trade_close_prices=pos_exit_prices,\n",
    "    signal_list=exit_list[0], \n",
    "    trade_open_prices=pos_open_prices,\n",
    "    commission=COMMISSION, \n",
    "    slippage=SLIPPAGE, \n",
    "    init_inv=AVAILABLE_CAPITAL, \n",
    "    trade_size=TRADE_SIZE\n",
    ")\n",
    "\n",
    "winning_percent = 100 * sum(pnl_list > 0) / len(pnl_list)\n",
    "winning_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.501987281399046"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winning_percent = 100 * sum(pnl_list > 0) / np.sum(np.where(pnl_list!=0, 1, 0))\n",
    "winning_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10064"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.where(pnl_list!=0, 1, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed bar exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(cache=True)\n",
    "def get_exit_entry_testing2( \n",
    "    open_prices,  \n",
    "    signal_list,\n",
    "    n_exit_bars\n",
    "):\n",
    "\n",
    "    exit_list = np.zeros((2, len(signal_list[0])))\n",
    "\n",
    "    n_exit_bars = np.int64(n_exit_bars)\n",
    "\n",
    "    for i in range(len(signal_list[0])-1):\n",
    "\n",
    "        if signal_list[0][i] == 0:\n",
    "\n",
    "            pass\n",
    "\n",
    "        else:\n",
    "            \n",
    "            if i + n_exit_bars < len(signal_list[0]):\n",
    "                exit_list[0][i+n_exit_bars] = -signal_list[0][i]\n",
    "                exit_list[1][i+n_exit_bars] = open_prices[i+n_exit_bars]\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "    return exit_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "exit_list = get_exit_entry_testing2( \n",
    "    open_prices=df['open'].values,  \n",
    "    signal_list=signal_list,\n",
    "    n_exit_bars=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-16.0, 1067607.2)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(exit_list[0]), sum(exit_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.where(exit_list[0]!=0, 1, 0)), np.sum(np.where(exit_list[1]!=0, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.97420634920635"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_list, exit_list = get_signals(signal_list, exit_list)\n",
    "pos_open_prices, pos_exit_prices = create_position_open_prices(signal_list, exit_list)\n",
    "\n",
    "pnl_list = get_pnl_testing(\n",
    "    trade_close_prices=pos_exit_prices,\n",
    "    signal_list=exit_list[0], \n",
    "    trade_open_prices=pos_open_prices,\n",
    "    commission=COMMISSION, \n",
    "    slippage=SLIPPAGE, \n",
    "    init_inv=AVAILABLE_CAPITAL, \n",
    "    trade_size=TRADE_SIZE\n",
    ")\n",
    "\n",
    "winning_percent = 100 * sum(pnl_list > 0) / len(pnl_list)\n",
    "winning_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.04771371769384"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winning_percent = 100 * sum(pnl_list > 0) / np.sum(np.where(pnl_list!=0, 1, 0))\n",
    "winning_percent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(cache=True)\n",
    "def get_exit_entry_testing3( \n",
    "    open_prices,  \n",
    "    signal_list\n",
    "):\n",
    "\n",
    "    exit_list = np.zeros((2, len(signal_list[0])))\n",
    "\n",
    "    for i in range(len(signal_list[0])-1):\n",
    "\n",
    "        if signal_list[0][i] == 0:\n",
    "\n",
    "            pass\n",
    "\n",
    "        else:\n",
    "\n",
    "            for j in range(i+1, len(signal_list[0])):\n",
    "                if signal_list[0][j] != 0:\n",
    "                    j = j - 1\n",
    "                    break\n",
    "                else:\n",
    "                    if np.random.rand() > 0.5:\n",
    "                        break\n",
    "            \n",
    "            exit_list[0][j] = -signal_list[0][i]\n",
    "            exit_list[1][j] = open_prices[j]\n",
    "        \n",
    "    return exit_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "exit_list = get_exit_entry_testing3( \n",
    "    open_prices=df['open'].values,  \n",
    "    signal_list=signal_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-16.0, 1067603.0)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(exit_list[0]), sum(exit_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.where(exit_list[0]!=0, 1, 0)), np.sum(np.where(exit_list[1]!=0, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.172619047619047"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_list, exit_list = get_signals(signal_list, exit_list)\n",
    "pos_open_prices, pos_exit_prices = create_position_open_prices(signal_list, exit_list)\n",
    "\n",
    "pnl_list = get_pnl_testing(\n",
    "    trade_close_prices=pos_exit_prices,\n",
    "    signal_list=exit_list[0], \n",
    "    trade_open_prices=pos_open_prices,\n",
    "    commission=COMMISSION, \n",
    "    slippage=SLIPPAGE, \n",
    "    init_inv=AVAILABLE_CAPITAL, \n",
    "    trade_size=TRADE_SIZE\n",
    ")\n",
    "\n",
    "winning_percent = 100 * sum(pnl_list > 0) / len(pnl_list)\n",
    "winning_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.218523303189905"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winning_percent = 100 * sum(pnl_list > 0) / np.sum(np.where(pnl_list!=0, 1, 0))\n",
    "winning_percent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exit testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['exit_signal'] = 0\n",
    "df.loc[df.index.isin(signal_idxs_true[1:]), 'exit_signal'] = df.loc[df.index.isin(signal_idxs_true[1:]), 'signal'].values\n",
    "\n",
    "df['exit_prices'] = 0\n",
    "df.loc[df.index.isin(signal_idxs[1:]), 'exit_prices'] = df.loc[df.index.isin(signal_idxs[1:]), 'open'].values\n",
    "\n",
    "exit_list = np.zeros((2, df.shape[0]))\n",
    "exit_list[0][1:] = df['exit_signal'].values[:-1]\n",
    "exit_list[1] = df['exit_prices'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[95, 373, 396, 496, 525, 574, 609, 651, 695, 711, 732, 801, 918, 972, 1088, 1107, 1228, 1376, 1439, 1526, 1566, 1747, 1801, 1870, 1890, 1993, 2061, 2198, 2272, 2294, 2433, 2481, 2521, 2579, 2833, 2860, 2882, 2948, 2970, 3024, 3097, 3242, 3473, 3510, 3764, 3782, 3836, 3990, 4088, 4205, 4427, 4549, 4583, 4720, 4804, 4831, 4939, 4985, 5012, 5061, 5173, 5209, 5220, 5301, 5534, 5701, 5850, 5893, 5965, 6023, 6254, 6311, 6598, 6630, 6674, 6758, 6807, 6931, 7125, 7318, 7336, 7413, 7440, 7488, 7521, 7566, 7584, 7650, 7781, 7876, 7910, 8012, 8080, 8094, 8191, 8297, 8462, 8496, 8622, 8730, 8753, 8865, 8948, 9012, 9091, 9281, 9375, 9433, 9488]\n"
     ]
    }
   ],
   "source": [
    "print([i for i in range(len(exit_list[0])) if exit_list[0][i] != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[95, 373, 396, 496, 525, 574, 609, 651, 695, 711, 732, 801, 918, 972, 1088, 1107, 1228, 1376, 1439, 1526, 1566, 1747, 1801, 1870, 1890, 1993, 2061, 2198, 2272, 2294, 2433, 2481, 2521, 2579, 2833, 2860, 2882, 2948, 2970, 3024, 3097, 3242, 3473, 3510, 3764, 3782, 3836, 3990, 4088, 4205, 4427, 4549, 4583, 4720, 4804, 4831, 4939, 4985, 5012, 5061, 5173, 5209, 5220, 5301, 5534, 5701, 5850, 5893, 5965, 6023, 6254, 6311, 6598, 6630, 6674, 6758, 6807, 6931, 7125, 7318, 7336, 7413, 7440, 7488, 7521, 7566, 7584, 7650, 7781, 7876, 7910, 8012, 8080, 8094, 8191, 8297, 8462, 8496, 8622, 8730, 8753, 8865, 8948, 9012, 9091, 9281, 9375, 9433, 9488]\n"
     ]
    }
   ],
   "source": [
    "print(signal_idxs[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similar approach entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(cache=True)\n",
    "def get_entry_exit_testing1(\n",
    "    close_prices,\n",
    "    open_prices,\n",
    "    n_bars\n",
    "):\n",
    "\n",
    "    signal_list = np.zeros((2, len(close_prices)))\n",
    "\n",
    "    # n_bars = np.int64(n_bars)\n",
    "\n",
    "    for i in range(n_bars, len(signal_list[0])):\n",
    "            \n",
    "        if close_prices[i - n_bars] - close_prices[i - 1] > 0:\n",
    "            signal_list[0][i] = 1\n",
    "            signal_list[1][i] = open_prices[i]\n",
    "        elif close_prices[i - n_bars] - close_prices[i - 1] < 0:\n",
    "           signal_list[0][i] = -1\n",
    "           signal_list[1][i] = open_prices[i]\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    return signal_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_list = get_entry_exit_testing1(\n",
    "    close_prices=df['close'].values,\n",
    "    open_prices=df['open'].values,\n",
    "    n_bars=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72.0, 161171668.60000023)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(signal_list[0]), sum(signal_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9654, 9654)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.where(signal_list[0]!=0, 1, 0)), np.sum(np.where(signal_list[1]!=0, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47.291666666666664"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_list, exit_list = get_signals(signal_list, exit_list)\n",
    "pos_open_prices, pos_exit_prices = create_position_open_prices(signal_list, exit_list)\n",
    "\n",
    "pnl_list = get_pnl_testing(\n",
    "    trade_close_prices=pos_exit_prices,\n",
    "    signal_list=exit_list[0], \n",
    "    trade_open_prices=pos_open_prices,\n",
    "    commission=COMMISSION, \n",
    "    slippage=SLIPPAGE, \n",
    "    init_inv=AVAILABLE_CAPITAL, \n",
    "    trade_size=TRADE_SIZE\n",
    ")\n",
    "\n",
    "winning_percent = 100 * sum(pnl_list > 0) / len(pnl_list)\n",
    "winning_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47.3198332340679"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winning_percent = 100 * sum(pnl_list > 0) / np.sum(np.where(pnl_list!=0, 1, 0))\n",
    "winning_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(cache=True)\n",
    "def get_rsi(close_prices, prev_close_prices, length=14):\n",
    "    # Create numpy arrays to store the gain/loss values\n",
    "    gains = np.zeros(len(close_prices))\n",
    "    losses = np.zeros(len(close_prices))\n",
    "\n",
    "    # Iterate through the data frame and calculate the gain/loss for each period\n",
    "    for i in range(1, len(close_prices)):\n",
    "        change = close_prices[i] - prev_close_prices[i]\n",
    "        if change > 0:\n",
    "            gains[i] = change\n",
    "        elif change < 0:\n",
    "            losses[i] = abs(change)\n",
    "\n",
    "    # Calculate the average gain and loss for each period\n",
    "    avg_gains = np.zeros(len(close_prices))\n",
    "    avg_losses = np.zeros(len(close_prices))\n",
    "    for i in range(length, len(close_prices)):\n",
    "        avg_gains[i] = np.mean(gains[i-length:i])\n",
    "        avg_losses[i] = np.mean(losses[i-length:i])\n",
    "\n",
    "    # Calculate the relative strength and RSI for each period\n",
    "    rs = np.zeros(len(close_prices))\n",
    "    rsi = np.zeros(len(close_prices))\n",
    "    \n",
    "    for i in range(len(close_prices)):\n",
    "        if i+1 < length:\n",
    "            rsi[i] = -999\n",
    "        elif avg_losses[i] == 0:\n",
    "            rs[i] = avg_gains[i]\n",
    "            rsi[i] = 100\n",
    "        else:\n",
    "            rs[i] = avg_gains[i] / avg_losses[i]\n",
    "            rsi[i] = 100 - (100 / (1 + rs[i]))\n",
    "\n",
    "    return rsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(cache=True)\n",
    "def get_entry_exit_testing2(\n",
    "    close_prices, open_prices, prev_close_prices, rsi_window_size, rsi_threshold\n",
    "):\n",
    "\n",
    "    signal_list = np.zeros((2, len(close_prices)))\n",
    "\n",
    "    rsi = get_rsi(close_prices, prev_close_prices, length=rsi_window_size)\n",
    "\n",
    "    for i in range(len(close_prices)-1):\n",
    "\n",
    "        if i < rsi_window_size - 1 or rsi[i] == -999:\n",
    "            continue\n",
    "       \n",
    "        if rsi[i] < rsi_threshold:\n",
    "            signal_list[0][i+1] = 1\n",
    "            signal_list[1][i+1] = open_prices[i+1]\n",
    "        elif rsi[i] > (100 - rsi_threshold):\n",
    "            signal_list[0][i+1] = -1\n",
    "            signal_list[1][i+1] = open_prices[i+1]\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    return signal_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_list = get_entry_exit_testing2(\n",
    "    close_prices=df['close'].values, \n",
    "    open_prices=df['open'].values, \n",
    "    prev_close_prices=df['close'].shift(1).fillna(method='bfill').values, \n",
    "    rsi_window_size=10, \n",
    "    rsi_threshold = 20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34.0, 54070094.599999815)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(signal_list[0]), sum(signal_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3242, 3242)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.where(signal_list[0]!=0, 1, 0)), np.sum(np.where(signal_list[1]!=0, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.198412698412696"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_list, exit_list = get_signals(signal_list, exit_list)\n",
    "pos_open_prices, pos_exit_prices = create_position_open_prices(signal_list, exit_list)\n",
    "\n",
    "pnl_list = get_pnl_testing(\n",
    "    trade_close_prices=pos_exit_prices,\n",
    "    signal_list=exit_list[0], \n",
    "    trade_open_prices=pos_open_prices,\n",
    "    commission=COMMISSION, \n",
    "    slippage=SLIPPAGE, \n",
    "    init_inv=AVAILABLE_CAPITAL, \n",
    "    trade_size=TRADE_SIZE\n",
    ")\n",
    "\n",
    "winning_percent = 100 * sum(pnl_list > 0) / len(pnl_list)\n",
    "winning_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.30321105477682"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winning_percent = 100 * sum(pnl_list > 0) / np.sum(np.where(pnl_list!=0, 1, 0))\n",
    "winning_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(cache=True)\n",
    "def get_entry_exit_testing3(\n",
    "    open_prices\n",
    "):\n",
    "\n",
    "    signal_list = np.zeros((2, len(open_prices)))\n",
    "\n",
    "    for i in range(len(open_prices)-1):\n",
    "\n",
    "        if np.random.rand() > 0.7:\n",
    "            signal_list[0][i] = 1\n",
    "            signal_list[1][i] = open_prices[i]\n",
    "        elif np.random.rand() < 0.3:\n",
    "            signal_list[0][i] = -1\n",
    "            signal_list[1][i] = open_prices[i]\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    return signal_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_list = get_entry_exit_testing3(\n",
    "    open_prices=df['open'].values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(877.0, 85355821.69999993)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(signal_list[0]), sum(signal_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5113, 5113)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.where(signal_list[0]!=0, 1, 0)), np.sum(np.where(signal_list[1]!=0, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.541666666666664"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_list, exit_list = get_signals(signal_list, exit_list)\n",
    "pos_open_prices, pos_exit_prices = create_position_open_prices(signal_list, exit_list)\n",
    "\n",
    "pnl_list = get_pnl_testing(\n",
    "    trade_close_prices=pos_exit_prices,\n",
    "    signal_list=exit_list[0], \n",
    "    trade_open_prices=pos_open_prices,\n",
    "    commission=COMMISSION, \n",
    "    slippage=SLIPPAGE, \n",
    "    init_inv=AVAILABLE_CAPITAL, \n",
    "    trade_size=TRADE_SIZE\n",
    ")\n",
    "\n",
    "winning_percent = 100 * sum(pnl_list > 0) / len(pnl_list)\n",
    "winning_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.55831265508685"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winning_percent = 100 * sum(pnl_list > 0) / np.sum(np.where(pnl_list!=0, 1, 0))\n",
    "winning_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_52w_data():\n",
    "    df = pd.read_csv(Path(r'C:/\\Users/\\vchar/\\OneDrive/\\Desktop/\\ML Projects/\\Upwork/\\AlgoT_ML_Dev/\\GrammarEvolution/\\PonyGE2/\\datasets/\\BTCUSD_ohlcv.csv'))\n",
    "    # df = pd.read_csv('/kaggle/input/btcusd-test/BTCUSD_ohlcv.csv')\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "    df = df.iloc[-(7 * 60 * 24 * 52):]\n",
    "    df.sort_values('datetime', ascending=True, inplace=True)\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(524160, 6)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_52w = generate_52w_data()\n",
    "df_52w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_signal_txt = 'indicators.RSI(df=df, HistLength=10).values < 20'\n",
    "sell_signal_txt = 'indicators.RSI(df=df, HistLength=10).values > 80'\n",
    "lag_txt = '{i}'\n",
    "\n",
    "text_code = f'''import pandas as pd\n",
    "import numpy as np\n",
    "from src.fitness.indicators import indicators\n",
    "from numba import njit\n",
    "COMMISSION = 0.015\n",
    "SLIPPAGE = 0.00005\n",
    "AVAILABLE_CAPITAL = 700000\n",
    "TRADE_SIZE = 0.5\n",
    "\n",
    "@njit\n",
    "def merge_pnl(arr1, arr2):\n",
    "    out = np.zeros((len(arr1) + len(arr2)))\n",
    "    idx = 1\n",
    "    for i in range(len(arr1) + len(arr2)):\n",
    "        if i % 2 == 0:\n",
    "            out[i] = arr1[int(i/2)]\n",
    "        else:\n",
    "            out[i] = arr2[i-idx]\n",
    "        idx += 1\n",
    "    return out\n",
    "\n",
    "@njit\n",
    "def get_drawdowns(arr):\n",
    "    drawdowns = np.zeros((len(arr)))\n",
    "    max = arr[0]\n",
    "    for i in range(1, len(drawdowns)-1):\n",
    "        if arr[i-1] > arr[i] and arr[i] < arr[i+1]:\n",
    "            min = arr[i]\n",
    "            drawdowns[i] = max - min\n",
    "        elif arr[i-1] < arr[i] and arr[i] > arr[i+1]:\n",
    "            max = arr[i]\n",
    "    return drawdowns\n",
    "\n",
    "@njit\n",
    "def get_pnl(trade_close_prices, trade_open_prices, commission, slippage, init_inv, trade_size, is_buy):\n",
    "    pnl_list = np.zeros(len(trade_close_prices))\n",
    "    for i in range(len(trade_close_prices)):\n",
    "        temp_n_assets = int(init_inv * trade_size / trade_open_prices[i])\n",
    "        if is_buy == 1:\n",
    "            temp_pnl = temp_n_assets * (trade_close_prices[i] - trade_open_prices[i] * (1 + slippage))\n",
    "        else:\n",
    "            temp_pnl = -temp_n_assets * (trade_close_prices[i] - trade_open_prices[i] * (1 - slippage))\n",
    "        temp_pnl = temp_pnl * (1 - commission)\n",
    "        init_inv += temp_pnl\n",
    "        pnl_list[i] = temp_pnl\n",
    "    return pnl_list\n",
    "\n",
    "df = price_data.copy()\n",
    "# for i in range(1, 6):\n",
    "#     df[f'close_{lag_txt}'] = df['close'].shift(i)\n",
    "#     df[f'open_{lag_txt}'] = df['open'].shift(i)\n",
    "#     df[f'high_{lag_txt}'] = df['high'].shift(i)\n",
    "#     df[f'low_{lag_txt}'] = df['low'].shift(i)\n",
    "#     df[f'volume_{lag_txt}'] = df['volume'].shift(i)\n",
    "# df.dropna(inplace=True)\n",
    "# df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df['buy'] = ({buy_signal_txt}).astype(int)\n",
    "df['sell'] = ({sell_signal_txt}).astype(int)\n",
    "df['signal'] = df['buy'] + df['sell']\n",
    "df['signal'] = df['signal'].apply(lambda x: 1 if x==1 else 0)\n",
    "df['sell'] = df['sell'] * (-1)\n",
    "df['signal'] = df['signal'] * df['sell']\n",
    "df['signal'] = df['signal'] + df['buy']\n",
    "df.drop(columns=['buy', 'sell'], inplace=True)\n",
    "\n",
    "buy_idxs = []\n",
    "sell_idxs = []\n",
    "is_buy = 0\n",
    "is_sell = 0\n",
    "for i, row in enumerate(df.itertuples()):\n",
    "    if row.signal == 1 and is_buy == 0:\n",
    "        buy_idxs.append(i+1)\n",
    "        is_buy = 1\n",
    "        is_sell = 0\n",
    "    elif row.signal == -1 and is_sell == 0:\n",
    "        sell_idxs.append(i+1)\n",
    "        is_sell = 1\n",
    "        is_buy = 0\n",
    "\n",
    "if len(buy_idxs) > len(sell_idxs):\n",
    "    buy_idxs = buy_idxs[:-(len(buy_idxs) - len(sell_idxs))]\n",
    "elif len(buy_idxs) < len(sell_idxs):\n",
    "    sell_idxs = sell_idxs[:-(len(sell_idxs) - len(buy_idxs))]\n",
    "\n",
    "if len(buy_idxs) == 0 or len(sell_idxs) == 0:\n",
    "    print(\"not enough signals\")\n",
    "\n",
    "buy_prices = df[df.index.isin(buy_idxs)]['open'].values\n",
    "sell_prices = df[df.index.isin(sell_idxs)]['open'].values\n",
    "\n",
    "if buy_idxs[0] < sell_idxs[0]:\n",
    "    buy_arr = get_pnl(sell_prices, buy_prices, COMMISSION, SLIPPAGE, AVAILABLE_CAPITAL, TRADE_SIZE, 1)\n",
    "    buy_pnl = np.sum(buy_arr)\n",
    "    sell_arr = get_pnl(buy_prices[1:], sell_prices[:-1], COMMISSION, SLIPPAGE, AVAILABLE_CAPITAL, TRADE_SIZE, 0)\n",
    "    sell_pnl = np.sum(sell_arr)\n",
    "    all_arr = merge_pnl(buy_arr, sell_arr)\n",
    "else:\n",
    "    sell_arr = get_pnl(buy_prices, sell_prices, COMMISSION, SLIPPAGE, AVAILABLE_CAPITAL, TRADE_SIZE, 0)\n",
    "    sell_pnl = np.sum(sell_arr)\n",
    "    buy_arr = get_pnl(sell_prices[1:], buy_prices[:-1], COMMISSION, SLIPPAGE, AVAILABLE_CAPITAL, TRADE_SIZE, 1)\n",
    "    buy_pnl = np.sum(buy_arr)\n",
    "    all_arr = merge_pnl(sell_arr, buy_arr)\n",
    "\n",
    "total_pnl = buy_pnl + sell_pnl\n",
    "equity_curve_arr = np.cumsum(all_arr)\n",
    "drawdowns = get_drawdowns(equity_curve_arr)\n",
    "avg_drawdown = np.sum(drawdowns[drawdowns!=0]) / len(drawdowns[drawdowns!=0])\n",
    "fitness = total_pnl / avg_drawdown'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'price_data': df}\n",
    "exec(text_code, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20.931649876661233, 622.6980546194997, 13034.09765817344)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['fitness'], d['avg_drawdown'], d['total_pnl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_win_perc_entry_testing(data, strategy_df, entry2idx_dict, exit2idx_dict, init_inv, comission, trade_size):\n",
    "\n",
    "    bars_per_5week = 7 * 60 * 24 * 5\n",
    "    n_bars_per_year = 7 * 60 * 24 * 52\n",
    "\n",
    "    entry_walk_forward_dict = {}\n",
    "\n",
    "    for idx in range(0, n_bars_per_year, bars_per_5week):\n",
    "\n",
    "        temp_target_data = data.iloc[idx:idx+bars_per_5week, :]\n",
    "\n",
    "        for i in range(10):\n",
    "\n",
    "            if idx == 0:\n",
    "                entry_walk_forward_dict[i] = defaultdict(list)\n",
    "\n",
    "            # fixed stop and target exit testing\n",
    "            chosen_entry_strategy = entry2idx_dict[strategy_df.iloc[i]['Entry']]\n",
    "            chosen_exit_strategy = exit2idx_dict['get_exit_entry_testing1']\n",
    "\n",
    "            entry_dynamic_args = {\n",
    "                elem.split(':')[0].strip(): float(elem.split(':')[1].strip()) \n",
    "                for elem in strategy_df.iloc[i]['Entry params'].split(',')\n",
    "            }\n",
    "            entry_dynamic_keys = list(entry_dynamic_args.keys())\n",
    "            entry_dynamic_values = list(entry_dynamic_args.values())\n",
    "\n",
    "            exit_dynamic_args = {\n",
    "                elem.split(':')[0].strip(): float(elem.split(':')[1].strip()) \n",
    "                for elem in strategy_df.iloc[i]['Exit params'].split(',')\n",
    "            }\n",
    "            exit_dynamic_keys = list(exit_dynamic_args.keys())\n",
    "            exit_dynamic_values = list(exit_dynamic_args.values())\n",
    "\n",
    "            fixed_winning_percent = get_entry_testing_wp(\n",
    "                entry_strategy=chosen_entry_strategy,\n",
    "                entry_dynamic_keys=entry_dynamic_keys,\n",
    "                entry_dynamic_values=entry_dynamic_values,\n",
    "                exit_strategy=chosen_exit_strategy,\n",
    "                exit_dynamic_keys=exit_dynamic_keys,\n",
    "                exit_dynamic_values=exit_dynamic_values,\n",
    "                target_data=temp_target_data,\n",
    "                init_inv=init_inv, \n",
    "                comission=comission,\n",
    "                trade_size=trade_size,\n",
    "            )\n",
    "            entry_walk_forward_dict[i]['fixed_sp_testing'].append(fixed_winning_percent)\n",
    "\n",
    "            # fixed bar exit testing\n",
    "            chosen_exit_strategy = exit2idx_dict['get_exit_entry_testing2']\n",
    "            fixed_bar_winning_percent = get_entry_testing_wp(\n",
    "                entry_strategy=chosen_entry_strategy,\n",
    "                entry_dynamic_keys=entry_dynamic_keys,\n",
    "                entry_dynamic_values=entry_dynamic_values,\n",
    "                exit_strategy=chosen_exit_strategy,\n",
    "                exit_dynamic_keys=exit_dynamic_keys,\n",
    "                exit_dynamic_values=exit_dynamic_values,\n",
    "                target_data=temp_target_data,\n",
    "                init_inv=init_inv, \n",
    "                comission=comission,\n",
    "                trade_size=trade_size\n",
    "            )\n",
    "            entry_walk_forward_dict[i]['fixed_bar_testing'].append(fixed_bar_winning_percent)\n",
    "\n",
    "            # random exit testing\n",
    "            random_exit_idx = np.random.randint(strategy_df.shape[0])\n",
    "            chosen_exit_strategy = exit2idx_dict[strategy_df.iloc[random_exit_idx]['Exit']]\n",
    "\n",
    "            exit_dynamic_args = {\n",
    "                elem.split(':')[0].strip(): float(elem.split(':')[1].strip()) \n",
    "                for elem in strategy_df.iloc[random_exit_idx]['Exit params'].split(',')\n",
    "            }\n",
    "            exit_dynamic_keys = list(exit_dynamic_args.keys())\n",
    "            exit_dynamic_values = list(exit_dynamic_args.values())\n",
    "\n",
    "            random_winning_percent = get_entry_testing_wp(\n",
    "                entry_strategy=chosen_entry_strategy,\n",
    "                entry_dynamic_keys=entry_dynamic_keys,\n",
    "                entry_dynamic_values=entry_dynamic_values,\n",
    "                exit_strategy=chosen_exit_strategy,\n",
    "                exit_dynamic_keys=exit_dynamic_keys,\n",
    "                exit_dynamic_values=exit_dynamic_values,\n",
    "                target_data=temp_target_data,\n",
    "                init_inv=init_inv, \n",
    "                comission=comission,\n",
    "                trade_size=trade_size\n",
    "            )\n",
    "            entry_walk_forward_dict[i]['random_exit_testing'].append(random_winning_percent)\n",
    "\n",
    "    mean_win_perc_dict = defaultdict(list)\n",
    "\n",
    "    for k in entry_walk_forward_dict.keys():\n",
    "        mean_win_perc_dict['Fixed_StopLoss_TakeProfit_testing'].\\\n",
    "            append(np.mean(entry_walk_forward_dict[k]['fixed_sp_testing']))\n",
    "        mean_win_perc_dict['Fixed_Bar_testing'].\\\n",
    "            append(np.mean(entry_walk_forward_dict[k]['fixed_bar_testing']))\n",
    "        mean_win_perc_dict['Random_Exit_testing'].\\\n",
    "            append(np.mean(entry_walk_forward_dict[k]['random_exit_testing']))\n",
    "        \n",
    "    win_pc_df = pd.DataFrame(mean_win_perc_dict)\n",
    "    win_pc_df = pd.concat([\n",
    "        strategy_df.iloc[:10][['Entry', 'Exit', 'Entry params', 'Exit params']], \n",
    "        win_pc_df\n",
    "    ], axis=1)\n",
    "\n",
    "    return win_pc_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grammar_evol",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
