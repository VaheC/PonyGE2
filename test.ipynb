{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data():\n",
    "    df = pd.read_csv(Path(r'C:/\\Users/\\vchar/\\OneDrive/\\Desktop/\\ML Projects/\\Upwork/\\AlgoT_ML_Dev/\\GrammarEvolution/\\PonyGE2/\\datasets/\\BTCUSD_ohlcv.csv'))\n",
    "    # df = pd.read_csv('/kaggle/input/btcusd-test/BTCUSD_ohlcv.csv')\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "    df = df.iloc[-10080:]\n",
    "    df.sort_values('datetime', ascending=True, inplace=True)\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-30 20:45:00</td>\n",
       "      <td>16534.6</td>\n",
       "      <td>16537.5</td>\n",
       "      <td>16534.6</td>\n",
       "      <td>16537.5</td>\n",
       "      <td>36187.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-30 20:46:00</td>\n",
       "      <td>16537.5</td>\n",
       "      <td>16538.2</td>\n",
       "      <td>16535.6</td>\n",
       "      <td>16538.2</td>\n",
       "      <td>101860.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-30 20:47:00</td>\n",
       "      <td>16538.2</td>\n",
       "      <td>16538.2</td>\n",
       "      <td>16538.1</td>\n",
       "      <td>16538.2</td>\n",
       "      <td>102265.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-30 20:48:00</td>\n",
       "      <td>16538.2</td>\n",
       "      <td>16538.4</td>\n",
       "      <td>16538.1</td>\n",
       "      <td>16538.2</td>\n",
       "      <td>71347.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-30 20:49:00</td>\n",
       "      <td>16538.2</td>\n",
       "      <td>16538.2</td>\n",
       "      <td>16535.8</td>\n",
       "      <td>16535.9</td>\n",
       "      <td>57985.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime     open     high      low    close    volume\n",
       "0 2022-12-30 20:45:00  16534.6  16537.5  16534.6  16537.5   36187.0\n",
       "1 2022-12-30 20:46:00  16537.5  16538.2  16535.6  16538.2  101860.0\n",
       "2 2022-12-30 20:47:00  16538.2  16538.2  16538.1  16538.2  102265.0\n",
       "3 2022-12-30 20:48:00  16538.2  16538.4  16538.1  16538.2   71347.0\n",
       "4 2022-12-30 20:49:00  16538.2  16538.2  16535.8  16535.9   57985.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = generate_data()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numba import prange, njit, types\n",
    "from numba.typed import Dict\n",
    "import pandas_ta as ta\n",
    "import itertools\n",
    "import gc\n",
    "import time\n",
    "from scipy.stats import norm, iqr, chi2, chi2_contingency\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_observation(x, x_median, x_iqr, is_centered=True, is_scaled=True):\n",
    "\n",
    "    if is_centered:\n",
    "        new_x = x - x_median\n",
    "    else:\n",
    "        new_x = x.copy()\n",
    "\n",
    "    if is_scaled:\n",
    "        new_x = 100 * norm.cdf(0.25 * new_x / x_iqr) - 50\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    return new_x\n",
    "\n",
    "# Creating functions for trend indicators/variables\n",
    "\n",
    "def MA_DIFFERENCE(df, ShortLength, LongLength, Lag):\n",
    "    short_ma = ta.sma(df['close'], length=ShortLength)\n",
    "    long_ma = ta.sma(df['close'].shift(Lag), length=LongLength)\n",
    "    ma_diff = short_ma - long_ma\n",
    "    df_atr = ta.atr(high=df['high'], low=df['low'], close=df['close'], length=LongLength+Lag)\n",
    "    df_stat = ma_diff / df_atr\n",
    "    period = LongLength+Lag\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['MA_Diff']\n",
    "    return df_stat\n",
    "\n",
    "def get_ls_slope(y, length):\n",
    "    # X = np.vstack([np.arange(1, length+1), np.ones(length, dtype='int')]).T\n",
    "    # m, c = np.linalg.lstsq(X, y, rcond=None)[0]\n",
    "    x = np.arange(1, length+1)\n",
    "    # np.polyfit(x, y, 1)\n",
    "    return np.polyfit(x, y, 1)[0] #m #* np.arange(1, length+1) + c\n",
    "\n",
    "def LINEAR_PER_ATR(df, HistLength, ATRlength):\n",
    "    df_log_mean = np.log(df[['high', 'low', 'open', 'close']].mean(axis=1))\n",
    "    df_atr = ta.atr(high=df['high'], low=df['low'], close=df['close'], length=ATRlength)\n",
    "    df_slope = df_log_mean.rolling(window=HistLength).apply(lambda x: get_ls_slope(y=x, length=len(x)))\n",
    "    df_stat = df_slope / df_atr\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Price_Velocity']\n",
    "    return df_stat\n",
    "\n",
    "def get_quad_slope(y, length):\n",
    "    # X = np.vstack([np.arange(1, length+1), np.ones(length, dtype='int')]).T\n",
    "    # m, c = np.linalg.lstsq(X, y, rcond=None)[0]\n",
    "    x = np.arange(1, length+1)\n",
    "    # np.polyfit(x, y, 1)\n",
    "    return np.polyfit(x, y, 2)[0] #m #* np.arange(1, length+1) + c\n",
    "\n",
    "def QUADRATIC_PER_ATR(df, HistLength, ATRlength):\n",
    "    df_log_mean = np.log(df[['high', 'low', 'open', 'close']].mean(axis=1))\n",
    "    df_atr = ta.atr(high=df['high'], low=df['low'], close=df['close'], length=ATRlength)\n",
    "    df_slope = df_log_mean.rolling(window=HistLength).apply(lambda x: get_quad_slope(y=x, length=len(x)))\n",
    "    df_stat = df_slope / df_atr\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Price_Acceleration']\n",
    "    return df_stat\n",
    "\n",
    "def get_cubic_slope(y, length):\n",
    "    # X = np.vstack([np.arange(1, length+1), np.ones(length, dtype='int')]).T\n",
    "    # m, c = np.linalg.lstsq(X, y, rcond=None)[0]\n",
    "    x = np.arange(1, length+1)\n",
    "    # np.polyfit(x, y, 1)\n",
    "    return np.polyfit(x, y, 3)[0] #m #* np.arange(1, length+1) + c\n",
    "\n",
    "def CUBIC_PER_ATR(df, HistLength, ATRlength):\n",
    "    df_log_mean = np.log(df[['high', 'low', 'open', 'close']].mean(axis=1))\n",
    "    df_atr = ta.atr(high=df['high'], low=df['low'], close=df['close'], length=ATRlength)\n",
    "    df_slope = df_log_mean.rolling(window=HistLength).apply(lambda x: get_cubic_slope(y=x, length=len(x)))\n",
    "    df_stat = df_slope / df_atr\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Acceleration_Rate_of_Change']\n",
    "    return df_stat\n",
    "\n",
    "def RSI(df, HistLength):\n",
    "    rsi_df = ta.rsi(df['close'], length=HistLength).to_frame()\n",
    "    rsi_df.columns = ['RSI']\n",
    "    return rsi_df\n",
    "\n",
    "def STOCHASTIC_K(df, fastk_period, slowk_period, slowd_period):\n",
    "\n",
    "\tdf_stat = ta.stoch(\n",
    "\t\tdf[\"high\"], df[\"low\"], df[\"close\"], \n",
    "\t\tfastk_period, slowk_period, slowd_period)[f'STOCHk_{fastk_period}_{slowk_period}_{slowd_period}']\n",
    "\tdf_stat = df_stat.to_frame()\n",
    "\tdf_stat.columns = ['STOCHASTIC_K']\n",
    "\treturn df_stat\n",
    "\n",
    "def STOCHASTIC_D(df, fastk_period, slowk_period, slowd_period):\n",
    "\tdf_stat = ta.stoch(\n",
    "\t\tdf[\"high\"], df[\"low\"], df[\"close\"], \n",
    "\t\tfastk_period, slowk_period, slowd_period)[f'STOCHd_{fastk_period}_{slowk_period}_{slowd_period}']\n",
    "\tdf_stat = df_stat.to_frame()\n",
    "\tdf_stat.columns = ['STOCHASTIC_D']\n",
    "\treturn df_stat\n",
    "\n",
    "def PRICE_MOMENTUM(df, HistLength, StdDevLength):\n",
    "\n",
    "    df_stat = df['close'] / df['close'].shift(HistLength)\n",
    "    df_std = df['close'].rolling(window=StdDevLength).std()\n",
    "    df_stat = df_stat / df_std\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Price_Momentum']\n",
    "    return df_stat\n",
    "\n",
    "def ADX(df, HistLength):\n",
    "\tdf_stat = ta.adx(\n",
    "\t\thigh=df['high'], \n",
    "\t\tlow=df['low'], \n",
    "\t\tclose=df['close'], \n",
    "\t\tlength=HistLength\n",
    "\t)[f'ADX_{HistLength}']\n",
    "\n",
    "\tdf_stat = df_stat.to_frame()\n",
    "\tdf_stat.columns = ['ADX']\n",
    "\treturn df_stat\n",
    "\n",
    "def MIN_ADX(df, HistLength, MinLength):\n",
    "\n",
    "    adx_list = []\n",
    "\n",
    "    for i in range(MinLength):\n",
    "        temp_adx = ta.adx(\n",
    "            high=df['high'].shift(i), \n",
    "            low=df['low'].shift(i), \n",
    "            close=df['close'].shift(i), \n",
    "            length=HistLength\n",
    "        )[f'ADX_{HistLength}']\n",
    "\n",
    "        adx_list.append(temp_adx.values)\n",
    "\n",
    "    df_stat = pd.Series(np.min(np.array(adx_list), axis=0), index=temp_adx.index)\n",
    "    df_stat = df_stat.to_frame()  \n",
    "    df_stat.columns = ['Min_ADX']\n",
    "    return df_stat\n",
    "\n",
    "def RESIDUAL_MIN_ADX(df, HistLength, MinLength):\n",
    "\n",
    "    current_adx = ta.adx(\n",
    "        high=df['high'], \n",
    "        low=df['low'], \n",
    "        close=df['close'], \n",
    "        length=HistLength\n",
    "    )[f'ADX_{HistLength}']\n",
    "\n",
    "    min_adx = MIN_ADX(df, HistLength, MinLength)\n",
    "\n",
    "    df_stat = current_adx - min_adx\n",
    "\n",
    "    return df_stat\n",
    "\n",
    "def MAX_ADX(df, HistLength, MaxLength):\n",
    "\n",
    "    adx_list = []\n",
    "\n",
    "    for i in range(MaxLength):\n",
    "        temp_adx = ta.adx(\n",
    "            high=df['high'].shift(i), \n",
    "            low=df['low'].shift(i), \n",
    "            close=df['close'].shift(i), \n",
    "            length=HistLength\n",
    "        )[f'ADX_{HistLength}']\n",
    "\n",
    "        adx_list.append(temp_adx.values)\n",
    "\n",
    "    df_stat = pd.DataFrame(np.max(np.array(adx_list), axis=0), index=df.index)\n",
    "    df_stat.columns = ['MAX_ADX']\n",
    "    return df_stat\n",
    "\n",
    "def RESIDUAL_MAX_ADX(df, HistLength, MaxLength):\n",
    "\n",
    "    current_adx = ta.adx(\n",
    "        high=df['high'], \n",
    "        low=df['low'], \n",
    "        close=df['close'], \n",
    "        length=HistLength\n",
    "    )[f'ADX_{HistLength}']\n",
    "\n",
    "    max_adx = MAX_ADX(df, HistLength, MaxLength)\n",
    "\n",
    "    df_stat = max_adx - current_adx\n",
    "\n",
    "    return df_stat\n",
    "\n",
    "def DELTA_ADX(df, HistLength,  DeltaLength):\n",
    "\n",
    "    current_adx = ta.adx(\n",
    "        high=df['high'], \n",
    "        low=df['low'], \n",
    "        close=df['close'], \n",
    "        length=HistLength\n",
    "    )[f'ADX_{HistLength}']\n",
    "\n",
    "    lag_adx = ta.adx(\n",
    "        high=df['high'].shift(DeltaLength), \n",
    "        low=df['low'].shift(DeltaLength), \n",
    "        close=df['close'].shift(DeltaLength), \n",
    "        length=HistLength\n",
    "    )[f'ADX_{HistLength}']\n",
    "\n",
    "    df_stat = current_adx - lag_adx\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['ADX_Velocity']\n",
    "    return df_stat\n",
    "\n",
    "def ACCEL_ADX(df, HistLength, DeltaLength):\n",
    "\n",
    "    current_adx = ta.adx(\n",
    "        high=df['high'], \n",
    "        low=df['low'], \n",
    "        close=df['close'], \n",
    "        length=HistLength\n",
    "    )[f'ADX_{HistLength}']\n",
    "\n",
    "    lag_adx1 = ta.adx(\n",
    "        high=df['high'].shift(DeltaLength), \n",
    "        low=df['low'].shift(DeltaLength), \n",
    "        close=df['close'].shift(DeltaLength), \n",
    "        length=HistLength\n",
    "    )[f'ADX_{HistLength}']\n",
    "\n",
    "    lag_adx2 = ta.adx(\n",
    "        high=df['high'].shift(2*DeltaLength), \n",
    "        low=df['low'].shift(2*DeltaLength), \n",
    "        close=df['close'].shift(2*DeltaLength), \n",
    "        length=HistLength\n",
    "    )[f'ADX_{HistLength}']\n",
    "\n",
    "    df_stat = current_adx + lag_adx2 - 2 * lag_adx1\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['ADX_Acceleration']\n",
    "    return df_stat\n",
    "\n",
    "def INTRADAY_INTENSITY(df, HistLength):\n",
    "\n",
    "    diff1 = df['high'] - df['low']\n",
    "    diff2 = df['high'] - df['close'].shift(1)\n",
    "    diff3 = df['close'].shift(1) - df['low']\n",
    "\n",
    "    true_range = np.max(\n",
    "        np.array(\n",
    "            [\n",
    "                diff1.values, \n",
    "                diff2.values, \n",
    "                diff3.values\n",
    "             ]\n",
    "        ), \n",
    "    axis=0\n",
    "    )\n",
    "\n",
    "    current_change = df['close'] - df['open']\n",
    "\n",
    "    df_stat = current_change / true_range\n",
    "    df_stat = df_stat.rolling(window=HistLength).mean()\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Intraday_Intensity']\n",
    "    return df_stat\n",
    "\n",
    "def DELTA_INTRADAY_INTENSITY(df, HistLength, DeltaLength):\n",
    "\n",
    "    current_inten = INTRADAY_INTENSITY(df, HistLength)\n",
    "    lag_inten = INTRADAY_INTENSITY(df=df.shift(DeltaLength), HistLength=HistLength)\n",
    "    df_stat = current_inten - lag_inten\n",
    "    df_stat.columns = ['Delta_Intraday_Intensity']\n",
    "    return df_stat\n",
    "\n",
    "def REACTIVITY(df, HistLength):\n",
    "\n",
    "    price_change = df['close'] - df['close'].shift(HistLength)\n",
    "\n",
    "    max_price = df['high'].rolling(window=HistLength).max()\n",
    "    min_price = df['low'].rolling(window=HistLength).min()\n",
    "    price_range = max_price - min_price\n",
    "\n",
    "    total_volume = df['volume'].rolling(window=HistLength).sum()\n",
    "\n",
    "    ema_price_range = ta.ema(close=price_range, length=8*HistLength)\n",
    "    ema_total_volume = ta.ema(close=total_volume, length=8*HistLength)\n",
    "    aspect_ratio = (price_range / ema_price_range) / (total_volume / ema_total_volume)\n",
    "\n",
    "    raw_reactivity = price_change * aspect_ratio\n",
    "    df_stat = raw_reactivity / ema_price_range\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Reactivity']\n",
    "    return df_stat\n",
    "\n",
    "def DELTA_REACTIVITY(df, HistLength, DeltaDist):\n",
    "\n",
    "    current_reactivity = REACTIVITY(df, HistLength)\n",
    "    lag_reactivity = REACTIVITY(df=df.shift(DeltaDist), HistLength=HistLength)\n",
    "\n",
    "    stat_values = (current_reactivity - lag_reactivity).values.reshape(-1, )\n",
    "\n",
    "    df_stat = pd.Series(stat_values, index=df.index)\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Delta_Reactivity']\n",
    "    return df_stat\n",
    "\n",
    "def MIN_REACTIVITY(df, HistLength, Dist):\n",
    "\n",
    "    reactivity_list = []\n",
    "    for i in range(Dist):\n",
    "        reactivity_list.append(REACTIVITY(df=df.shift(i), HistLength=HistLength).values)\n",
    "\n",
    "    stat_values = np.min(np.array(reactivity_list), axis=0).reshape(-1, )\n",
    "\n",
    "    df_stat = pd.Series(stat_values, index=df.index)\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Min_Reactivity']\n",
    "    return df_stat\n",
    "\n",
    "def MAX_REACTIVITY(df, HistLength, Dist):\n",
    "\n",
    "    reactivity_list = []\n",
    "    for i in range(Dist):\n",
    "        reactivity_list.append(REACTIVITY(df=df.shift(i), HistLength=HistLength).values)\n",
    "\n",
    "    stat_values = np.max(np.array(reactivity_list), axis=0).reshape(-1, )\n",
    "\n",
    "    df_stat = pd.Series(stat_values, index=df.index)\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Max_Reactivity']\n",
    "    return df_stat\n",
    "\n",
    "# Creating functions for trend like indicators/variables\n",
    "\n",
    "def CLOSE_TO_CLOSE(df):\n",
    "\n",
    "    df_stat = 100 * np.log(df['close'] / df['close'].shift(1))\n",
    "    df_stat = df_stat.to_frame()\n",
    "    df_stat.columns = ['Close_to_Close']\n",
    "    return df_stat\n",
    "\n",
    "@njit\n",
    "def get_n_day_high(x, y):\n",
    "\n",
    "    N = len(x) + 1\n",
    "\n",
    "    for i in prange(len(x)-1, -1, -1):\n",
    "        if x[i] > y:\n",
    "            N = i + 1\n",
    "            break\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    return 100 * (N-1) / len(x) - 50\n",
    "\n",
    "@njit\n",
    "def get_hist_values(x, length):\n",
    "\n",
    "    hist_values = []\n",
    "\n",
    "    for i in prange(length, len(x)+1):\n",
    "\n",
    "        hist_values.append(x[i-length: i])\n",
    "\n",
    "    return hist_values\n",
    "\n",
    "def N_DAY_HIGH(df, HistLength):\n",
    "\n",
    "    list_of_values = get_hist_values(x=df['high'].values, length=HistLength)\n",
    "    # df['high'].rolling(window=HistLength, closed='left').apply(\n",
    "    #     lambda x: list_of_values.append(x.values) or 0, \n",
    "    #     raw=False\n",
    "    # )\n",
    "\n",
    "    temp_df = pd.Series(list_of_values, index=df.iloc[HistLength-1:].index)\n",
    "    temp_df = temp_df.to_frame()\n",
    "    temp_df.columns = ['high_list']\n",
    "    temp_df['high'] = df.iloc[HistLength:]['high']\n",
    "\n",
    "    df_stat = temp_df.apply(lambda x: get_n_day_high(x=x['high_list'], y=x['high']), axis=1)\n",
    "    df_stat = df_stat.to_frame()\n",
    "    df_stat.columns = ['N_Day_High']\n",
    "    return df_stat\n",
    "\n",
    "@njit\n",
    "def get_n_day_low(x, y):\n",
    "\n",
    "    N = len(x) + 1\n",
    "\n",
    "    for i in prange(len(x)-1, -1, -1):\n",
    "        if x[i] < y:\n",
    "            N = i + 1\n",
    "            break\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    return 100 * (N-1) / len(x) - 50\n",
    "\n",
    "def N_DAY_LOW(df, HistLength):\n",
    "\n",
    "    list_of_values = get_hist_values(x=df['low'].values, length=HistLength)\n",
    "    # df['low'].rolling(window=HistLength, closed='left').apply(\n",
    "    #     lambda x: list_of_values.append(x.values) or 0, \n",
    "    #     raw=False\n",
    "    # )\n",
    "\n",
    "    temp_df = pd.Series(list_of_values, index=df.iloc[HistLength-1:].index)\n",
    "    temp_df = temp_df.to_frame()\n",
    "    temp_df.columns = ['low_list']\n",
    "    temp_df['low'] = df.iloc[HistLength:]['low']\n",
    "\n",
    "    df_stat = temp_df.apply(lambda x: get_n_day_low(x=x['low_list'], y=x['low']), axis=1)\n",
    "    df_stat = df_stat.to_frame()\n",
    "    df_stat.columns = ['N_Day_Low']\n",
    "    return df_stat\n",
    "\n",
    "# Creating functions for indicators/variables of deviations from trend\n",
    "\n",
    "def CLOSE_MINUS_MOVING_AVERAGE(df, HistLen, ATRlen):\n",
    "\n",
    "    close_ratio = np.log(df['close'] / df['close'].rolling(window=HistLen).mean())\n",
    "    atr = ta.atr(high=df['high'], low=df['low'], close=df['close'], length=ATRlen)\n",
    "    df_stat = close_ratio / atr\n",
    "    period = HistLen\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['CMMA']\n",
    "    return df_stat\n",
    "\n",
    "def get_ls_fit(y):\n",
    "    length = len(y)\n",
    "    x = np.arange(1, length+1)\n",
    "    result = np.polyfit(x, y, 1)\n",
    "    y_fit = result[1] + length * result[0]\n",
    "    std_dev = np.sum((y - y_fit)**2)\n",
    "    std_error = (std_dev / (length-1)) ** 0.5\n",
    "    return [y_fit, std_error]\n",
    "\n",
    "def LINEAR_DEVIATION(df, HistLength):\n",
    "\n",
    "    df_log_mean = np.log(df[['high', 'low', 'open', 'close']].mean(axis=1))\n",
    "\n",
    "    list_of_values = get_hist_values(x=df_log_mean.values, length=HistLength)\n",
    "    # df_log_mean.rolling(window=HistLength, closed='both').apply(\n",
    "    #     lambda x: list_of_values.append(x.values) or 0, \n",
    "    #     raw=False\n",
    "    # )\n",
    "\n",
    "    temp_df = pd.Series(list_of_values, index=df.iloc[HistLength-1:].index)\n",
    "    temp_df = temp_df.apply(lambda x: get_ls_fit(y=x))\n",
    "    temp_df = pd.DataFrame(temp_df.to_list(), columns=['fit','std_error'])\n",
    "    temp_df.index = df.iloc[HistLength-1:].index\n",
    "    temp_df['log_price'] = df_log_mean.iloc[HistLength-1:]\n",
    "\n",
    "    df_stat = (temp_df['log_price'] - temp_df['fit']) / temp_df['std_error']\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Linear_Deviation']\n",
    "    return df_stat\n",
    "\n",
    "def get_quadratic_fit(y):\n",
    "    length = len(y)\n",
    "    x = np.arange(1, length+1)\n",
    "    result = np.polyfit(x, y, 2)\n",
    "    y_fit = result[2] + length * result[1] + (length**2) * result[0]\n",
    "    std_dev = np.sum((y - y_fit)**2)\n",
    "    std_error = (std_dev / (length-1)) ** 0.5\n",
    "    return [y_fit, std_error]\n",
    "\n",
    "def QUADRATIC_DEVIATION(df, HistLength):\n",
    "\n",
    "    df_log_mean = np.log(df[['high', 'low', 'open', 'close']].mean(axis=1))\n",
    "\n",
    "    # list_of_values = []\n",
    "    # df_log_mean.rolling(window=HistLength, closed='both').apply(\n",
    "    #     lambda x: list_of_values.append(x.values) or 0, \n",
    "    #     raw=False\n",
    "    # )\n",
    "    list_of_values = get_hist_values(x=df_log_mean.values, length=HistLength)\n",
    "\n",
    "    temp_df = pd.Series(list_of_values, index=df.iloc[HistLength-1:].index)\n",
    "    temp_df = temp_df.apply(lambda x: get_quadratic_fit(y=x))\n",
    "    temp_df = pd.DataFrame(temp_df.to_list(), columns=['fit','std_error'])\n",
    "    temp_df.index = df.iloc[HistLength-1:].index\n",
    "    temp_df['log_price'] = df_log_mean.iloc[HistLength-1:]\n",
    "\n",
    "    df_stat = (temp_df['log_price'] - temp_df['fit']) / temp_df['std_error']\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Quadratic_Deviation']\n",
    "    return df_stat\n",
    "\n",
    "def get_cubic_fit(y):\n",
    "    length = len(y)\n",
    "    x = np.arange(1, length+1)\n",
    "    result = np.polyfit(x, y, 3)\n",
    "    y_fit = result[3] + length * result[2] + (length**2) * result[1] + (length**3) * result[0]\n",
    "    std_dev = np.sum((y - y_fit)**2)\n",
    "    std_error = (std_dev / (length-1)) ** 0.5\n",
    "    return [y_fit, std_error]\n",
    "\n",
    "def CUBIC_DEVIATION(df, HistLength):\n",
    "\n",
    "    df_log_mean = np.log(df[['high', 'low', 'open', 'close']].mean(axis=1))\n",
    "\n",
    "    # list_of_values = []\n",
    "    # df_log_mean.rolling(window=HistLength, closed='both').apply(\n",
    "    #     lambda x: list_of_values.append(x.values) or 0, \n",
    "    #     raw=False\n",
    "    # )\n",
    "    list_of_values = get_hist_values(x=df_log_mean.values, length=HistLength)\n",
    "\n",
    "    temp_df = pd.Series(list_of_values, index=df.iloc[HistLength-1:].index)\n",
    "    temp_df = temp_df.apply(lambda x: get_cubic_fit(y=x))\n",
    "    temp_df = pd.DataFrame(temp_df.to_list(), columns=['fit','std_error'])\n",
    "    temp_df.index = df.iloc[HistLength-1:].index\n",
    "    temp_df['log_price'] = df_log_mean.iloc[HistLength-1:]\n",
    "\n",
    "    df_stat = (temp_df['log_price'] - temp_df['fit']) / temp_df['std_error']\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Cubic_Deviation']\n",
    "    return df_stat\n",
    "\n",
    "def get_ls_fit2(x, y):\n",
    "    result = np.polyfit(x, y, 1)\n",
    "    y_fit = result[1] + x[-1] * result[0]\n",
    "    return y_fit\n",
    "\n",
    "def DETRENDED_RSI(df, DetrendedLength, DetrenderLength, Lookback):\n",
    "\n",
    "    rsi_y = ta.rsi(df['close'], length=DetrendedLength)\n",
    "\n",
    "    if DetrendedLength == 2:\n",
    "        rsi_y = 1 / (1 + np.exp(-rsi_y))\n",
    "\n",
    "    rsi_x = ta.rsi(df['close'], length=DetrenderLength)\n",
    "\n",
    "    rsi_array = np.vstack([rsi_y.values, rsi_x.values]).T\n",
    "    rsi_df = pd.DataFrame(rsi_array, columns=['rsi_y', 'rsi_x'], index=rsi_y.index)\n",
    "    rsi_df.dropna(inplace=True)\n",
    "\n",
    "    # list_of_rsi_y = []\n",
    "    # rsi_df['rsi_y'].rolling(window=Lookback, closed='both').apply(\n",
    "    #     lambda x: list_of_rsi_y.append(x.values) or 0, \n",
    "    #     raw=False\n",
    "    # )\n",
    "    list_of_rsi_y = get_hist_values(x=rsi_df['rsi_y'].values, length=Lookback)\n",
    "\n",
    "    # list_of_rsi_x = []\n",
    "    # rsi_df['rsi_x'].rolling(window=Lookback, closed='both').apply(\n",
    "    #     lambda x: list_of_rsi_x.append(x.values) or 0, \n",
    "    #     raw=False\n",
    "    # )\n",
    "    list_of_rsi_x = get_hist_values(x=rsi_df['rsi_x'].values, length=Lookback)\n",
    "\n",
    "    temp_df = pd.Series(list_of_rsi_x, index=df.iloc[Lookback-1+DetrenderLength:].index)\n",
    "    temp_df = temp_df.to_frame()\n",
    "    temp_df.columns = ['rsi_x']\n",
    "    temp_df['rsi_y'] = list_of_rsi_y\n",
    "\n",
    "    temp_df['fit'] = temp_df.apply(lambda x: get_ls_fit2(x=x['rsi_x'], y=x['rsi_y']), axis=1)\n",
    "    temp_df['rsi_y'] = rsi_y.iloc[Lookback-1:]\n",
    "\n",
    "    df_stat = (temp_df['rsi_y'] - temp_df['fit'])\n",
    "    df_stat = df_stat.to_frame()\n",
    "    df_stat.columns = ['Detrended_RSI']\n",
    "    return df_stat\n",
    "\n",
    "# Creating functions for volatility indicators/variables\n",
    "\n",
    "def ABS_PRICE_CHANGE_OSCILLATOR(df, ShortLen, Multiplier):\n",
    "\n",
    "    price_changes = np.abs(np.log(df['close']/df['close'].shift(1)))\n",
    "    short_ma = price_changes.rolling(window=ShortLen).mean()\n",
    "    long_ma = price_changes.rolling(window=ShortLen*Multiplier).mean()\n",
    "    atr = ta.atr(high=df['high'], low=df['low'], close=df['close'], length=ShortLen*Multiplier)\n",
    "    df_stat = (short_ma - long_ma) / atr\n",
    "    period = ShortLen\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['APCO']\n",
    "    return df_stat\n",
    "\n",
    "def PRICE_VARIANCE_RATIO(df, HistLength, Multiplier):\n",
    "\n",
    "    log_prices = np.log(df['close'])\n",
    "    short_var = log_prices.rolling(window=HistLength).var()\n",
    "    long_var = log_prices.rolling(window=HistLength*Multiplier).var()\n",
    "    df_stat = short_var / long_var\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['PVR']\n",
    "    return df_stat\n",
    "\n",
    "def MIN_PRICE_VARIANCE_RATIO(df, HistLen, Mult, Mlength):\n",
    "\n",
    "    pvr_list = []\n",
    "\n",
    "    for i in range(Mlength):\n",
    "\n",
    "        pvr_list.append(PRICE_VARIANCE_RATIO(df=df.shift(i), HistLength=HistLen, Multiplier=Mult))\n",
    "\n",
    "    df_stat = np.min(np.array(pvr_list), axis=0)\n",
    "    df_stat = pd.DataFrame(df_stat, index=df.index)\n",
    "    df_stat.columns = ['MinPVR']\n",
    "    return df_stat\n",
    "\n",
    "def MAX_PRICE_VARIANCE_RATIO(df, HistLen, Mult, Mlength):\n",
    "\n",
    "    pvr_list = []\n",
    "\n",
    "    for i in range(Mlength):\n",
    "\n",
    "        pvr_list.append(PRICE_VARIANCE_RATIO(df=df.shift(i), HistLength=HistLen, Multiplier=Mult))\n",
    "\n",
    "    df_stat = np.max(np.array(pvr_list), axis=0)\n",
    "    df_stat = pd.DataFrame(df_stat, index=df.index)\n",
    "    df_stat.columns = ['MaxPVR']\n",
    "    return df_stat\n",
    "\n",
    "def CHANGE_VARIANCE_RATIO(df, HistLength, Multiplier):\n",
    "\n",
    "    log_prices = np.log(df['close']/df['close'].shift(1))\n",
    "    short_var = log_prices.rolling(window=HistLength).var()\n",
    "    long_var = log_prices.rolling(window=HistLength*Multiplier).var()\n",
    "    df_stat = short_var / long_var\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['CVR']\n",
    "    return df_stat\n",
    "\n",
    "def MIN_CHANGE_VARIANCE_RATIO(df, HistLen, Mult, Mlen):\n",
    "\n",
    "    pvr_list = []\n",
    "\n",
    "    for i in range(Mlen):\n",
    "\n",
    "        pvr_list.append(CHANGE_VARIANCE_RATIO(df=df.shift(i), HistLength=HistLen, Multiplier=Mult))\n",
    "\n",
    "    df_stat = np.min(np.array(pvr_list), axis=0)\n",
    "    df_stat = pd.DataFrame(df_stat, index=df.index)\n",
    "    df_stat.columns = ['MinCVR']\n",
    "    return df_stat\n",
    "\n",
    "def MAX_CHANGE_VARIANCE_RATIO(df, HistLen, Mult, Mlength):\n",
    "\n",
    "    pvr_list = []\n",
    "\n",
    "    for i in range(Mlength):\n",
    "\n",
    "        pvr_list.append(CHANGE_VARIANCE_RATIO(df=df.shift(i), HistLength=HistLen, Multiplier=Mult))\n",
    "\n",
    "    df_stat = np.max(np.array(pvr_list), axis=0)\n",
    "    df_stat = pd.DataFrame(df_stat, index=df.index)\n",
    "    df_stat.columns = ['MaxCVR']\n",
    "    return df_stat\n",
    "\n",
    "def ATR_RATIO(df, HistLength, Multiplier):\n",
    "\n",
    "    short_atr = ta.atr(high=df['high'], low=df['low'], close=df['close'], length=HistLength)\n",
    "    long_atr = ta.atr(high=df['high'], low=df['low'], close=df['close'], length=HistLength*Multiplier)\n",
    "    df_stat = short_atr / long_atr\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['ATR_Ratio']\n",
    "    return df_stat\n",
    "\n",
    "def DELTA_PRICE_VARIANCE_RATIO(df, HistLength, Multiplier):\n",
    "\n",
    "    current_pvr = PRICE_VARIANCE_RATIO(df, HistLength, Multiplier)\n",
    "    lag_value = HistLength * Multiplier\n",
    "    lag_pvr = PRICE_VARIANCE_RATIO(df=df.shift(lag_value), HistLength=HistLength, Multiplier=Multiplier)\n",
    "    df_stat = current_pvr - lag_pvr\n",
    "    df_stat.columns = ['DPVR']\n",
    "    return df_stat\n",
    "\n",
    "def DELTA_CHANGE_VARIANCE_RATIO(df, HistLength, Multiplier):\n",
    "\n",
    "    current_pvr = CHANGE_VARIANCE_RATIO(df, HistLength, Multiplier)\n",
    "    lag_value = HistLength * Multiplier\n",
    "    lag_pvr = CHANGE_VARIANCE_RATIO(df=df.shift(lag_value), HistLength=HistLength, Multiplier=Multiplier)\n",
    "    df_stat = current_pvr - lag_pvr\n",
    "    df_stat.columns = ['DCVR']\n",
    "    return df_stat\n",
    "\n",
    "def DELTA_ATR_RATIO(df, HistLength, Multiplier):\n",
    "\n",
    "    current_pvr = ATR_RATIO(df, HistLength, Multiplier)\n",
    "    lag_value = HistLength * Multiplier\n",
    "    lag_pvr = ATR_RATIO(df=df.shift(lag_value), HistLength=HistLength, Multiplier=Multiplier)\n",
    "    df_stat = current_pvr - lag_pvr\n",
    "    df_stat.columns = ['Delta_ATR_Ration']\n",
    "    return df_stat\n",
    "\n",
    "def BOLLINGER_WIDTH(df, HistLength):\n",
    "\n",
    "    mean = df['close'].rolling(window=HistLength).mean()\n",
    "    std = df['close'].rolling(window=HistLength).std()\n",
    "    df_stat = np.log(std / mean)\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Bollinger_Width']\n",
    "    return df_stat\n",
    "\n",
    "def DELTA_BOLLINGER_WIDTH(df, HistLength, DeltaLength):\n",
    "\n",
    "    current_bw = BOLLINGER_WIDTH(df, HistLength)\n",
    "    lag_bw = BOLLINGER_WIDTH(df=df.shift(DeltaLength), HistLength=HistLength)\n",
    "    df_stat = current_bw - lag_bw\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:]['Bollinger_Width'].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:]['Bollinger_Width'].values)\n",
    "    df_stat = pd.Series(df_stat.values.reshape(-1, ), index=df_stat.index)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Delta_Bollinger_Width']\n",
    "    return df_stat\n",
    "\n",
    "@njit\n",
    "def get_n_day_narrower(x, y):\n",
    "\n",
    "    N = len(x) + 1\n",
    "\n",
    "    for i in prange(len(x)-1, -1, -1):\n",
    "        if x[i] < y:\n",
    "            N = i + 1\n",
    "            break\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    return 100 * (N-1) / len(x) - 50\n",
    "\n",
    "def N_DAY_NARROWER(df, HistLength):\n",
    "\n",
    "    diff1 = df['high'] - df['low']\n",
    "    diff2 = df['high'] - df['close'].shift(1)\n",
    "    diff3 = df['close'].shift(1) - df['low']\n",
    "\n",
    "    true_range = np.max(\n",
    "        np.array(\n",
    "            [\n",
    "                diff1.values, \n",
    "                diff2.values, \n",
    "                diff3.values\n",
    "             ]\n",
    "        ), \n",
    "    axis=0\n",
    "    )\n",
    "\n",
    "    true_range = pd.Series(true_range, index=df.index)\n",
    "\n",
    "    # list_of_values = []\n",
    "    # true_range.rolling(window=HistLength, closed='left').apply(\n",
    "    #     lambda x: list_of_values.append(x.values) or 0, \n",
    "    #     raw=False\n",
    "    # )\n",
    "    list_of_values = get_hist_values(x=true_range.values, length=HistLength)\n",
    "\n",
    "    temp_df = pd.Series(list_of_values, index=df.iloc[HistLength-1:].index)\n",
    "    temp_df = temp_df.to_frame()\n",
    "    temp_df.columns = ['tr_list']\n",
    "    temp_df['tr'] = true_range.iloc[HistLength+1:]\n",
    "\n",
    "    df_stat = temp_df.apply(lambda x: get_n_day_narrower(x=x['tr_list'], y=x['tr']), axis=1)\n",
    "    df_stat = df_stat.to_frame()\n",
    "    df_stat.columns = ['N_Day_Narrower']\n",
    "    return df_stat\n",
    "\n",
    "@njit\n",
    "def get_n_day_wider(x, y):\n",
    "\n",
    "    N = len(x) + 1\n",
    "\n",
    "    for i in prange(len(x)-1, -1, -1):\n",
    "        if x[i] > y:\n",
    "            N = i + 1\n",
    "            break\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    return 100 * (N-1) / len(x) - 50\n",
    "\n",
    "def N_DAY_WIDER(df, HistLength):\n",
    "\n",
    "    diff1 = df['high'] - df['low']\n",
    "    diff2 = df['high'] - df['close'].shift(1)\n",
    "    diff3 = df['close'].shift(1) - df['low']\n",
    "\n",
    "    true_range = np.max(\n",
    "        np.array(\n",
    "            [\n",
    "                diff1.values, \n",
    "                diff2.values, \n",
    "                diff3.values\n",
    "             ]\n",
    "        ), \n",
    "    axis=0\n",
    "    )\n",
    "\n",
    "    true_range = pd.Series(true_range, index=df.index)\n",
    "\n",
    "    # list_of_values = []\n",
    "    # true_range.rolling(window=HistLength, closed='left').apply(\n",
    "    #     lambda x: list_of_values.append(x.values) or 0, \n",
    "    #     raw=False\n",
    "    # )\n",
    "    list_of_values = get_hist_values(x=true_range.values, length=HistLength)\n",
    "\n",
    "    temp_df = pd.Series(list_of_values, index=df.iloc[HistLength-1:].index)\n",
    "    temp_df = temp_df.to_frame()\n",
    "    temp_df.columns = ['tr_list']\n",
    "    temp_df['tr'] = true_range.iloc[HistLength+1:]\n",
    "\n",
    "    df_stat = temp_df.apply(lambda x: get_n_day_wider(x=x['tr_list'], y=x['tr']), axis=1)\n",
    "    df_stat = df_stat.to_frame()\n",
    "    df_stat.columns = ['N_Day_Wider']\n",
    "    return df_stat\n",
    "\n",
    "# Creating functions for basic price distribution statistics\n",
    "\n",
    "def PRICE_SKEWNESS(df, HistLength, Multiplier):\n",
    "\n",
    "    short_skew = df['close'].rolling(window=HistLength).skew()\n",
    "\n",
    "    if Multiplier > 1:\n",
    "        long_skew = df['close'].rolling(window=HistLength*Multiplier).skew()\n",
    "        df_stat = short_skew / long_skew\n",
    "    else:\n",
    "        df_stat = short_skew\n",
    "\n",
    "    df_stat = df_stat.to_frame()\n",
    "    df_stat.columns = ['Price_Skewness']\n",
    "    return df_stat\n",
    "\n",
    "def CHANGE_SKEWNESS(df, HistLength, Multiplier):\n",
    "\n",
    "    price_change = df['close'] / df['close'].shift(1)\n",
    "\n",
    "    short_skew = price_change.rolling(window=HistLength).skew()\n",
    "\n",
    "    if Multiplier > 1:\n",
    "        long_skew = price_change.rolling(window=HistLength*Multiplier).skew()\n",
    "        df_stat = short_skew / long_skew\n",
    "    else:\n",
    "        df_stat = short_skew\n",
    "\n",
    "    df_stat = df_stat.to_frame()\n",
    "    df_stat.columns = ['Change_Skewness']\n",
    "    return df_stat\n",
    "\n",
    "def PRICE_KURTOSIS(df, HistLength, Multiplier):\n",
    "\n",
    "    short_kurtosis = df['close'].rolling(window=HistLength).kurt()\n",
    "\n",
    "    if Multiplier > 1:\n",
    "        long_kurtosis = df['close'].rolling(window=HistLength*Multiplier).kurt()\n",
    "        df_stat = short_kurtosis / long_kurtosis\n",
    "    else:\n",
    "        df_stat = short_kurtosis\n",
    "\n",
    "    df_stat = df_stat.to_frame()\n",
    "    df_stat.columns = ['Price_Kurtosis']\n",
    "    return df_stat\n",
    "\n",
    "def CHANGE_KURTOSIS(df, HistLength, Multiplier):\n",
    "\n",
    "    price_change = df['close'] / df['close'].shift(1)\n",
    "\n",
    "    short_kurtosis = price_change.rolling(window=HistLength).kurt()\n",
    "\n",
    "    if Multiplier > 1:\n",
    "        long_kurtosis = price_change.rolling(window=HistLength*Multiplier).kurt()\n",
    "        df_stat = short_kurtosis / long_kurtosis\n",
    "    else:\n",
    "        df_stat = short_kurtosis\n",
    "\n",
    "    df_stat = df_stat.to_frame()\n",
    "    df_stat.columns = ['Change_Kurtosis']\n",
    "    return df_stat\n",
    "\n",
    "def DELTA_PRICE_SKEWNESS(df, HistLen, Multiplier, DeltaLen):\n",
    "\n",
    "    current_ps = PRICE_SKEWNESS(df, HistLen, Multiplier)\n",
    "    lag_ps = PRICE_SKEWNESS(df=df.shift(DeltaLen), HistLength=HistLen, Multiplier=Multiplier)\n",
    "    df_stat = current_ps - lag_ps\n",
    "    df_stat.columns = ['Delta_Price_Skewness']\n",
    "    return df_stat\n",
    "\n",
    "def DELTA_CHANGE_SKEWNESS(df, HistLen, Multiplier, DeltaLen):\n",
    "\n",
    "    current_cs = CHANGE_SKEWNESS(df, HistLen, Multiplier)\n",
    "    lag_cs = CHANGE_SKEWNESS(df=df.shift(DeltaLen), HistLength=HistLen, Multiplier=Multiplier)\n",
    "    df_stat = current_cs - lag_cs\n",
    "    df_stat.columns = ['Delta_Change_Skewness']\n",
    "    return df_stat\n",
    "\n",
    "def DELTA_PRICE_KURTOSIS(df, HistLen, Multiplier, DeltaLen):\n",
    "\n",
    "    current_pk = PRICE_KURTOSIS(df, HistLen, Multiplier)\n",
    "    lag_pk = PRICE_KURTOSIS(df=df.shift(DeltaLen), HistLength=HistLen, Multiplier=Multiplier)\n",
    "    df_stat = current_pk - lag_pk\n",
    "    df_stat.columns = ['Delta_Price_Kurtosis']\n",
    "    return df_stat\n",
    "\n",
    "def DELTA_CHANGE_KURTOSIS(df, HistLen, Multiplier, DeltaLen):\n",
    "\n",
    "    current_ck = CHANGE_KURTOSIS(df, HistLen, Multiplier)\n",
    "    lag_ck = CHANGE_KURTOSIS(df=df.shift(DeltaLen), HistLength=HistLen, Multiplier=Multiplier)\n",
    "    df_stat = current_ck - lag_ck\n",
    "    df_stat.columns = ['Delta_Change_Kurtosis']\n",
    "    return df_stat\n",
    "\n",
    "# Creating functions for indicators/variables that significantly involve volume\n",
    "\n",
    "def VOLUME_MOMENTUM(df, HistLength, Multiplier):\n",
    "\n",
    "    short_ma = df['volume'].rolling(window=HistLength).mean()\n",
    "    long_ma = df['volume'].rolling(window=HistLength*Multiplier).mean()\n",
    "    df_stat = short_ma / long_ma\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Volume_Momentum']\n",
    "    return df_stat\n",
    "\n",
    "def DELTA_VOLUME_MOMENTUM(df, HistLen, Multiplier, DeltaLen):\n",
    "\n",
    "    current_vm = CHANGE_KURTOSIS(df, HistLen, Multiplier)\n",
    "    lag_vm = CHANGE_KURTOSIS(df=df.shift(DeltaLen), HistLength=HistLen, Multiplier=Multiplier)\n",
    "    df_stat = current_vm - lag_vm\n",
    "    period = HistLen\n",
    "    x_median = df_stat.iloc[-period:]['Change_Kurtosis'].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:]['Change_Kurtosis'].values)\n",
    "    df_stat = pd.Series(df_stat.values.reshape(-1, ), index=df_stat.index)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Delta_Volume_Momentum']\n",
    "    return df_stat\n",
    "\n",
    "def VOLUME_WEIGHTED_MA_OVER_MA(df, HistLength):\n",
    "\n",
    "    volume_sum = df['volume'].rolling(window=HistLength).sum()\n",
    "    vp = df['close'] * df['volume']\n",
    "    vp_sum = vp.rolling(window=HistLength).sum()\n",
    "    ma_vw = vp_sum / volume_sum\n",
    "\n",
    "    simple_ma = df['close'].rolling(window=HistLength).mean()\n",
    "\n",
    "    df_stat = np.log(ma_vw / simple_ma)\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['VWMOM']\n",
    "    return df_stat\n",
    "\n",
    "def DIFF_VOLUME_WEIGHTED_MA_OVER_MA(df, ShortDist, LongDist):\n",
    "\n",
    "    short_vwmom = VOLUME_WEIGHTED_MA_OVER_MA(df, HistLength=ShortDist)\n",
    "    long_vwmom = VOLUME_WEIGHTED_MA_OVER_MA(df, HistLength=LongDist)\n",
    "    df_stat = short_vwmom - long_vwmom\n",
    "    period = ShortDist\n",
    "    x_median = df_stat.iloc[-period:]['VWMOM'].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:]['VWMOM'].values)\n",
    "    df_stat = pd.Series(df_stat.values.reshape(-1, ), index=df_stat.index)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Diff_VWMOM']\n",
    "    return df_stat\n",
    "\n",
    "def get_ls_slope2(x, y):\n",
    "    result = np.polyfit(x, y, 1)\n",
    "    return result[0]\n",
    "\n",
    "@njit\n",
    "def get_hist_values(x, length):\n",
    "\n",
    "    hist_values = []\n",
    "\n",
    "    for i in prange(length, len(x)+1):\n",
    "\n",
    "        hist_values.append(x[i-length: i])\n",
    "\n",
    "    return hist_values\n",
    "\n",
    "def PRICE_VOLUME_FIT(df, HistLength):\n",
    "\n",
    "    log_price = np.log(df['close'])\n",
    "\n",
    "    log_volume = np.log(df['volume']).replace(-np.inf, 0)\n",
    "\n",
    "    log_array = np.vstack([log_price.values, log_volume.values]).T\n",
    "    log_df = pd.DataFrame(log_array, columns=['log_price', 'log_volume'], index=log_price.index)\n",
    "    log_df.dropna(inplace=True)\n",
    "\n",
    "    list_of_log_price = get_hist_values(x=log_df['log_price'].values, length=HistLength)\n",
    "\n",
    "    list_of_log_volume = get_hist_values(x=log_df['log_volume'].values, length=HistLength)\n",
    "\n",
    "    index_length = len(list_of_log_volume)\n",
    "    temp_df = pd.Series(list_of_log_volume, index=df.iloc[-index_length:].index)\n",
    "    temp_df = temp_df.to_frame()\n",
    "    temp_df.columns = ['log_volume']\n",
    "    temp_df['log_price'] = list_of_log_price\n",
    "\n",
    "    temp_df['slope'] = temp_df.apply(lambda x: get_ls_slope2(x=x['log_volume'], y=x['log_price']), axis=1)\n",
    "\n",
    "    df_stat = temp_df['slope']\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Price_Volume_Fit']\n",
    "    return df_stat\n",
    "\n",
    "def DIFF_PRICE_VOLUME_FIT(df, ShortDist, LongDist):\n",
    "\n",
    "    short_pvf = PRICE_VOLUME_FIT(df, HistLength=ShortDist)\n",
    "    long_pvf = PRICE_VOLUME_FIT(df, HistLength=LongDist)\n",
    "    df_stat = short_pvf - long_pvf\n",
    "    period = ShortDist\n",
    "    x_median = df_stat.iloc[-period:]['Price_Volume_Fit'].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:]['Price_Volume_Fit'].values)\n",
    "    df_stat = pd.Series(df_stat.values.reshape(-1, ), index=df_stat.index)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Diff_PVF']\n",
    "    return df_stat\n",
    "\n",
    "def DELTA_PRICE_VOLUME_FIT(df, HistLength, DeltaDist):\n",
    "\n",
    "    current_pvf = PRICE_VOLUME_FIT(df, HistLength)\n",
    "    lag_pvf = PRICE_VOLUME_FIT(df=df.shift(DeltaDist), HistLength=HistLength)\n",
    "    df_stat = current_pvf - lag_pvf\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:]['Price_Volume_Fit'].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:]['Price_Volume_Fit'].values)\n",
    "    df_stat = pd.Series(df_stat.values.reshape(-1, ), index=df_stat.index)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Delta_PVF']\n",
    "    return df_stat\n",
    "\n",
    "def ON_BALANCE_VOLUME(df, HistLength):\n",
    "\n",
    "    bool1 = (df['close'] > df['close'].shift(1)).astype(int)\n",
    "    volume1 = df['volume'] * bool1\n",
    "    signed_volume1 = volume1.rolling(window=HistLength).sum()\n",
    "\n",
    "    bool2 = (df['close'] < df['close'].shift(1)).astype(int)\n",
    "    volume2 = df['volume'] * bool2\n",
    "    signed_volume2 = volume2.rolling(window=HistLength).sum()\n",
    "\n",
    "    signed_volume = signed_volume1 - signed_volume2\n",
    "\n",
    "    total_volume = df['volume'].rolling(window=HistLength).sum()\n",
    "\n",
    "    df_stat = signed_volume / total_volume\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = pd.Series(df_stat.values.reshape(-1, ), index=df_stat.index)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['On_Balance_Volume']\n",
    "    return df_stat\n",
    "\n",
    "def DELTA_ON_BALANCE_VOLUME(df, HistLength, DeltaDist):\n",
    "\n",
    "    current_obv = ON_BALANCE_VOLUME(df, HistLength)\n",
    "    lag_obv = ON_BALANCE_VOLUME(df=df.shift(DeltaDist), HistLength=HistLength)\n",
    "    df_stat = current_obv - lag_obv\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:]['On_Balance_Volume'].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:]['On_Balance_Volume'].values)\n",
    "    df_stat = pd.Series(df_stat.values.reshape(-1, ), index=df_stat.index)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Delta_OBV']\n",
    "    return df_stat\n",
    "\n",
    "def POSITIVE_VOLUME_INDICATOR(df, HistLength):\n",
    "\n",
    "    price_change = (df['close'] - df['close'].shift(1)) / df['close'].shift(1)\n",
    "    is_increased = (df['volume'] > df['volume'].shift(1))\n",
    "    price_change = price_change * is_increased\n",
    "    df_stat = price_change.rolling(window=HistLength).mean()\n",
    "\n",
    "    std_length = np.max([2*HistLength, 250])\n",
    "    std_price_change = price_change.rolling(window=std_length).std()\n",
    "    df_stat = df_stat / std_price_change\n",
    "\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Positive_Volume']\n",
    "    return df_stat\n",
    "\n",
    "def DELTA_POSITIVE_VOLUME_INDICATOR(df, HistLength, DeltaDist):\n",
    "\n",
    "    current_pv = POSITIVE_VOLUME_INDICATOR(df, HistLength)\n",
    "    lag_pv = POSITIVE_VOLUME_INDICATOR(df=df.shift(DeltaDist), HistLength=HistLength)\n",
    "    df_stat = current_pv - lag_pv\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:]['Positive_Volume'].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:]['Positive_Volume'].values)\n",
    "    df_stat = pd.Series(df_stat.values.reshape(-1, ), index=df_stat.index)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Delta_Positive_Volume']\n",
    "    return df_stat\n",
    "\n",
    "def NEGATIVE_VOLUME_INDICATOR(df, HistLength):\n",
    "\n",
    "    price_change = (df['close'] - df['close'].shift(1)) / df['close'].shift(1)\n",
    "    is_decreased = (df['volume'] < df['volume'].shift(1))\n",
    "    price_change = price_change * is_decreased\n",
    "    df_stat = price_change.rolling(window=HistLength).mean()\n",
    "\n",
    "    std_length = np.max([2*HistLength, 250])\n",
    "    std_price_change = price_change.rolling(window=std_length).std()\n",
    "    df_stat = df_stat / std_price_change\n",
    "\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Negative_Volume']\n",
    "    return df_stat\n",
    "\n",
    "def DELTA_NEGATIVE_VOLUME_INDICATOR(df, HistLength, DeltaDist):\n",
    "\n",
    "    current_pv = NEGATIVE_VOLUME_INDICATOR(df, HistLength)\n",
    "    lag_pv = NEGATIVE_VOLUME_INDICATOR(df=df.shift(DeltaDist), HistLength=HistLength)\n",
    "    df_stat = current_pv - lag_pv\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:]['Negative_Volume'].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:]['Negative_Volume'].values)\n",
    "    df_stat = pd.Series(df_stat.values.reshape(-1, ), index=df_stat.index)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Delta_Negative_Volume']\n",
    "    return df_stat\n",
    "\n",
    "def PRODUCT_PRICE_VOLUME(df, HistLength):\n",
    "\n",
    "    median_volume = df['volume'].rolling(window=250).median()\n",
    "    normalized_volume = df['volume'] / median_volume\n",
    "\n",
    "    price_changes = np.log(df['close']/df['close'].shift(1))\n",
    "    median_price_changes = price_changes.rolling(window=250).median()\n",
    "    quantile25 = price_changes.rolling(window=250).quantile(0.25)\n",
    "    quantile75 = price_changes.rolling(window=250).quantile(0.75)\n",
    "    iqr_price_changes = quantile75 - quantile25\n",
    "    normalized_price_changes = (price_changes - median_price_changes) / iqr_price_changes\n",
    "\n",
    "    precursor = normalized_volume * normalized_price_changes\n",
    "\n",
    "    df_stat = precursor.rolling(window=HistLength).mean()\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Product_Price_Volume']\n",
    "    return df_stat\n",
    "\n",
    "def SUM_PRICE_VOLUME(df, HistLength):\n",
    "\n",
    "    median_volume = df['volume'].rolling(window=250).median()\n",
    "    normalized_volume = df['volume'] / median_volume\n",
    "\n",
    "    price_changes = np.log(df['close']/df['close'].shift(1))\n",
    "    median_price_changes = price_changes.rolling(window=250).median()\n",
    "    quantile25 = price_changes.rolling(window=250).quantile(0.25)\n",
    "    quantile75 = price_changes.rolling(window=250).quantile(0.75)\n",
    "    iqr_price_changes = quantile75 - quantile25\n",
    "    normalized_price_changes = (price_changes - median_price_changes) / iqr_price_changes\n",
    "\n",
    "    sum_sign = np.array(list(map(lambda x: -1 if x<0 else 1, normalized_price_changes)))\n",
    "    precursor = (normalized_volume + np.abs(normalized_price_changes)) * sum_sign\n",
    "\n",
    "    df_stat = precursor.rolling(window=HistLength).mean()\n",
    "    period = HistLength\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Sum_Price_Volume']\n",
    "    return df_stat\n",
    "\n",
    "def DELTA_PRODUCT_PRICE_VOLUME(df, HistLen, DeltaDist):\n",
    "\n",
    "    current_ppv = PRODUCT_PRICE_VOLUME(df, HistLen)\n",
    "    lag_ppv = PRODUCT_PRICE_VOLUME(df=df.shift(DeltaDist), HistLength=HistLen)\n",
    "    df_stat = current_ppv - lag_ppv\n",
    "    period = HistLen\n",
    "    x_median = df_stat.iloc[-period:]['Product_Price_Volume'].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:]['Product_Price_Volume'].values)\n",
    "    df_stat = pd.Series(df_stat.values.reshape(-1, ), index=df_stat.index)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Delta_PPV']\n",
    "    return df_stat\n",
    "\n",
    "def DELTA_SUM_PRICE_VOLUME(df, HistLen, DeltaDist):\n",
    "\n",
    "    current_ppv = SUM_PRICE_VOLUME(df, HistLen)\n",
    "    lag_ppv = SUM_PRICE_VOLUME(df=df.shift(DeltaDist), HistLength=HistLen)\n",
    "    df_stat = current_ppv - lag_ppv\n",
    "    period = HistLen\n",
    "    x_median = df_stat.iloc[-period:]['Sum_Price_Volume'].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:]['Sum_Price_Volume'].values)\n",
    "    df_stat = pd.Series(df_stat.values.reshape(-1, ), index=df_stat.index)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Delta_SPV']\n",
    "    return df_stat\n",
    "\n",
    "# Creating functions for entropy and mutual information indicators/variables\n",
    "\n",
    "@njit\n",
    "def get_entropy(x):\n",
    "\n",
    "    entropy = 0\n",
    "\n",
    "    for i in prange(len(x)):\n",
    "        p = x[i] / np.sum(x)\n",
    "        entropy += -p * np.log2(p)\n",
    "\n",
    "    return entropy\n",
    "\n",
    "def PRICE_ENTROPY(df, WordLength):\n",
    "\n",
    "    length = 10 * (2 ** WordLength)\n",
    "\n",
    "    bool_list = []\n",
    "\n",
    "    for i in range(length):\n",
    "        price_bool1 = ((df['close'].shift(i) > df['close'].shift(i+1)).astype(int)).astype(str)\n",
    "        price_bool2 = ((df['close'].shift(i+1) > df['close'].shift(i+2)).astype(int)).astype(str)\n",
    "        price_bool = price_bool1 + price_bool2\n",
    "\n",
    "        bool_list.append(price_bool.values)\n",
    "\n",
    "        del price_bool1, price_bool2, price_bool\n",
    "        gc.collect()\n",
    "\n",
    "    bool_list = np.array(bool_list).T.tolist()\n",
    "\n",
    "    temp_df = pd.Series(bool_list, index=df.index).apply(lambda x: np.unique(x, return_counts=True)[1])\n",
    "    df_stat = temp_df.apply(get_entropy)\n",
    "    period = length\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Price_Entropy']\n",
    "    return df_stat\n",
    "\n",
    "def VOLUME_ENTROPY(df, WordLength):\n",
    "\n",
    "    length = 10 * (2 ** WordLength)\n",
    "\n",
    "    bool_list = []\n",
    "\n",
    "    for i in range(length):\n",
    "        volume_bool1 = ((df['volume'].shift(i) > df['volume'].shift(i+1)).astype(int)).astype(str)\n",
    "        volume_bool2 = ((df['volume'].shift(i+1) > df['volume'].shift(i+2)).astype(int)).astype(str)\n",
    "        volume_bool = volume_bool1 + volume_bool2\n",
    "\n",
    "        bool_list.append(volume_bool.values)\n",
    "\n",
    "        del volume_bool1, volume_bool2, volume_bool\n",
    "        gc.collect()  \n",
    "\n",
    "    bool_list = np.array(bool_list).T.tolist()\n",
    "\n",
    "    temp_df = pd.Series(bool_list, index=df.index).apply(lambda x: np.unique(x, return_counts=True)[1])\n",
    "    df_stat = temp_df.apply(get_entropy)\n",
    "    period = length\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Volume_Entropy']\n",
    "    return df_stat\n",
    "\n",
    "@njit\n",
    "def get_mi_data(x, length):\n",
    "    \n",
    "    xc = []\n",
    "    x1 = []\n",
    "    x2 = []\n",
    "    x3 = []\n",
    "\n",
    "    for i in prange(length, len(x)):\n",
    "\n",
    "        xc.append(x[i-length:i])\n",
    "        x1.append(x[i-length:i-1])\n",
    "        x2.append(x[i-length:i-2])\n",
    "        x3.append(x[i-length:i-3])\n",
    "\n",
    "    return xc, x1, x2, x3\n",
    "\n",
    "@njit\n",
    "def get_mi(c, x, y, z):\n",
    "\n",
    "    bool1 = np.where(c[1:] > x, 1, 0)\n",
    "    bool2 = np.where(x[1:] > y, 1, 0)\n",
    "    bool3 = np.where(y[1:] > z, 1, 0)\n",
    "\n",
    "    var23 = np.zeros(len(bool3), dtype='int')\n",
    "    var123 = np.zeros(len(bool3), dtype='int')\n",
    "\n",
    "    for i in prange(len(bool3)):\n",
    "\n",
    "        if bool2[i+1] == 0 and bool3[i] == 0:\n",
    "\n",
    "            var23[i] = 1\n",
    "\n",
    "            if bool1[i+3] == 0:\n",
    "                var123[i] = 1\n",
    "            else:\n",
    "                var123[i] = 2\n",
    "\n",
    "        elif bool2[i+1] == 1 and bool3[i] == 0:\n",
    "\n",
    "            var23[i] = 2\n",
    "\n",
    "            if bool1[i+3] == 0:\n",
    "                var123[i] = 3\n",
    "            else:\n",
    "                var123[i] = 4\n",
    "\n",
    "        elif bool2[i+1] == 0 and bool3[i] == 1:\n",
    "\n",
    "            var23[i] = 3\n",
    "\n",
    "            if bool1[i+3] == 0:\n",
    "                var123[i] = 5\n",
    "            else:\n",
    "                var123[i] = 6\n",
    "\n",
    "        else:\n",
    "\n",
    "            var23[i] = 4\n",
    "\n",
    "            if bool1[i+3] == 0:\n",
    "                var123[i] = 7\n",
    "            else:\n",
    "                var123[i] = 8\n",
    "    \n",
    "    prob1 = np.zeros(2)\n",
    "    for i in prange(2):\n",
    "        prob1[i] = np.sum(np.where(bool1==i, 1, 0))/ len(bool1)\n",
    "\n",
    "    prob23 = np.zeros(4)\n",
    "    for i in prange(1, 5):\n",
    "        prob23[i] = np.sum(np.where(var23==i, 1, 0))/ len(var23)\n",
    "\n",
    "    prob123 = np.zeros(8)\n",
    "    for i in prange(1, 9):\n",
    "        prob123[i] = np.sum(np.where(var123==i, 1, 0))/ len(var123)\n",
    "\n",
    "\n",
    "    mi = 0\n",
    "\n",
    "    for i in prange(2):\n",
    "        for j in prange(2):\n",
    "            for k in prange(2):\n",
    "                \n",
    "                if j == 0 and k == 0:\n",
    "\n",
    "                    py = prob23[0]\n",
    "\n",
    "                    if i == 0:\n",
    "                        pxy = prob123[0]\n",
    "                        px = prob1[0]\n",
    "                    else:\n",
    "                        pxy = prob123[1]\n",
    "                        px = prob1[1]\n",
    "\n",
    "                elif j == 1 and k == 0:\n",
    "\n",
    "                    py = prob23[1]\n",
    "\n",
    "                    if i == 0:\n",
    "                        pxy = prob123[2]\n",
    "                        px = prob1[0]\n",
    "                    else:\n",
    "                        pxy = prob123[3]\n",
    "                        px = prob1[1]\n",
    "\n",
    "                elif j == 0 and k == 1:\n",
    "\n",
    "                    py = prob23[2]\n",
    "\n",
    "                    if i == 0:\n",
    "                        pxy = prob123[4]\n",
    "                        px = prob1[0]\n",
    "                    else:\n",
    "                        pxy = prob123[5]\n",
    "                        px = prob1[1]\n",
    "\n",
    "                else:\n",
    "\n",
    "                    py = prob23[3]\n",
    "\n",
    "                    if i == 0:\n",
    "                        pxy = prob123[6]\n",
    "                        px = prob1[0]\n",
    "                    else:\n",
    "                        pxy = prob123[7]\n",
    "                        px = prob1[1]\n",
    "\n",
    "                if px * py == 0:\n",
    "                    mi += 0\n",
    "                else:\n",
    "                    mi += pxy * np.log(pxy/(px*py))\n",
    "\n",
    "    return mi\n",
    "\n",
    "def PRICE_MUTUAL_INFORMATION(df, WordLength):\n",
    "\n",
    "    length = 10 * (2 ** (1 + WordLength))\n",
    "\n",
    "    xc, x1, x2, x3 = get_mi_data(x=df['close'].values, length=length)\n",
    "    temp_df = pd.Series(xc, index=df.index[length:])\n",
    "    temp_df = temp_df.to_frame()\n",
    "    temp_df.columns = ['price']\n",
    "    temp_df['price_lag1'] = x1\n",
    "    temp_df['price_lag2'] = x2\n",
    "    temp_df['price_lag3'] = x3\n",
    "    df_stat = temp_df.apply(\n",
    "        lambda x: get_mi(\n",
    "            c=x['price'], \n",
    "            x=x['price_lag1'], \n",
    "            y=x['price_lag2'], \n",
    "            z=x['price_lag3']\n",
    "        ), \n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    period = length\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Price_MI']\n",
    "    return df_stat\n",
    "\n",
    "def VOLUME_MUTUAL_INFORMATION(df, WordLength):\n",
    "\n",
    "    length = 10 * (2 ** (1 + WordLength))\n",
    "\n",
    "    xc, x1, x2, x3 = get_mi_data(x=df['volume'].values, length=length)\n",
    "    temp_df = pd.Series(xc, index=df.index[length:])\n",
    "    temp_df = temp_df.to_frame()\n",
    "    temp_df.columns = ['volume']\n",
    "    temp_df['volume_lag1'] = x1\n",
    "    temp_df['volume_lag2'] = x2\n",
    "    temp_df['volume_lag3'] = x3\n",
    "    df_stat = temp_df.apply(\n",
    "        lambda x: get_mi(\n",
    "            c=x['volume'], \n",
    "            x=x['volume_lag1'], \n",
    "            y=x['volume_lag2'], \n",
    "            z=x['volume_lag3']\n",
    "        ), \n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    period = length\n",
    "    x_median = df_stat.iloc[-period:].median()\n",
    "    x_iqr = iqr(df_stat.iloc[-period:].values)\n",
    "    df_stat = df_stat.to_frame().apply(lambda x: normalize_observation(x, x_median, x_iqr))\n",
    "    df_stat.columns = ['Volume_MI']\n",
    "    return df_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit\n",
    "\n",
    "@njit\n",
    "def merge_pnl(arr1, arr2):\n",
    "    out = np.zeros((len(arr1) + len(arr2)))\n",
    "    idx = 1\n",
    "    for i in range(len(arr1) + len(arr2)):\n",
    "        if i % 2 == 0:\n",
    "            out[i] = arr1[int(i/2)]\n",
    "        else:\n",
    "            out[i] = arr2[i-idx]\n",
    "        idx += 1\n",
    "    return out\n",
    "\n",
    "@njit\n",
    "def get_drawdowns(arr):\n",
    "    drawdowns = np.zeros((len(arr)))\n",
    "    max = arr[0]\n",
    "    for i in range(1, len(drawdowns)-1):\n",
    "        if arr[i-1] > arr[i] and arr[i] < arr[i+1]:\n",
    "            min = arr[i]\n",
    "            drawdowns[i] = max - min\n",
    "        elif arr[i-1] < arr[i] and arr[i] > arr[i+1]:\n",
    "            max = arr[i]\n",
    "    return drawdowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['buy'] = (MA_DIFFERENCE(df=data, ShortLength=9, LongLength=7, Lag=478).values <= df['open'].values.reshape(-1, 1)).astype(int)\n",
    "# df['sell'] = (RSI(df=data, HistLength=9).values + df['high'].values.reshape(-1, 1) >= 0.5).astype(int)\n",
    "# df['signal'] = df['buy'] + df['sell']\n",
    "# df['signal'] = df['signal'].apply(lambda x: 1 if x==1 else 0)\n",
    "# df['sell'] = df['sell'] * (-1)\n",
    "# df['signal'] = df['signal'] * df['sell']\n",
    "# df['signal'] = df['signal'] + df['buy']\n",
    "# df.drop(columns=['buy', 'sell'], inplace=True)\n",
    "\n",
    "# df = df.assign(buy=(df.open.values.reshape(-1, 1) >= df.volume.values.reshape(-1, 1)).astype(int))\n",
    "# df = df.assign(sell=(df.volume.values.reshape(-1, 1) * df.close.values.reshape(-1, 1) <= 8.3).astype(int))\n",
    "# df = df.assign(signal = (df.buy + df.sell).values)\n",
    "# df.signal = df.signal.apply(lambda x: 1 if x==1 else 0)\n",
    "# df.sell = df.sell * (-1)\n",
    "# df.signal = df.signal * df.sell\n",
    "# df.signal = df.signal + df.buy\n",
    "# df.drop(columns=['buy', 'sell'], inplace=True)\n",
    "\n",
    "# df['buy'] = (9.2 <= df['open'].values.reshape(-1, 1)).astype(int)\n",
    "# df['sell'] = (df['high'].values.reshape(-1, 1) // df['open'].values.reshape(-1, 1) >= 9.833).astype(int)\n",
    "# df['signal'] = df['buy'] + df['sell']\n",
    "# df['signal'] = df['signal'].apply(lambda x: 1 if x==1 else 0)\n",
    "# df['sell'] = df['sell'] * (-1)\n",
    "# df['signal'] = df['signal'] * df['sell']\n",
    "# df['signal'] = df['signal'] + df['buy']\n",
    "# df.drop(columns=['buy', 'sell'], inplace=True)\n",
    "\n",
    "df['buy'] = (RSI(df=data, HistLength=10).values < 30).astype(int)\n",
    "df['sell'] = (RSI(df=data, HistLength=10).values > 70).astype(int)\n",
    "# df['buy'] = (RSI(df=data, HistLength=10).values < 20).astype(int)\n",
    "# df['sell'] = (RSI(df=data, HistLength=10).values < 30).astype(int)\n",
    "df['signal'] = df['buy'] + df['sell']\n",
    "df['signal'] = df['signal'].apply(lambda x: 1 if x==1 else 0)\n",
    "df['sell'] = df['sell'] * (-1)\n",
    "df['signal'] = df['signal'] * df['sell']\n",
    "df['signal'] = df['signal'] + df['buy']\n",
    "df.drop(columns=['buy', 'sell'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_idxs = []\n",
    "sell_idxs = []\n",
    "is_buy = 0\n",
    "is_sell = 0\n",
    "for i, row in enumerate(df.itertuples()):\n",
    "    if row.signal == 1 and is_buy == 0:\n",
    "        buy_idxs.append(i+1)\n",
    "        is_buy = 1\n",
    "        is_sell = 0\n",
    "    elif row.signal == -1 and is_sell == 0:\n",
    "        sell_idxs.append(i+1)\n",
    "        is_sell = 1\n",
    "        is_buy = 0\n",
    "if len(buy_idxs) > len(sell_idxs):\n",
    "    buy_idxs = buy_idxs[:-(len(buy_idxs) - len(sell_idxs))]\n",
    "elif len(buy_idxs) < len(sell_idxs):\n",
    "    sell_idxs = sell_idxs[:-(len(sell_idxs) - len(buy_idxs))]\n",
    "if len(buy_idxs) == 0 or len(sell_idxs) == 0:\n",
    "    fitness = -999\n",
    "buy_prices = df[df.index.isin(buy_idxs)].open.values\n",
    "sell_prices = df[df.index.isin(sell_idxs)].open.values\n",
    "if buy_idxs[0] < sell_idxs[0]:\n",
    "    buy_pnl = np.sum(sell_prices - buy_prices)\n",
    "    sell_pnl = np.sum(sell_prices[:-1] - buy_prices[1:])\n",
    "else:\n",
    "    sell_pnl = np.sum(sell_prices - buy_prices)\n",
    "    buy_pnl = np.sum(sell_prices[1:] - buy_prices[:-1])\n",
    "total_pnl = buy_pnl + sell_pnl\n",
    "if buy_idxs[0] < sell_idxs[0]:\n",
    "    buy_arr = sell_prices - buy_prices\n",
    "    sell_arr = sell_prices[:-1] - buy_prices[1:]\n",
    "    all_arr = merge_pnl(buy_arr, sell_arr)\n",
    "else:\n",
    "    sell_arr = sell_prices - buy_prices\n",
    "    buy_arr = sell_prices[1:] - buy_prices[:-1]\n",
    "    all_arr = merge_pnl(sell_arr, buy_arr)\n",
    "equity_curve_arr = np.cumsum(all_arr)\n",
    "drawdowns = get_drawdowns(equity_curve_arr)\n",
    "avg_drawdown = np.sum(drawdowns[drawdowns!=0]) / len(drawdowns[drawdowns!=0])\n",
    "fitness = total_pnl / avg_drawdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.040e+01,  2.130e+01, -1.010e+01,  2.130e+01,  0.000e+00,\n",
       "        2.130e+01,  2.000e+00,  2.130e+01,  1.700e+00,  2.130e+01,\n",
       "       -1.240e+01,  2.130e+01,  1.590e+01,  2.130e+01, -1.780e+01,\n",
       "        2.130e+01,  5.600e+00,  2.130e+01, -2.470e+01,  2.130e+01,\n",
       "        1.460e+01,  2.130e+01,  5.400e+00,  2.130e+01,  1.500e+01,\n",
       "        2.130e+01,  8.600e+00,  2.130e+01,  5.600e+00,  2.130e+01,\n",
       "        1.230e+01,  2.130e+01,  1.350e+01,  2.130e+01,  5.700e+00,\n",
       "        2.130e+01,  2.260e+01,  2.130e+01,  1.360e+01,  2.130e+01,\n",
       "        2.620e+01,  2.130e+01, -7.300e+00,  2.130e+01,  6.500e+00,\n",
       "        2.130e+01, -7.600e+00,  2.130e+01,  1.380e+01,  2.130e+01,\n",
       "       -2.690e+01,  2.130e+01, -1.510e+01,  2.130e+01, -3.300e+00,\n",
       "        2.130e+01,  5.800e+00,  2.130e+01, -1.890e+01,  2.130e+01,\n",
       "       -1.180e+01,  2.130e+01, -4.100e+00,  2.130e+01,  1.240e+01,\n",
       "        2.130e+01,  5.600e+00,  2.130e+01, -1.240e+01,  2.130e+01,\n",
       "       -6.700e+00,  2.130e+01, -3.380e+01,  2.130e+01, -1.000e+01,\n",
       "        2.130e+01, -6.450e+01,  2.130e+01,  2.000e+01,  2.130e+01,\n",
       "        3.000e-01,  2.130e+01, -7.600e+00,  2.130e+01,  1.180e+01,\n",
       "        2.130e+01, -1.450e+01,  2.130e+01,  9.300e+00,  2.130e+01,\n",
       "        5.600e+00,  2.130e+01,  1.100e+00,  2.130e+01,  8.100e+00,\n",
       "        2.130e+01,  8.900e+00,  2.130e+01,  6.400e+00,  2.130e+01,\n",
       "       -2.300e+00,  2.130e+01,  2.000e-01,  2.130e+01, -6.800e+00,\n",
       "        2.130e+01, -3.270e+01,  2.130e+01,  1.000e-01,  2.130e+01,\n",
       "       -1.440e+01,  2.130e+01,  5.400e+00,  2.130e+01,  7.800e+00,\n",
       "        2.130e+01,  1.190e+01,  2.130e+01,  3.110e+01,  2.130e+01,\n",
       "        3.700e+01,  2.130e+01,  2.400e+00,  2.130e+01, -1.370e+01,\n",
       "        2.130e+01, -3.800e+00,  2.130e+01, -1.954e+02,  2.130e+01,\n",
       "        1.010e+01,  2.130e+01, -6.100e+00,  2.130e+01,  9.300e+00,\n",
       "        2.130e+01,  3.570e+01,  2.130e+01,  3.500e+00,  2.130e+01,\n",
       "        1.180e+01,  2.130e+01, -2.900e+00,  2.130e+01, -1.850e+01,\n",
       "        2.130e+01,  2.350e+01,  2.130e+01,  1.100e+00,  2.130e+01,\n",
       "        1.500e+00,  2.130e+01, -1.060e+01,  2.130e+01,  1.300e+01,\n",
       "        2.130e+01,  8.700e+00,  2.130e+01, -5.500e+00,  2.130e+01,\n",
       "        2.000e+00,  2.130e+01,  1.300e+01,  2.130e+01, -9.500e+00,\n",
       "        2.130e+01,  8.000e-01,  2.130e+01,  1.210e+01,  2.130e+01,\n",
       "        3.070e+01,  2.130e+01, -1.590e+01,  2.130e+01,  1.640e+01,\n",
       "        2.130e+01, -6.600e+00,  2.130e+01, -2.100e+00,  2.130e+01,\n",
       "        1.380e+01,  2.130e+01,  5.400e+00,  2.130e+01, -1.580e+01,\n",
       "        2.130e+01, -1.200e+00,  2.130e+01,  1.010e+01,  2.130e+01,\n",
       "       -6.100e+00,  2.130e+01, -7.400e+00,  2.130e+01, -2.900e+00,\n",
       "        2.130e+01,  4.740e+01,  2.130e+01,  6.300e+01,  2.130e+01,\n",
       "       -3.220e+01,  2.130e+01,  1.340e+01])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.523618229678396"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[70,\n",
       " 204,\n",
       " 383,\n",
       " 525,\n",
       " 608,\n",
       " 695,\n",
       " 728,\n",
       " 885,\n",
       " 917,\n",
       " 1078,\n",
       " 1123,\n",
       " 1195,\n",
       " 1228,\n",
       " 1304,\n",
       " 1340,\n",
       " 1360,\n",
       " 1392,\n",
       " 1439,\n",
       " 1534,\n",
       " 1646,\n",
       " 1672,\n",
       " 1797,\n",
       " 1884,\n",
       " 2061,\n",
       " 2130,\n",
       " 2270,\n",
       " 2428,\n",
       " 2517,\n",
       " 2557,\n",
       " 2638,\n",
       " 2765,\n",
       " 2822,\n",
       " 2880,\n",
       " 2970,\n",
       " 3092,\n",
       " 3281,\n",
       " 3383,\n",
       " 3467,\n",
       " 3557,\n",
       " 3609,\n",
       " 3700,\n",
       " 3836,\n",
       " 3941,\n",
       " 4088,\n",
       " 4162,\n",
       " 4199,\n",
       " 4240,\n",
       " 4278,\n",
       " 4342,\n",
       " 4423,\n",
       " 4568,\n",
       " 4683,\n",
       " 4780,\n",
       " 4916,\n",
       " 5005,\n",
       " 5127,\n",
       " 5169,\n",
       " 5219,\n",
       " 5284,\n",
       " 5408,\n",
       " 5527,\n",
       " 5667,\n",
       " 5850,\n",
       " 5957,\n",
       " 6249,\n",
       " 6300,\n",
       " 6410,\n",
       " 6429,\n",
       " 6464,\n",
       " 6662,\n",
       " 6801,\n",
       " 6962,\n",
       " 7036,\n",
       " 7099,\n",
       " 7292,\n",
       " 7334,\n",
       " 7432,\n",
       " 7516,\n",
       " 7581,\n",
       " 7760,\n",
       " 7895,\n",
       " 7973,\n",
       " 8075,\n",
       " 8128,\n",
       " 8169,\n",
       " 8278,\n",
       " 8352,\n",
       " 8436,\n",
       " 8565,\n",
       " 8618,\n",
       " 8677,\n",
       " 8751,\n",
       " 8917,\n",
       " 9075,\n",
       " 9220,\n",
       " 9302,\n",
       " 9373,\n",
       " 9483,\n",
       " 9695,\n",
       " 9720,\n",
       " 9813,\n",
       " 9871]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buy_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15,\n",
       " 121,\n",
       " 347,\n",
       " 494,\n",
       " 569,\n",
       " 650,\n",
       " 711,\n",
       " 800,\n",
       " 897,\n",
       " 972,\n",
       " 1106,\n",
       " 1178,\n",
       " 1206,\n",
       " 1288,\n",
       " 1328,\n",
       " 1353,\n",
       " 1371,\n",
       " 1416,\n",
       " 1525,\n",
       " 1610,\n",
       " 1663,\n",
       " 1706,\n",
       " 1870,\n",
       " 1983,\n",
       " 2100,\n",
       " 2193,\n",
       " 2294,\n",
       " 2477,\n",
       " 2551,\n",
       " 2578,\n",
       " 2674,\n",
       " 2777,\n",
       " 2860,\n",
       " 2945,\n",
       " 3007,\n",
       " 3212,\n",
       " 3289,\n",
       " 3412,\n",
       " 3504,\n",
       " 3571,\n",
       " 3682,\n",
       " 3775,\n",
       " 3929,\n",
       " 3990,\n",
       " 4126,\n",
       " 4179,\n",
       " 4202,\n",
       " 4262,\n",
       " 4303,\n",
       " 4374,\n",
       " 4534,\n",
       " 4635,\n",
       " 4719,\n",
       " 4831,\n",
       " 4978,\n",
       " 5058,\n",
       " 5161,\n",
       " 5209,\n",
       " 5261,\n",
       " 5300,\n",
       " 5474,\n",
       " 5600,\n",
       " 5699,\n",
       " 5888,\n",
       " 6020,\n",
       " 6277,\n",
       " 6310,\n",
       " 6415,\n",
       " 6446,\n",
       " 6628,\n",
       " 6757,\n",
       " 6832,\n",
       " 6997,\n",
       " 7060,\n",
       " 7237,\n",
       " 7303,\n",
       " 7358,\n",
       " 7487,\n",
       " 7565,\n",
       " 7649,\n",
       " 7868,\n",
       " 7958,\n",
       " 7999,\n",
       " 8091,\n",
       " 8149,\n",
       " 8252,\n",
       " 8293,\n",
       " 8425,\n",
       " 8496,\n",
       " 8578,\n",
       " 8664,\n",
       " 8708,\n",
       " 8857,\n",
       " 9011,\n",
       " 9199,\n",
       " 9280,\n",
       " 9321,\n",
       " 9433,\n",
       " 9661,\n",
       " 9710,\n",
       " 9738,\n",
       " 9836]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sell_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202.90000000011423"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_pnl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.523618229678396"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>buy</th>\n",
       "      <th>sell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-30 22:05:00</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>16583.4</td>\n",
       "      <td>16583.4</td>\n",
       "      <td>4741.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-30 22:06:00</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-30 22:07:00</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>16583.4</td>\n",
       "      <td>16583.4</td>\n",
       "      <td>34811.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-30 22:08:00</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-30 22:09:00</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>16583.5</td>\n",
       "      <td>5783.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime     open     high      low    close   volume  buy  sell\n",
       "0 2022-12-30 22:05:00  16583.5  16583.5  16583.4  16583.4   4741.0    0     0\n",
       "1 2022-12-30 22:06:00  16583.5  16583.5  16583.5  16583.5     22.0    0     0\n",
       "2 2022-12-30 22:07:00  16583.5  16583.5  16583.4  16583.4  34811.0    0     0\n",
       "3 2022-12-30 22:08:00  16583.5  16583.5  16583.5  16583.5     20.0    0     0\n",
       "4 2022-12-30 22:09:00  16583.5  16583.5  16583.5  16583.5   5783.0    0     0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['buy'].sum(), df['sell'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([44.6])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equity_curve_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(np.arange(len(equity_curve_arr)), equity_curve_arr)\n",
    "for i in range(len(drawdowns)):\n",
    "    if drawdowns[i] != 0:\n",
    "        plt.plot(i, equity_curve_arr[i] - 10, marker='^', color='orange')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.874277777777778"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "17547.4 / (60 * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BTC and ETH merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>btc_open</th>\n",
       "      <th>btc_high</th>\n",
       "      <th>btc_low</th>\n",
       "      <th>btc_close</th>\n",
       "      <th>btc_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-09-04 17:50:00</td>\n",
       "      <td>58052.27</td>\n",
       "      <td>58055.91</td>\n",
       "      <td>57961.70</td>\n",
       "      <td>57975.48</td>\n",
       "      <td>6.286958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-09-04 17:51:00</td>\n",
       "      <td>57975.48</td>\n",
       "      <td>58014.30</td>\n",
       "      <td>57945.01</td>\n",
       "      <td>57948.03</td>\n",
       "      <td>13.541664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-09-04 17:52:00</td>\n",
       "      <td>57948.03</td>\n",
       "      <td>57948.03</td>\n",
       "      <td>57888.06</td>\n",
       "      <td>57892.97</td>\n",
       "      <td>11.412409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-09-04 17:53:00</td>\n",
       "      <td>57889.36</td>\n",
       "      <td>57898.18</td>\n",
       "      <td>57836.55</td>\n",
       "      <td>57857.49</td>\n",
       "      <td>6.163645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-09-04 17:54:00</td>\n",
       "      <td>57857.51</td>\n",
       "      <td>57915.60</td>\n",
       "      <td>57857.51</td>\n",
       "      <td>57912.29</td>\n",
       "      <td>8.040556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime  btc_open  btc_high   btc_low  btc_close  btc_volume\n",
       "0 2024-09-04 17:50:00  58052.27  58055.91  57961.70   57975.48    6.286958\n",
       "1 2024-09-04 17:51:00  57975.48  58014.30  57945.01   57948.03   13.541664\n",
       "2 2024-09-04 17:52:00  57948.03  57948.03  57888.06   57892.97   11.412409\n",
       "3 2024-09-04 17:53:00  57889.36  57898.18  57836.55   57857.49    6.163645\n",
       "4 2024-09-04 17:54:00  57857.51  57915.60  57857.51   57912.29    8.040556"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_btc = pd.read_csv(Path(r'C:/\\Users/\\vchar/\\OneDrive/\\Desktop/\\ML Projects/\\Upwork/\\AlgoT_ML_Dev/\\GrammarEvolution/\\PonyGE2/\\datasets/\\BTC-1m.csv'))\n",
    "# df_btc = pd.read_csv('/kaggle/input/btcusd-test/BTCUSD_ohlcv.csv')\n",
    "df_btc['datetime'] = pd.to_datetime(df_btc['datetime'])\n",
    "df_btc = df_btc.iloc[-10000:]\n",
    "df_btc.sort_values('datetime', ascending=True, inplace=True)\n",
    "df_btc.reset_index(inplace=True, drop=True)\n",
    "df_btc.rename(\n",
    "    columns={\n",
    "        'open': 'btc_open', \n",
    "        'close': 'btc_close', \n",
    "        'low': 'btc_low', \n",
    "        'high': 'btc_high', \n",
    "        'volume': 'btc_volume'\n",
    "    },\n",
    "    inplace=True\n",
    ")\n",
    "df_btc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>btc_open</th>\n",
       "      <th>btc_high</th>\n",
       "      <th>btc_low</th>\n",
       "      <th>btc_close</th>\n",
       "      <th>btc_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2024-09-11 16:25:00</td>\n",
       "      <td>56864.38</td>\n",
       "      <td>56923.75</td>\n",
       "      <td>56847.32</td>\n",
       "      <td>56903.83</td>\n",
       "      <td>12.777984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>2024-09-11 16:26:00</td>\n",
       "      <td>56904.37</td>\n",
       "      <td>56916.37</td>\n",
       "      <td>56788.22</td>\n",
       "      <td>56808.40</td>\n",
       "      <td>10.192957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>2024-09-11 16:27:00</td>\n",
       "      <td>56804.54</td>\n",
       "      <td>56821.79</td>\n",
       "      <td>56787.89</td>\n",
       "      <td>56798.19</td>\n",
       "      <td>2.912109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>2024-09-11 16:28:00</td>\n",
       "      <td>56798.19</td>\n",
       "      <td>56831.83</td>\n",
       "      <td>56793.29</td>\n",
       "      <td>56830.72</td>\n",
       "      <td>3.706732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>2024-09-11 16:29:00</td>\n",
       "      <td>56828.08</td>\n",
       "      <td>56864.97</td>\n",
       "      <td>56828.08</td>\n",
       "      <td>56848.40</td>\n",
       "      <td>3.865301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                datetime  btc_open  btc_high   btc_low  btc_close  btc_volume\n",
       "9995 2024-09-11 16:25:00  56864.38  56923.75  56847.32   56903.83   12.777984\n",
       "9996 2024-09-11 16:26:00  56904.37  56916.37  56788.22   56808.40   10.192957\n",
       "9997 2024-09-11 16:27:00  56804.54  56821.79  56787.89   56798.19    2.912109\n",
       "9998 2024-09-11 16:28:00  56798.19  56831.83  56793.29   56830.72    3.706732\n",
       "9999 2024-09-11 16:29:00  56828.08  56864.97  56828.08   56848.40    3.865301"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_btc.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>eth_open</th>\n",
       "      <th>eth_high</th>\n",
       "      <th>eth_low</th>\n",
       "      <th>eth_close</th>\n",
       "      <th>eth_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-09-07 14:22:00</td>\n",
       "      <td>2295.48</td>\n",
       "      <td>2295.48</td>\n",
       "      <td>2292.22</td>\n",
       "      <td>2292.22</td>\n",
       "      <td>8.133025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-09-07 14:23:00</td>\n",
       "      <td>2292.23</td>\n",
       "      <td>2293.17</td>\n",
       "      <td>2291.09</td>\n",
       "      <td>2292.84</td>\n",
       "      <td>18.279947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-09-07 14:24:00</td>\n",
       "      <td>2292.75</td>\n",
       "      <td>2293.33</td>\n",
       "      <td>2291.55</td>\n",
       "      <td>2292.98</td>\n",
       "      <td>12.682892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-09-07 14:25:00</td>\n",
       "      <td>2292.98</td>\n",
       "      <td>2293.07</td>\n",
       "      <td>2291.24</td>\n",
       "      <td>2292.00</td>\n",
       "      <td>29.546565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-09-07 14:26:00</td>\n",
       "      <td>2291.81</td>\n",
       "      <td>2294.84</td>\n",
       "      <td>2291.80</td>\n",
       "      <td>2294.80</td>\n",
       "      <td>7.415414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime  eth_open  eth_high  eth_low  eth_close  eth_volume\n",
       "0 2024-09-07 14:22:00   2295.48   2295.48  2292.22    2292.22    8.133025\n",
       "1 2024-09-07 14:23:00   2292.23   2293.17  2291.09    2292.84   18.279947\n",
       "2 2024-09-07 14:24:00   2292.75   2293.33  2291.55    2292.98   12.682892\n",
       "3 2024-09-07 14:25:00   2292.98   2293.07  2291.24    2292.00   29.546565\n",
       "4 2024-09-07 14:26:00   2291.81   2294.84  2291.80    2294.80    7.415414"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eth = pd.read_csv(Path(r'C:/\\Users/\\vchar/\\OneDrive/\\Desktop/\\ML Projects/\\Upwork/\\AlgoT_ML_Dev/\\GrammarEvolution/\\PonyGE2/\\datasets/\\ETH-1m.csv'))\n",
    "# df_eth = pd.read_csv('/kaggle/input/btcusd-test/BTCUSD_ohlcv.csv')\n",
    "df_eth['datetime'] = pd.to_datetime(df_eth['datetime'])\n",
    "df_eth = df_eth.iloc[-10000:]\n",
    "df_eth.sort_values('datetime', ascending=True, inplace=True)\n",
    "df_eth.reset_index(inplace=True, drop=True)\n",
    "df_eth.rename(\n",
    "    columns={\n",
    "        'open': 'eth_open', \n",
    "        'close': 'eth_close', \n",
    "        'low': 'eth_low', \n",
    "        'high': 'eth_high', \n",
    "        'volume': 'eth_volume'\n",
    "    },\n",
    "    inplace=True\n",
    ")\n",
    "df_eth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>eth_open</th>\n",
       "      <th>eth_high</th>\n",
       "      <th>eth_low</th>\n",
       "      <th>eth_close</th>\n",
       "      <th>eth_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2024-09-14 12:57:00</td>\n",
       "      <td>2421.30</td>\n",
       "      <td>2421.45</td>\n",
       "      <td>2420.28</td>\n",
       "      <td>2421.45</td>\n",
       "      <td>37.802834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>2024-09-14 12:58:00</td>\n",
       "      <td>2421.39</td>\n",
       "      <td>2421.44</td>\n",
       "      <td>2421.02</td>\n",
       "      <td>2421.24</td>\n",
       "      <td>3.580702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>2024-09-14 12:59:00</td>\n",
       "      <td>2421.24</td>\n",
       "      <td>2421.70</td>\n",
       "      <td>2421.12</td>\n",
       "      <td>2421.44</td>\n",
       "      <td>15.611558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>2024-09-14 13:00:00</td>\n",
       "      <td>2421.46</td>\n",
       "      <td>2421.52</td>\n",
       "      <td>2420.57</td>\n",
       "      <td>2421.40</td>\n",
       "      <td>10.753724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>2024-09-14 13:01:00</td>\n",
       "      <td>2421.26</td>\n",
       "      <td>2421.29</td>\n",
       "      <td>2420.61</td>\n",
       "      <td>2420.61</td>\n",
       "      <td>4.673591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                datetime  eth_open  eth_high  eth_low  eth_close  eth_volume\n",
       "9995 2024-09-14 12:57:00   2421.30   2421.45  2420.28    2421.45   37.802834\n",
       "9996 2024-09-14 12:58:00   2421.39   2421.44  2421.02    2421.24    3.580702\n",
       "9997 2024-09-14 12:59:00   2421.24   2421.70  2421.12    2421.44   15.611558\n",
       "9998 2024-09-14 13:00:00   2421.46   2421.52  2420.57    2421.40   10.753724\n",
       "9999 2024-09-14 13:01:00   2421.26   2421.29  2420.61    2420.61    4.673591"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eth.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>sol_open</th>\n",
       "      <th>sol_high</th>\n",
       "      <th>sol_low</th>\n",
       "      <th>sol_close</th>\n",
       "      <th>sol_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-11-22 12:01:00</td>\n",
       "      <td>54.50</td>\n",
       "      <td>54.52</td>\n",
       "      <td>54.47</td>\n",
       "      <td>54.51</td>\n",
       "      <td>475.244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-11-22 12:02:00</td>\n",
       "      <td>54.52</td>\n",
       "      <td>54.52</td>\n",
       "      <td>54.49</td>\n",
       "      <td>54.52</td>\n",
       "      <td>371.520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-11-22 12:03:00</td>\n",
       "      <td>54.50</td>\n",
       "      <td>54.63</td>\n",
       "      <td>54.50</td>\n",
       "      <td>54.63</td>\n",
       "      <td>538.134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-11-22 12:04:00</td>\n",
       "      <td>54.63</td>\n",
       "      <td>54.72</td>\n",
       "      <td>54.54</td>\n",
       "      <td>54.72</td>\n",
       "      <td>87.496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-11-22 12:05:00</td>\n",
       "      <td>54.72</td>\n",
       "      <td>54.72</td>\n",
       "      <td>54.70</td>\n",
       "      <td>54.70</td>\n",
       "      <td>4112.125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime  sol_open  sol_high  sol_low  sol_close  sol_volume\n",
       "0 2023-11-22 12:01:00     54.50     54.52    54.47      54.51     475.244\n",
       "1 2023-11-22 12:02:00     54.52     54.52    54.49      54.52     371.520\n",
       "2 2023-11-22 12:03:00     54.50     54.63    54.50      54.63     538.134\n",
       "3 2023-11-22 12:04:00     54.63     54.72    54.54      54.72      87.496\n",
       "4 2023-11-22 12:05:00     54.72     54.72    54.70      54.70    4112.125"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sol = pd.read_csv(Path(r'C:/\\Users/\\vchar/\\OneDrive/\\Desktop/\\ML Projects/\\Upwork/\\AlgoT_ML_Dev/\\GrammarEvolution/\\PonyGE2/\\datasets/\\SOL-1m.csv'))\n",
    "# df_sol = pd.read_csv('/kaggle/input/btcusd-test/BTCUSD_ohlcv.csv')\n",
    "df_sol['datetime'] = pd.to_datetime(df_sol['datetime'])\n",
    "df_sol = df_sol.iloc[-10000:]\n",
    "df_sol.sort_values('datetime', ascending=True, inplace=True)\n",
    "df_sol.reset_index(inplace=True, drop=True)\n",
    "df_sol.rename(\n",
    "    columns={\n",
    "        'open': 'sol_open', \n",
    "        'close': 'sol_close', \n",
    "        'low': 'sol_low', \n",
    "        'high': 'sol_high', \n",
    "        'volume': 'sol_volume'\n",
    "    },\n",
    "    inplace=True\n",
    ")\n",
    "df_sol.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>sol_open</th>\n",
       "      <th>sol_high</th>\n",
       "      <th>sol_low</th>\n",
       "      <th>sol_close</th>\n",
       "      <th>sol_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2023-11-29 10:40:00</td>\n",
       "      <td>60.21</td>\n",
       "      <td>60.31</td>\n",
       "      <td>60.04</td>\n",
       "      <td>60.31</td>\n",
       "      <td>2471.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>2023-11-29 10:41:00</td>\n",
       "      <td>60.32</td>\n",
       "      <td>60.32</td>\n",
       "      <td>60.22</td>\n",
       "      <td>60.26</td>\n",
       "      <td>417.767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>2023-11-29 10:42:00</td>\n",
       "      <td>60.28</td>\n",
       "      <td>60.30</td>\n",
       "      <td>60.22</td>\n",
       "      <td>60.30</td>\n",
       "      <td>541.638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>2023-11-29 10:43:00</td>\n",
       "      <td>60.32</td>\n",
       "      <td>60.45</td>\n",
       "      <td>60.29</td>\n",
       "      <td>60.33</td>\n",
       "      <td>1013.428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>2023-11-29 10:44:00</td>\n",
       "      <td>60.26</td>\n",
       "      <td>60.31</td>\n",
       "      <td>60.16</td>\n",
       "      <td>60.19</td>\n",
       "      <td>1979.268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                datetime  sol_open  sol_high  sol_low  sol_close  sol_volume\n",
       "9995 2023-11-29 10:40:00     60.21     60.31    60.04      60.31    2471.730\n",
       "9996 2023-11-29 10:41:00     60.32     60.32    60.22      60.26     417.767\n",
       "9997 2023-11-29 10:42:00     60.28     60.30    60.22      60.30     541.638\n",
       "9998 2023-11-29 10:43:00     60.32     60.45    60.29      60.33    1013.428\n",
       "9999 2023-11-29 10:44:00     60.26     60.31    60.16      60.19    1979.268"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sol.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>btc_open</th>\n",
       "      <th>btc_high</th>\n",
       "      <th>btc_low</th>\n",
       "      <th>btc_close</th>\n",
       "      <th>btc_volume</th>\n",
       "      <th>eth_open</th>\n",
       "      <th>eth_high</th>\n",
       "      <th>eth_low</th>\n",
       "      <th>eth_close</th>\n",
       "      <th>eth_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-09-07 14:22:00</td>\n",
       "      <td>54626.71</td>\n",
       "      <td>54626.71</td>\n",
       "      <td>54575.54</td>\n",
       "      <td>54587.68</td>\n",
       "      <td>3.029570</td>\n",
       "      <td>2295.48</td>\n",
       "      <td>2295.48</td>\n",
       "      <td>2292.22</td>\n",
       "      <td>2292.22</td>\n",
       "      <td>8.133025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-09-07 14:23:00</td>\n",
       "      <td>54579.67</td>\n",
       "      <td>54596.70</td>\n",
       "      <td>54557.25</td>\n",
       "      <td>54588.69</td>\n",
       "      <td>4.557107</td>\n",
       "      <td>2292.23</td>\n",
       "      <td>2293.17</td>\n",
       "      <td>2291.09</td>\n",
       "      <td>2292.84</td>\n",
       "      <td>18.279947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-09-07 14:24:00</td>\n",
       "      <td>54585.02</td>\n",
       "      <td>54605.49</td>\n",
       "      <td>54568.01</td>\n",
       "      <td>54605.49</td>\n",
       "      <td>3.003662</td>\n",
       "      <td>2292.75</td>\n",
       "      <td>2293.33</td>\n",
       "      <td>2291.55</td>\n",
       "      <td>2292.98</td>\n",
       "      <td>12.682892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-09-07 14:25:00</td>\n",
       "      <td>54605.49</td>\n",
       "      <td>54609.63</td>\n",
       "      <td>54581.65</td>\n",
       "      <td>54587.49</td>\n",
       "      <td>0.997784</td>\n",
       "      <td>2292.98</td>\n",
       "      <td>2293.07</td>\n",
       "      <td>2291.24</td>\n",
       "      <td>2292.00</td>\n",
       "      <td>29.546565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-09-07 14:26:00</td>\n",
       "      <td>54586.10</td>\n",
       "      <td>54658.16</td>\n",
       "      <td>54586.10</td>\n",
       "      <td>54658.16</td>\n",
       "      <td>2.026429</td>\n",
       "      <td>2291.81</td>\n",
       "      <td>2294.84</td>\n",
       "      <td>2291.80</td>\n",
       "      <td>2294.80</td>\n",
       "      <td>7.415414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime  btc_open  btc_high   btc_low  btc_close  btc_volume  \\\n",
       "0 2024-09-07 14:22:00  54626.71  54626.71  54575.54   54587.68    3.029570   \n",
       "1 2024-09-07 14:23:00  54579.67  54596.70  54557.25   54588.69    4.557107   \n",
       "2 2024-09-07 14:24:00  54585.02  54605.49  54568.01   54605.49    3.003662   \n",
       "3 2024-09-07 14:25:00  54605.49  54609.63  54581.65   54587.49    0.997784   \n",
       "4 2024-09-07 14:26:00  54586.10  54658.16  54586.10   54658.16    2.026429   \n",
       "\n",
       "   eth_open  eth_high  eth_low  eth_close  eth_volume  \n",
       "0   2295.48   2295.48  2292.22    2292.22    8.133025  \n",
       "1   2292.23   2293.17  2291.09    2292.84   18.279947  \n",
       "2   2292.75   2293.33  2291.55    2292.98   12.682892  \n",
       "3   2292.98   2293.07  2291.24    2292.00   29.546565  \n",
       "4   2291.81   2294.84  2291.80    2294.80    7.415414  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_btc.set_index('datetime', inplace=True)\n",
    "# df_eth.set_index('datetime', inplace=True)\n",
    "\n",
    "df_m = pd.merge(df_btc, df_eth, on='datetime')\n",
    "df_m.sort_values('datetime', ascending=True)\n",
    "df_m.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5888 entries, 0 to 5887\n",
      "Data columns (total 11 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   datetime    5888 non-null   datetime64[ns]\n",
      " 1   btc_open    5888 non-null   float64       \n",
      " 2   btc_high    5888 non-null   float64       \n",
      " 3   btc_low     5888 non-null   float64       \n",
      " 4   btc_close   5888 non-null   float64       \n",
      " 5   btc_volume  5888 non-null   float64       \n",
      " 6   eth_open    5888 non-null   float64       \n",
      " 7   eth_high    5888 non-null   float64       \n",
      " 8   eth_low     5888 non-null   float64       \n",
      " 9   eth_close   5888 non-null   float64       \n",
      " 10  eth_volume  5888 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(10)\n",
      "memory usage: 506.1 KB\n"
     ]
    }
   ],
   "source": [
    "df_m.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m.to_csv(\n",
    "    Path(r'C:/\\Users/\\vchar/\\OneDrive/\\Desktop/\\ML Projects/\\Upwork/\\AlgoT_ML_Dev/\\GrammarEvolution/\\PonyGE2/\\datasets/\\BTC-ETH-1m.csv'),\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65037"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "448797 - (2 * 52 * (24 * 60) + 5 * 52 * (15 * 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6E_1m_databento_symbol_final_1min.csv',\n",
       " 'AAPL_1m_databento.csv',\n",
       " 'AAV-1m-1000wks-data.csv',\n",
       " 'AMZN_1m_databento.csv',\n",
       " 'BTC-1m-1000wks-data.csv',\n",
       " 'CL_1m_databento_symbol_final_1min.csv',\n",
       " 'COIN_1m_databento.csv',\n",
       " 'DOG-1m-1000wks-data.csv',\n",
       " 'ES_1m_databento_symbol_final_1min.csv',\n",
       " 'ETH-1m-1000wks-data.csv_backup.csv',\n",
       " 'FET-1m-1000wks-data.csv_backup.csv',\n",
       " 'GC_1m_databento_symbol_final_1min.csv',\n",
       " 'GOOGL_1m_databento.csv',\n",
       " 'INJ-1m-1000wks-data.csv',\n",
       " 'LIN-1m-1000wks-data.csv_backup.csv',\n",
       " 'META_1m_databento.csv',\n",
       " 'MSFT_1m_databento.csv',\n",
       " 'NG_1m_databento_symbol_final_1min.csv',\n",
       " 'NQ_1m_databento_symbol_final_1min.csv',\n",
       " 'NVDA_1m_databento.csv',\n",
       " 'PLTR_1m_databento.csv',\n",
       " 'SOL-1m-1000wks-data.csv_backup.csv',\n",
       " 'SUI-1m-1000wks-data.csv',\n",
       " 'TIA-1m-1000wks-data.csv',\n",
       " 'TSLA_1m_databento.csv',\n",
       " 'XRP-1m-1000wks-data.csv',\n",
       " 'ZF_1m_databento_symbol_final_1min.csv',\n",
       " 'ZN_1m_databento_symbol_final_1min.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_path = Path(r'C:/\\Users/\\vchar/\\Downloads/\\FULL DATA LIBRARY')\n",
    "\n",
    "files_list = os.listdir(main_path)\n",
    "files_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETH-1m-1000wks-data.csv_backup.csv doesn't contain overlapping data.\n",
      "SOL-1m-1000wks-data.csv_backup.csv doesn't contain overlapping data.\n"
     ]
    }
   ],
   "source": [
    "# final_df = pd.DataFrame()\n",
    "\n",
    "final_df = pd.read_csv(os.path.join(main_path, files_list[4]))\n",
    "instrument_name = files_list[4].replace('-', '_').split('_')[0].lower()\n",
    "final_df['datetime'] = pd.to_datetime(final_df['datetime'])\n",
    "final_df.sort_values('datetime', ascending=True, inplace=True)\n",
    "final_df.reset_index(inplace=True, drop=True)\n",
    "final_df.rename(\n",
    "    columns={\n",
    "        'open': f'{instrument_name}_open', \n",
    "        'close': f'{instrument_name}_close', \n",
    "        'low': f'{instrument_name}_low', \n",
    "        'high': f'{instrument_name}_high', \n",
    "        'volume': f'{instrument_name}_volume'\n",
    "    },\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "final_df.set_index('datetime', inplace=True)\n",
    "complete_time_index = pd.date_range(start=final_df.index.min(), end=final_df.index.max(), freq='min')\n",
    "final_df = final_df.reindex(complete_time_index)\n",
    "final_df = final_df.ffill()\n",
    "final_df.reset_index(inplace=True)\n",
    "final_df.rename(columns={'index': 'datetime'}, inplace=True)\n",
    "\n",
    "for i in range(len(files_list)):\n",
    "    if i in [4, 9, 21]:\n",
    "        if i != 4:\n",
    "            print(f\"{files_list[i]} doesn't contain overlapping data.\")\n",
    "        continue\n",
    "    temp_df = pd.read_csv(os.path.join(main_path, files_list[i]))\n",
    "    instrument_name = files_list[i].replace('-', '_').split('_')[0].lower()\n",
    "    temp_df['datetime'] = pd.to_datetime(temp_df['datetime'])\n",
    "    temp_df.sort_values('datetime', ascending=True, inplace=True)\n",
    "    # temp_df.set_index('datetime', inplace=True)\n",
    "    temp_df.reset_index(inplace=True, drop=True)\n",
    "    temp_df.rename(\n",
    "        columns={\n",
    "            'open': f'{instrument_name}_open', \n",
    "            'close': f'{instrument_name}_close', \n",
    "            'low': f'{instrument_name}_low', \n",
    "            'high': f'{instrument_name}_high', \n",
    "            'volume': f'{instrument_name}_volume'\n",
    "        },\n",
    "        inplace=True\n",
    "    )\n",
    "    # print(f\"{i}: {files_list[i]}: start_date = {temp_df.iloc[0]['datetime']} end_date = {temp_df.iloc[-1]['datetime']}\")\n",
    "    # if i == 0:\n",
    "    #     final_df = temp_df.copy()\n",
    "    # else:\n",
    "    #     final_df = pd.merge(final_df, temp_df, on='datetime')\n",
    "    # temp_df.ffill(inplace=True)\n",
    "    final_df = pd.merge(final_df, temp_df, on='datetime', how='left')\n",
    "    final_df.ffill(inplace=True)\n",
    "\n",
    "    if final_df.shape[0] == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4814757, 131)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(457520, 131)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.dropna(inplace=True)\n",
    "final_df.reset_index(drop=True, inplace=True)\n",
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df['diff'] = final_df['datetime'].diff().apply(lambda x: x if pd.isna(x) else x.total_seconds()/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>btc_open</th>\n",
       "      <th>btc_high</th>\n",
       "      <th>btc_low</th>\n",
       "      <th>btc_close</th>\n",
       "      <th>btc_volume</th>\n",
       "      <th>6e_open</th>\n",
       "      <th>6e_high</th>\n",
       "      <th>6e_low</th>\n",
       "      <th>6e_close</th>\n",
       "      <th>...</th>\n",
       "      <th>zf_open</th>\n",
       "      <th>zf_high</th>\n",
       "      <th>zf_low</th>\n",
       "      <th>zf_close</th>\n",
       "      <th>zf_volume</th>\n",
       "      <th>zn_open</th>\n",
       "      <th>zn_high</th>\n",
       "      <th>zn_low</th>\n",
       "      <th>zn_close</th>\n",
       "      <th>zn_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-11-01 18:14:00</td>\n",
       "      <td>34553.59</td>\n",
       "      <td>34565.88</td>\n",
       "      <td>34546.16</td>\n",
       "      <td>34549.35</td>\n",
       "      <td>6.687855</td>\n",
       "      <td>1.0557</td>\n",
       "      <td>1.05570</td>\n",
       "      <td>1.05515</td>\n",
       "      <td>1.05520</td>\n",
       "      <td>...</td>\n",
       "      <td>104.867188</td>\n",
       "      <td>104.867188</td>\n",
       "      <td>104.843750</td>\n",
       "      <td>104.843750</td>\n",
       "      <td>1640.0</td>\n",
       "      <td>106.750000</td>\n",
       "      <td>106.765625</td>\n",
       "      <td>106.703125</td>\n",
       "      <td>106.703125</td>\n",
       "      <td>2238.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-11-01 18:15:00</td>\n",
       "      <td>34549.33</td>\n",
       "      <td>34552.58</td>\n",
       "      <td>34507.30</td>\n",
       "      <td>34507.39</td>\n",
       "      <td>14.284419</td>\n",
       "      <td>1.0552</td>\n",
       "      <td>1.05530</td>\n",
       "      <td>1.05465</td>\n",
       "      <td>1.05465</td>\n",
       "      <td>...</td>\n",
       "      <td>104.843750</td>\n",
       "      <td>104.851562</td>\n",
       "      <td>104.828125</td>\n",
       "      <td>104.835938</td>\n",
       "      <td>6235.0</td>\n",
       "      <td>106.718750</td>\n",
       "      <td>106.734375</td>\n",
       "      <td>106.703125</td>\n",
       "      <td>106.703125</td>\n",
       "      <td>4672.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-11-01 18:16:00</td>\n",
       "      <td>34507.49</td>\n",
       "      <td>34525.83</td>\n",
       "      <td>34486.81</td>\n",
       "      <td>34522.14</td>\n",
       "      <td>7.825300</td>\n",
       "      <td>1.0546</td>\n",
       "      <td>1.05505</td>\n",
       "      <td>1.05445</td>\n",
       "      <td>1.05505</td>\n",
       "      <td>...</td>\n",
       "      <td>104.835938</td>\n",
       "      <td>104.859375</td>\n",
       "      <td>104.835938</td>\n",
       "      <td>104.851562</td>\n",
       "      <td>2477.0</td>\n",
       "      <td>106.703125</td>\n",
       "      <td>106.734375</td>\n",
       "      <td>106.687500</td>\n",
       "      <td>106.734375</td>\n",
       "      <td>2382.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-11-01 18:17:00</td>\n",
       "      <td>34522.14</td>\n",
       "      <td>34530.14</td>\n",
       "      <td>34500.18</td>\n",
       "      <td>34526.96</td>\n",
       "      <td>7.512638</td>\n",
       "      <td>1.0550</td>\n",
       "      <td>1.05525</td>\n",
       "      <td>1.05490</td>\n",
       "      <td>1.05515</td>\n",
       "      <td>...</td>\n",
       "      <td>104.851562</td>\n",
       "      <td>104.867188</td>\n",
       "      <td>104.843750</td>\n",
       "      <td>104.851562</td>\n",
       "      <td>3767.0</td>\n",
       "      <td>106.734375</td>\n",
       "      <td>106.750000</td>\n",
       "      <td>106.734375</td>\n",
       "      <td>106.750000</td>\n",
       "      <td>2937.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-11-01 18:18:00</td>\n",
       "      <td>34526.20</td>\n",
       "      <td>34545.63</td>\n",
       "      <td>34525.18</td>\n",
       "      <td>34540.48</td>\n",
       "      <td>13.100650</td>\n",
       "      <td>1.0551</td>\n",
       "      <td>1.05535</td>\n",
       "      <td>1.05510</td>\n",
       "      <td>1.05530</td>\n",
       "      <td>...</td>\n",
       "      <td>104.851562</td>\n",
       "      <td>104.859375</td>\n",
       "      <td>104.851562</td>\n",
       "      <td>104.851562</td>\n",
       "      <td>1634.0</td>\n",
       "      <td>106.734375</td>\n",
       "      <td>106.750000</td>\n",
       "      <td>106.734375</td>\n",
       "      <td>106.734375</td>\n",
       "      <td>962.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime  btc_open  btc_high   btc_low  btc_close  btc_volume  \\\n",
       "0 2023-11-01 18:14:00  34553.59  34565.88  34546.16   34549.35    6.687855   \n",
       "1 2023-11-01 18:15:00  34549.33  34552.58  34507.30   34507.39   14.284419   \n",
       "2 2023-11-01 18:16:00  34507.49  34525.83  34486.81   34522.14    7.825300   \n",
       "3 2023-11-01 18:17:00  34522.14  34530.14  34500.18   34526.96    7.512638   \n",
       "4 2023-11-01 18:18:00  34526.20  34545.63  34525.18   34540.48   13.100650   \n",
       "\n",
       "   6e_open  6e_high   6e_low  6e_close  ...     zf_open     zf_high  \\\n",
       "0   1.0557  1.05570  1.05515   1.05520  ...  104.867188  104.867188   \n",
       "1   1.0552  1.05530  1.05465   1.05465  ...  104.843750  104.851562   \n",
       "2   1.0546  1.05505  1.05445   1.05505  ...  104.835938  104.859375   \n",
       "3   1.0550  1.05525  1.05490   1.05515  ...  104.851562  104.867188   \n",
       "4   1.0551  1.05535  1.05510   1.05530  ...  104.851562  104.859375   \n",
       "\n",
       "       zf_low    zf_close  zf_volume     zn_open     zn_high      zn_low  \\\n",
       "0  104.843750  104.843750     1640.0  106.750000  106.765625  106.703125   \n",
       "1  104.828125  104.835938     6235.0  106.718750  106.734375  106.703125   \n",
       "2  104.835938  104.851562     2477.0  106.703125  106.734375  106.687500   \n",
       "3  104.843750  104.851562     3767.0  106.734375  106.750000  106.734375   \n",
       "4  104.851562  104.851562     1634.0  106.734375  106.750000  106.734375   \n",
       "\n",
       "     zn_close  zn_volume  \n",
       "0  106.703125     2238.0  \n",
       "1  106.703125     4672.0  \n",
       "2  106.734375     2382.0  \n",
       "3  106.750000     2937.0  \n",
       "4  106.734375      962.0  \n",
       "\n",
       "[5 rows x 131 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>btc_open</th>\n",
       "      <th>btc_high</th>\n",
       "      <th>btc_low</th>\n",
       "      <th>btc_close</th>\n",
       "      <th>btc_volume</th>\n",
       "      <th>6e_open</th>\n",
       "      <th>6e_high</th>\n",
       "      <th>6e_low</th>\n",
       "      <th>6e_close</th>\n",
       "      <th>...</th>\n",
       "      <th>zf_open</th>\n",
       "      <th>zf_high</th>\n",
       "      <th>zf_low</th>\n",
       "      <th>zf_close</th>\n",
       "      <th>zf_volume</th>\n",
       "      <th>zn_open</th>\n",
       "      <th>zn_high</th>\n",
       "      <th>zn_low</th>\n",
       "      <th>zn_close</th>\n",
       "      <th>zn_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>457515</th>\n",
       "      <td>2024-09-14 11:29:00</td>\n",
       "      <td>59835.10</td>\n",
       "      <td>59835.10</td>\n",
       "      <td>59805.98</td>\n",
       "      <td>59819.64</td>\n",
       "      <td>2.781430</td>\n",
       "      <td>1.11185</td>\n",
       "      <td>1.11185</td>\n",
       "      <td>1.11175</td>\n",
       "      <td>1.11185</td>\n",
       "      <td>...</td>\n",
       "      <td>110.625</td>\n",
       "      <td>110.632812</td>\n",
       "      <td>110.617188</td>\n",
       "      <td>110.625</td>\n",
       "      <td>1569.0</td>\n",
       "      <td>115.390625</td>\n",
       "      <td>115.390625</td>\n",
       "      <td>115.375</td>\n",
       "      <td>115.390625</td>\n",
       "      <td>641.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457516</th>\n",
       "      <td>2024-09-14 11:30:00</td>\n",
       "      <td>59815.61</td>\n",
       "      <td>59825.88</td>\n",
       "      <td>59805.44</td>\n",
       "      <td>59813.19</td>\n",
       "      <td>0.866345</td>\n",
       "      <td>1.11185</td>\n",
       "      <td>1.11185</td>\n",
       "      <td>1.11175</td>\n",
       "      <td>1.11185</td>\n",
       "      <td>...</td>\n",
       "      <td>110.625</td>\n",
       "      <td>110.632812</td>\n",
       "      <td>110.617188</td>\n",
       "      <td>110.625</td>\n",
       "      <td>1569.0</td>\n",
       "      <td>115.390625</td>\n",
       "      <td>115.390625</td>\n",
       "      <td>115.375</td>\n",
       "      <td>115.390625</td>\n",
       "      <td>641.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457517</th>\n",
       "      <td>2024-09-14 11:31:00</td>\n",
       "      <td>59811.70</td>\n",
       "      <td>59827.60</td>\n",
       "      <td>59805.43</td>\n",
       "      <td>59827.18</td>\n",
       "      <td>2.052995</td>\n",
       "      <td>1.11185</td>\n",
       "      <td>1.11185</td>\n",
       "      <td>1.11175</td>\n",
       "      <td>1.11185</td>\n",
       "      <td>...</td>\n",
       "      <td>110.625</td>\n",
       "      <td>110.632812</td>\n",
       "      <td>110.617188</td>\n",
       "      <td>110.625</td>\n",
       "      <td>1569.0</td>\n",
       "      <td>115.390625</td>\n",
       "      <td>115.390625</td>\n",
       "      <td>115.375</td>\n",
       "      <td>115.390625</td>\n",
       "      <td>641.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457518</th>\n",
       "      <td>2024-09-14 11:32:00</td>\n",
       "      <td>59827.17</td>\n",
       "      <td>59833.78</td>\n",
       "      <td>59824.37</td>\n",
       "      <td>59831.64</td>\n",
       "      <td>1.489819</td>\n",
       "      <td>1.11185</td>\n",
       "      <td>1.11185</td>\n",
       "      <td>1.11175</td>\n",
       "      <td>1.11185</td>\n",
       "      <td>...</td>\n",
       "      <td>110.625</td>\n",
       "      <td>110.632812</td>\n",
       "      <td>110.617188</td>\n",
       "      <td>110.625</td>\n",
       "      <td>1569.0</td>\n",
       "      <td>115.390625</td>\n",
       "      <td>115.390625</td>\n",
       "      <td>115.375</td>\n",
       "      <td>115.390625</td>\n",
       "      <td>641.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457519</th>\n",
       "      <td>2024-09-14 11:33:00</td>\n",
       "      <td>59831.64</td>\n",
       "      <td>59836.10</td>\n",
       "      <td>59831.64</td>\n",
       "      <td>59836.10</td>\n",
       "      <td>0.078481</td>\n",
       "      <td>1.11185</td>\n",
       "      <td>1.11185</td>\n",
       "      <td>1.11175</td>\n",
       "      <td>1.11185</td>\n",
       "      <td>...</td>\n",
       "      <td>110.625</td>\n",
       "      <td>110.632812</td>\n",
       "      <td>110.617188</td>\n",
       "      <td>110.625</td>\n",
       "      <td>1569.0</td>\n",
       "      <td>115.390625</td>\n",
       "      <td>115.390625</td>\n",
       "      <td>115.375</td>\n",
       "      <td>115.390625</td>\n",
       "      <td>641.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  datetime  btc_open  btc_high   btc_low  btc_close  \\\n",
       "457515 2024-09-14 11:29:00  59835.10  59835.10  59805.98   59819.64   \n",
       "457516 2024-09-14 11:30:00  59815.61  59825.88  59805.44   59813.19   \n",
       "457517 2024-09-14 11:31:00  59811.70  59827.60  59805.43   59827.18   \n",
       "457518 2024-09-14 11:32:00  59827.17  59833.78  59824.37   59831.64   \n",
       "457519 2024-09-14 11:33:00  59831.64  59836.10  59831.64   59836.10   \n",
       "\n",
       "        btc_volume  6e_open  6e_high   6e_low  6e_close  ...  zf_open  \\\n",
       "457515    2.781430  1.11185  1.11185  1.11175   1.11185  ...  110.625   \n",
       "457516    0.866345  1.11185  1.11185  1.11175   1.11185  ...  110.625   \n",
       "457517    2.052995  1.11185  1.11185  1.11175   1.11185  ...  110.625   \n",
       "457518    1.489819  1.11185  1.11185  1.11175   1.11185  ...  110.625   \n",
       "457519    0.078481  1.11185  1.11185  1.11175   1.11185  ...  110.625   \n",
       "\n",
       "           zf_high      zf_low  zf_close  zf_volume     zn_open     zn_high  \\\n",
       "457515  110.632812  110.617188   110.625     1569.0  115.390625  115.390625   \n",
       "457516  110.632812  110.617188   110.625     1569.0  115.390625  115.390625   \n",
       "457517  110.632812  110.617188   110.625     1569.0  115.390625  115.390625   \n",
       "457518  110.632812  110.617188   110.625     1569.0  115.390625  115.390625   \n",
       "457519  110.632812  110.617188   110.625     1569.0  115.390625  115.390625   \n",
       "\n",
       "         zn_low    zn_close  zn_volume  \n",
       "457515  115.375  115.390625      641.0  \n",
       "457516  115.375  115.390625      641.0  \n",
       "457517  115.375  115.390625      641.0  \n",
       "457518  115.375  115.390625      641.0  \n",
       "457519  115.375  115.390625      641.0  \n",
       "\n",
       "[5 rows x 131 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(457520, 131)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['6e', 'aapl', 'aav', 'amzn', 'btc', 'cl', 'coin', 'datetime',\n",
       "       'dog', 'es', 'fet', 'gc', 'googl', 'inj', 'lin', 'meta', 'msft',\n",
       "       'ng', 'nq', 'nvda', 'pltr', 'sui', 'tia', 'tsla', 'xrp', 'zf',\n",
       "       'zn'], dtype='<U8')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique([i.split('_')[0] for i in final_df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"all_data_1min.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_list = [\n",
    "    '6e', 'aapl', 'aav', 'amzn', 'btc', 'cl', 'coin',\n",
    "    'dog', 'es', 'fet', 'gc', 'googl', 'inj', 'lin', 'meta', 'msft',\n",
    "    'ng', 'nq', 'nvda', 'pltr', 'sui', 'tia', 'tsla', 'xrp', 'zf',\n",
    "    'zn'\n",
    "]\n",
    "\n",
    "prefix_txt = '{:{:'\n",
    "suffix_txt = ':}:}{::}'\n",
    "it_txt = '_{i}'\n",
    "\n",
    "for instrument in inst_list:\n",
    "\n",
    "    if instrument == 'btc':\n",
    "        continue\n",
    "\n",
    "    text_template = f'''{prefix_txt}df[f\"'\"{instrument}_close{it_txt}\"'\"] = df[\"'\"{instrument}_close\"'\"].shift(i){suffix_txt}\n",
    "    {prefix_txt}df[f\"'\"{instrument}_open{it_txt}\"'\"] = df[\"'\"{instrument}_open\"'\"].shift(i){suffix_txt}\n",
    "    {prefix_txt}df[f\"'\"{instrument}_high{it_txt}\"'\"] = df[\"'\"{instrument}_high\"'\"].shift(i){suffix_txt}\n",
    "    {prefix_txt}df[f\"'\"{instrument}_low{it_txt}\"'\"] = df[\"'\"{instrument}_low\"'\"].shift(i){suffix_txt}\n",
    "    {prefix_txt}df[f\"'\"{instrument}_volume{it_txt}\"'\"] = df[\"'\"{instrument}_volume\"'\"].shift(i){suffix_txt}'''\n",
    "\n",
    "    print(text_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_list = [\n",
    "    '6e', 'aapl', 'aav', 'amzn', 'btc', 'cl', 'coin',\n",
    "    'dog', 'es', 'fet', 'gc', 'googl', 'inj', 'lin', 'meta', 'msft',\n",
    "    'ng', 'nq', 'nvda', 'pltr', 'sui', 'tia', 'tsla', 'xrp', 'zf',\n",
    "    'zn'\n",
    "]\n",
    "\n",
    "for instrument in inst_list:\n",
    "\n",
    "    if instrument == 'btc':\n",
    "        continue\n",
    "\n",
    "    txt_temp = f'''| df[\"'\"{instrument}_close\"'\"].values.reshape(-1, 1) \n",
    "    | df[\"'\"{instrument}_open\"'\"].values.reshape(-1, 1) \n",
    "    | df[\"'\"{instrument}_high\"'\"].values.reshape(-1, 1) \n",
    "    | df[\"'\"{instrument}_low\"'\"].values.reshape(-1, 1)\n",
    "    | df[\"'\"{instrument}_volume\"'\"].values.reshape(-1, 1)\n",
    "    | df[\"'\"{instrument}_close_1\"'\"].values.reshape(-1, 1) \n",
    "    | df[\"'\"{instrument}_open_1\"'\"].values.reshape(-1, 1) \n",
    "    | df[\"'\"{instrument}_high_1\"'\"].values.reshape(-1, 1) \n",
    "    | df[\"'\"{instrument}_low_1\"'\"].values.reshape(-1, 1)\n",
    "    | df[\"'\"{instrument}_volume_1\"'\"].values.reshape(-1, 1)\n",
    "    | df[\"'\"{instrument}_close_2\"'\"].values.reshape(-1, 1) \n",
    "    | df[\"'\"{instrument}_open_2\"'\"].values.reshape(-1, 1) \n",
    "    | df[\"'\"{instrument}_high_2\"'\"].values.reshape(-1, 1) \n",
    "    | df[\"'\"{instrument}_low_2\"'\"].values.reshape(-1, 1)\n",
    "    | df[\"'\"{instrument}_volume_2\"'\"].values.reshape(-1, 1)\n",
    "    | df[\"'\"{instrument}_close_3\"'\"].values.reshape(-1, 1) \n",
    "    | df[\"'\"{instrument}_open_3\"'\"].values.reshape(-1, 1) \n",
    "    | df[\"'\"{instrument}_high_3\"'\"].values.reshape(-1, 1) \n",
    "    | df[\"'\"{instrument}_low_3\"'\"].values.reshape(-1, 1)\n",
    "    | df[\"'\"{instrument}_volume_3\"'\"].values.reshape(-1, 1)\n",
    "    | df[\"'\"{instrument}_close_4\"'\"].values.reshape(-1, 1) \n",
    "    | df[\"'\"{instrument}_open_4\"'\"].values.reshape(-1, 1) \n",
    "    | df[\"'\"{instrument}_high_4\"'\"].values.reshape(-1, 1) \n",
    "    | df[\"'\"{instrument}_low_4\"'\"].values.reshape(-1, 1)\n",
    "    | df[\"'\"{instrument}_volume_4\"'\"].values.reshape(-1, 1)\n",
    "    | df[\"'\"{instrument}_close_5\"'\"].values.reshape(-1, 1) \n",
    "    | df[\"'\"{instrument}_open_5\"'\"].values.reshape(-1, 1) \n",
    "    | df[\"'\"{instrument}_high_5\"'\"].values.reshape(-1, 1) \n",
    "    | df[\"'\"{instrument}_low_5\"'\"].values.reshape(-1, 1)\n",
    "    | df[\"'\"{instrument}_volume_5\"'\"].values.reshape(-1, 1)'''\n",
    "\n",
    "    print(txt_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting strategy from the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['indicators.RSI(df=data, HistLength=10).values < 20']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re \n",
    "\n",
    "text = '''def fun(price_data):\n",
    "  import pandas as pd\n",
    "  import numpy as np\n",
    "  from fitness.indicators import indicators\n",
    "  from numba import njit\n",
    "  @njit\n",
    "  def merge_pnl(arr1, arr2):\n",
    "    out = np.zeros((len(arr1) + len(arr2)))\n",
    "    idx = 1\n",
    "    for i in range(len(arr1) + len(arr2)):\n",
    "      if i % 2 == 0:\n",
    "        out[i] = arr1[int(i/2)]\n",
    "      else:\n",
    "        out[i] = arr2[i-idx]\n",
    "      idx += 1\n",
    "    return out\n",
    "  @njit\n",
    "  def get_drawdowns(arr):\n",
    "    drawdowns = np.zeros((len(arr)))\n",
    "    max = arr[0]\n",
    "    for i in range(1, len(drawdowns)-1):\n",
    "      if arr[i-1] > arr[i] and arr[i] < arr[i+1]:\n",
    "        min = arr[i]\n",
    "        drawdowns[i] = max - min\n",
    "      elif arr[i-1] < arr[i] and arr[i] > arr[i+1]:\n",
    "        max = arr[i]\n",
    "    return drawdowns\n",
    "  df = price_data.copy()\n",
    "  df['buy'] = (indicators.RSI(df=data, HistLength=10).values < 20).astype(int)\n",
    "  df['sell'] = (indicators.RSI(df=data, HistLength=10).values > 80).astype(int)\n",
    "  df['signal'] = df['buy'] + df['sell']\n",
    "  df['signal'] = df['signal'].apply(lambda x: 1 if x==1 else 0)\n",
    "  df['sell'] = df['sell'] * (-1)\n",
    "  df['signal'] = df['signal'] * df['sell']\n",
    "  df['signal'] = df['signal'] + df['buy']\n",
    "  df.drop(columns=['buy', 'sell'], inplace=True)\n",
    "  buy_idxs = []\n",
    "  sell_idxs = []\n",
    "  is_buy = 0\n",
    "  is_sell = 0\n",
    "  for i, row in enumerate(df.itertuples()):\n",
    "    if row.signal == 1 and is_buy == 0:\n",
    "      buy_idxs.append(i+1)\n",
    "      is_buy = 1\n",
    "      is_sell = 0\n",
    "    elif row.signal == -1 and is_sell == 0:\n",
    "      sell_idxs.append(i+1)\n",
    "      is_sell = 1\n",
    "      is_buy = 0\n",
    "  if len(buy_idxs) > len(sell_idxs):\n",
    "    buy_idxs = buy_idxs[:-(len(buy_idxs) - len(sell_idxs))]\n",
    "  elif len(buy_idxs) < len(sell_idxs):\n",
    "    sell_idxs = sell_idxs[:-(len(sell_idxs) - len(buy_idxs))]\n",
    "  if len(buy_idxs) == 0 or len(sell_idxs) == 0:\n",
    "    return 999\n",
    "  buy_prices = df[df.index.isin(buy_idxs)]['open'].values\n",
    "  sell_prices = df[df.index.isin(sell_idxs)]['open'].values\n",
    "  if buy_idxs[0] < sell_idxs[0]:\n",
    "    buy_pnl = np.sum(sell_prices - buy_prices)\n",
    "    sell_pnl = np.sum(sell_prices[:-1] - buy_prices[1:])\n",
    "    buy_arr = sell_prices - buy_prices\n",
    "    sell_arr = sell_prices[:-1] - buy_prices[1:]\n",
    "    all_arr = merge_pnl(buy_arr, sell_arr)\n",
    "  else:\n",
    "    sell_pnl = np.sum(sell_prices - buy_prices)\n",
    "    buy_pnl = np.sum(sell_prices[1:] - buy_prices[:-1])\n",
    "    sell_arr = sell_prices - buy_prices\n",
    "    buy_arr = sell_prices[1:] - buy_prices[:-1]\n",
    "    all_arr = merge_pnl(sell_arr, buy_arr)\n",
    "  total_pnl = buy_pnl + sell_pnl\n",
    "  equity_curve_arr = np.cumsum(all_arr)\n",
    "  drawdowns = get_drawdowns(equity_curve_arr)\n",
    "  avg_drawdown = np.sum(drawdowns[drawdowns!=0]) / len(drawdowns[drawdowns!=0])\n",
    "  fitness = total_pnl / avg_drawdown\n",
    "  if np.isnan(fitness):\n",
    "    return 999\n",
    "  return -fitness\n",
    "fitness = fun(data)'''\n",
    "\n",
    "re.findall(r\"df\\[\\'buy\\'\\] = \\((.*)\\)\\.astype\\(int\\)\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['indicators.RSI(df=data, HistLength=10).values > 80']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\"df\\[\\'sell\\'\\] = \\((.*)\\)\\.astype\\(int\\)\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(cache=True)\n",
    "def get_pnl(\n",
    "    trade_close_prices,\n",
    "    trade_open_prices,\n",
    "    commission=0.015,\n",
    "    slippage=0.05,\n",
    "    init_inv=20000,\n",
    "    trade_size=0.1,\n",
    "    is_buy=1\n",
    "):\n",
    "\n",
    "    pnl_list = np.zeros(len(trade_close_prices))\n",
    "\n",
    "    for i in range(len(trade_close_prices)):\n",
    "        \n",
    "        temp_n_assets = int(init_inv * trade_size / trade_open_prices[i])\n",
    "        if is_buy == 1:\n",
    "            temp_pnl = temp_n_assets * (trade_close_prices[i] - trade_open_prices[i] * (1 + slippage))\n",
    "        else:\n",
    "            temp_pnl = -temp_n_assets * (trade_close_prices[i] - trade_open_prices[i] * (1 - slippage))\n",
    "        temp_pnl = temp_pnl * (1 - commission)\n",
    "        init_inv += temp_pnl\n",
    "\n",
    "        pnl_list[i] = temp_pnl\n",
    "\n",
    "    return pnl_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(price_data):\n",
    "  import pandas as pd\n",
    "  import numpy as np\n",
    "  # from fitness.indicators import indicators\n",
    "  from numba import njit\n",
    "  COMMISSION = 0.015\n",
    "  SLIPPAGE = 0.00005\n",
    "  AVAILABLE_CAPITAL = 700000\n",
    "  TRADE_SIZE = 0.5\n",
    "  @njit\n",
    "  def merge_pnl(arr1, arr2):\n",
    "    out = np.zeros((len(arr1) + len(arr2)))\n",
    "    idx = 1\n",
    "    for i in range(len(arr1) + len(arr2)):\n",
    "      if i % 2 == 0:\n",
    "        out[i] = arr1[int(i/2)]\n",
    "      else:\n",
    "        out[i] = arr2[i-idx]\n",
    "      idx += 1\n",
    "    return out\n",
    "  @njit\n",
    "  def get_drawdowns(arr):\n",
    "    drawdowns = np.zeros((len(arr)))\n",
    "    max = arr[0]\n",
    "    for i in range(1, len(drawdowns)-1):\n",
    "      if arr[i-1] > arr[i] and arr[i] < arr[i+1]:\n",
    "        min = arr[i]\n",
    "        drawdowns[i] = max - min\n",
    "      elif arr[i-1] < arr[i] and arr[i] > arr[i+1]:\n",
    "        max = arr[i]\n",
    "    return drawdowns\n",
    "  @njit\n",
    "  def get_pnl(trade_close_prices, trade_open_prices, commission, slippage, init_inv, trade_size, is_buy):\n",
    "    pnl_list = np.zeros(len(trade_close_prices))\n",
    "    for i in range(len(trade_close_prices)):\n",
    "      temp_n_assets = int(init_inv * trade_size / trade_open_prices[i])\n",
    "      if is_buy == 1:\n",
    "        temp_pnl = temp_n_assets * (trade_close_prices[i] - trade_open_prices[i] * (1 + slippage))\n",
    "      else:\n",
    "        temp_pnl = -temp_n_assets * (trade_close_prices[i] - trade_open_prices[i] * (1 - slippage))\n",
    "      temp_pnl = temp_pnl * (1 - commission)\n",
    "      init_inv += temp_pnl\n",
    "      pnl_list[i] = temp_pnl\n",
    "    return pnl_list\n",
    "  df = price_data.copy()\n",
    "  for i in range(1, 6):\n",
    "    df[f'close_{i}'] = df['close'].shift(i)\n",
    "    df[f'open_{i}'] = df['open'].shift(i)\n",
    "    df[f'high_{i}'] = df['high'].shift(i)\n",
    "    df[f'low_{i}'] = df['low'].shift(i)\n",
    "    df[f'volume_{i}'] = df['volume'].shift(i)\n",
    "  df.dropna(inplace=True)\n",
    "  df.reset_index(drop=True, inplace=True)\n",
    "  df['buy'] = (RSI(df=df, HistLength=10).values < 20).astype(int)\n",
    "  df['sell'] = (RSI(df=df, HistLength=10).values > 80).astype(int)\n",
    "  df['signal'] = df['buy'] + df['sell']\n",
    "  df['signal'] = df['signal'].apply(lambda x: 1 if x==1 else 0)\n",
    "  df['sell'] = df['sell'] * (-1)\n",
    "  df['signal'] = df['signal'] * df['sell']\n",
    "  df['signal'] = df['signal'] + df['buy']\n",
    "  df.drop(columns=['buy', 'sell'], inplace=True)\n",
    "  buy_idxs = []\n",
    "  sell_idxs = []\n",
    "  is_buy = 0\n",
    "  is_sell = 0\n",
    "  for i, row in enumerate(df.itertuples()):\n",
    "    if row.signal == 1 and is_buy == 0:\n",
    "      buy_idxs.append(i+1)\n",
    "      is_buy = 1\n",
    "      is_sell = 0\n",
    "    elif row.signal == -1 and is_sell == 0:\n",
    "      sell_idxs.append(i+1)\n",
    "      is_sell = 1\n",
    "      is_buy = 0\n",
    "  if len(buy_idxs) > len(sell_idxs):\n",
    "    buy_idxs = buy_idxs[:-(len(buy_idxs) - len(sell_idxs))]\n",
    "  elif len(buy_idxs) < len(sell_idxs):\n",
    "    sell_idxs = sell_idxs[:-(len(sell_idxs) - len(buy_idxs))]\n",
    "  if len(buy_idxs) == 0 or len(sell_idxs) == 0:\n",
    "    return 999\n",
    "  buy_prices = df[df.index.isin(buy_idxs)]['open'].values\n",
    "  sell_prices = df[df.index.isin(sell_idxs)]['open'].values\n",
    "  if buy_idxs[0] < sell_idxs[0]:\n",
    "    buy_arr = get_pnl(sell_prices, buy_prices, COMMISSION, SLIPPAGE, AVAILABLE_CAPITAL, TRADE_SIZE, 1)\n",
    "    buy_pnl = np.sum(buy_arr)\n",
    "    sell_arr = get_pnl(buy_prices[1:], sell_prices[:-1], COMMISSION, SLIPPAGE, AVAILABLE_CAPITAL, TRADE_SIZE, 0)\n",
    "    sell_pnl = np.sum(sell_arr)\n",
    "    all_arr = merge_pnl(buy_arr, sell_arr)\n",
    "  else:\n",
    "    sell_arr = get_pnl(buy_prices, sell_prices, COMMISSION, SLIPPAGE, AVAILABLE_CAPITAL, TRADE_SIZE, 0)\n",
    "    sell_pnl = np.sum(sell_arr)\n",
    "    buy_arr = get_pnl(sell_prices[1:], buy_prices[:-1], COMMISSION, SLIPPAGE, AVAILABLE_CAPITAL, TRADE_SIZE, 1)\n",
    "    buy_pnl = np.sum(buy_arr)\n",
    "    all_arr = merge_pnl(sell_arr, buy_arr)\n",
    "  total_pnl = buy_pnl + sell_pnl\n",
    "  equity_curve_arr = np.cumsum(all_arr)\n",
    "  drawdowns = get_drawdowns(equity_curve_arr)\n",
    "  avg_drawdown = np.sum(drawdowns[drawdowns!=0]) / len(drawdowns[drawdowns!=0])\n",
    "  fitness = total_pnl / avg_drawdown\n",
    "  if np.isnan(fitness):\n",
    "    return -999\n",
    "  return -fitness\n",
    "# fitness = fun(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limited testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.fitness.indicators import indicators\n",
    "from numba import njit\n",
    "COMMISSION = 0.015\n",
    "SLIPPAGE = 0.00005\n",
    "AVAILABLE_CAPITAL = 700000\n",
    "TRADE_SIZE = 0.5\n",
    "\n",
    "@njit\n",
    "def merge_pnl(arr1, arr2):\n",
    "    out = np.zeros((len(arr1) + len(arr2)))\n",
    "    idx = 1\n",
    "    for i in range(len(arr1) + len(arr2)):\n",
    "        if i % 2 == 0:\n",
    "            out[i] = arr1[int(i/2)]\n",
    "        else:\n",
    "            out[i] = arr2[i-idx]\n",
    "        idx += 1\n",
    "    return out\n",
    "\n",
    "@njit\n",
    "def get_drawdowns(arr):\n",
    "    drawdowns = np.zeros((len(arr)))\n",
    "    max = arr[0]\n",
    "    for i in range(1, len(drawdowns)-1):\n",
    "        if arr[i-1] > arr[i] and arr[i] < arr[i+1]:\n",
    "            min = arr[i]\n",
    "            drawdowns[i] = max - min\n",
    "        elif arr[i-1] < arr[i] and arr[i] > arr[i+1]:\n",
    "            max = arr[i]\n",
    "    return drawdowns\n",
    "\n",
    "@njit\n",
    "def get_pnl(trade_close_prices, trade_open_prices, commission, slippage, init_inv, trade_size, is_buy):\n",
    "    pnl_list = np.zeros(len(trade_close_prices))\n",
    "    for i in range(len(trade_close_prices)):\n",
    "        temp_n_assets = int(init_inv * trade_size / trade_open_prices[i])\n",
    "        if is_buy == 1:\n",
    "            temp_pnl = temp_n_assets * (trade_close_prices[i] - trade_open_prices[i] * (1 + slippage))\n",
    "        else:\n",
    "            temp_pnl = -temp_n_assets * (trade_close_prices[i] - trade_open_prices[i] * (1 - slippage))\n",
    "        temp_pnl = temp_pnl * (1 - commission)\n",
    "        init_inv += temp_pnl\n",
    "        pnl_list[i] = temp_pnl\n",
    "    return pnl_list\n",
    "\n",
    "# df = price_data.copy()\n",
    "# for i in range(1, 6):\n",
    "#     df[f'close_{i}'] = df['close'].shift(i)\n",
    "#     df[f'open_{i}'] = df['open'].shift(i)\n",
    "#     df[f'high_{i}'] = df['high'].shift(i)\n",
    "#     df[f'low_{i}'] = df['low'].shift(i)\n",
    "#     df[f'volume_{i}'] = df['volume'].shift(i)\n",
    "# df.dropna(inplace=True)\n",
    "# df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df['buy'] = (indicators.RSI(df=df, HistLength=10).values < 20).astype(int)\n",
    "df['sell'] = (indicators.RSI(df=df, HistLength=10).values > 80).astype(int)\n",
    "df['signal'] = df['buy'] + df['sell']\n",
    "df['signal'] = df['signal'].apply(lambda x: 1 if x==1 else 0)\n",
    "df['sell'] = df['sell'] * (-1)\n",
    "df['signal'] = df['signal'] * df['sell']\n",
    "df['signal'] = df['signal'] + df['buy']\n",
    "df.drop(columns=['buy', 'sell'], inplace=True)\n",
    "\n",
    "buy_idxs = []\n",
    "sell_idxs = []\n",
    "is_buy = 0\n",
    "is_sell = 0\n",
    "for i, row in enumerate(df.itertuples()):\n",
    "    if row.signal == 1 and is_buy == 0:\n",
    "        buy_idxs.append(i+1)\n",
    "        is_buy = 1\n",
    "        is_sell = 0\n",
    "    elif row.signal == -1 and is_sell == 0:\n",
    "        sell_idxs.append(i+1)\n",
    "        is_sell = 1\n",
    "        is_buy = 0\n",
    "\n",
    "if len(buy_idxs) > len(sell_idxs):\n",
    "    buy_idxs = buy_idxs[:-(len(buy_idxs) - len(sell_idxs))]\n",
    "elif len(buy_idxs) < len(sell_idxs):\n",
    "    sell_idxs = sell_idxs[:-(len(sell_idxs) - len(buy_idxs))]\n",
    "\n",
    "if len(buy_idxs) == 0 or len(sell_idxs) == 0:\n",
    "    print(\"not enough signals\")\n",
    "\n",
    "buy_prices = df[df.index.isin(buy_idxs)]['open'].values\n",
    "sell_prices = df[df.index.isin(sell_idxs)]['open'].values\n",
    "\n",
    "if buy_idxs[0] < sell_idxs[0]:\n",
    "    buy_arr = get_pnl(sell_prices, buy_prices, COMMISSION, SLIPPAGE, AVAILABLE_CAPITAL, TRADE_SIZE, 1)\n",
    "    buy_pnl = np.sum(buy_arr)\n",
    "    sell_arr = get_pnl(buy_prices[1:], sell_prices[:-1], COMMISSION, SLIPPAGE, AVAILABLE_CAPITAL, TRADE_SIZE, 0)\n",
    "    sell_pnl = np.sum(sell_arr)\n",
    "    all_arr = merge_pnl(buy_arr, sell_arr)\n",
    "else:\n",
    "    sell_arr = get_pnl(buy_prices, sell_prices, COMMISSION, SLIPPAGE, AVAILABLE_CAPITAL, TRADE_SIZE, 0)\n",
    "    sell_pnl = np.sum(sell_arr)\n",
    "    buy_arr = get_pnl(sell_prices[1:], buy_prices[:-1], COMMISSION, SLIPPAGE, AVAILABLE_CAPITAL, TRADE_SIZE, 1)\n",
    "    buy_pnl = np.sum(buy_arr)\n",
    "    all_arr = merge_pnl(sell_arr, buy_arr)\n",
    "\n",
    "total_pnl = buy_pnl + sell_pnl\n",
    "equity_curve_arr = np.cumsum(all_arr)\n",
    "drawdowns = get_drawdowns(equity_curve_arr)\n",
    "avg_drawdown = np.sum(drawdowns[drawdowns!=0]) / len(drawdowns[drawdowns!=0])\n",
    "fitness = total_pnl / avg_drawdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[95, 396, 525, 609, 695, 732, 918, 1088, 1228, 1439, 1566, 1801, 1890, 2061, 2272, 2433, 2521, 2833, 2882, 2970, 3097, 3473, 3764, 3836, 4088, 4427, 4583, 4804, 4939, 5012, 5173, 5220, 5534, 5850, 5965, 6254, 6598, 6674, 6807, 7125, 7336, 7440, 7521, 7584, 7781, 7910, 8080, 8191, 8462, 8622, 8753, 8948, 9091, 9375, 9488]\n"
     ]
    }
   ],
   "source": [
    "print(buy_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15, 373, 496, 574, 651, 711, 801, 972, 1107, 1376, 1526, 1747, 1870, 1993, 2198, 2294, 2481, 2579, 2860, 2948, 3024, 3242, 3510, 3782, 3990, 4205, 4549, 4720, 4831, 4985, 5061, 5209, 5301, 5701, 5893, 6023, 6311, 6630, 6758, 6931, 7318, 7413, 7488, 7566, 7650, 7876, 8012, 8094, 8297, 8496, 8730, 8865, 9012, 9281, 9433]\n"
     ]
    }
   ],
   "source": [
    "print(sell_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55, 55)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(buy_idxs), len(sell_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15, 95, 373, 396, 496, 525, 574, 609, 651, 695, 711, 732, 801, 918, 972, 1088, 1107, 1228, 1376, 1439, 1526, 1566, 1747, 1801, 1870, 1890, 1993, 2061, 2198, 2272, 2294, 2433, 2481, 2521, 2579, 2833, 2860, 2882, 2948, 2970, 3024, 3097, 3242, 3473, 3510, 3764, 3782, 3836, 3990, 4088, 4205, 4427, 4549, 4583, 4720, 4804, 4831, 4939, 4985, 5012, 5061, 5173, 5209, 5220, 5301, 5534, 5701, 5850, 5893, 5965, 6023, 6254, 6311, 6598, 6630, 6674, 6758, 6807, 6931, 7125, 7318, 7336, 7413, 7440, 7488, 7521, 7566, 7584, 7650, 7781, 7876, 7910, 8012, 8080, 8094, 8191, 8297, 8462, 8496, 8622, 8730, 8753, 8865, 8948, 9012, 9091, 9281, 9375, 9433, 9488]\n"
     ]
    }
   ],
   "source": [
    "signal_idxs = buy_idxs.copy()\n",
    "signal_idxs.extend(sell_idxs)\n",
    "signal_idxs = sorted(signal_idxs)\n",
    "print(signal_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14, 94, 372, 395, 495, 524, 573, 608, 650, 694, 710, 731, 800, 917, 971, 1087, 1106, 1227, 1375, 1438, 1525, 1565, 1746, 1800, 1869, 1889, 1992, 2060, 2197, 2271, 2293, 2432, 2480, 2520, 2578, 2832, 2859, 2881, 2947, 2969, 3023, 3096, 3241, 3472, 3509, 3763, 3781, 3835, 3989, 4087, 4204, 4426, 4548, 4582, 4719, 4803, 4830, 4938, 4984, 5011, 5060, 5172, 5208, 5219, 5300, 5533, 5700, 5849, 5892, 5964, 6022, 6253, 6310, 6597, 6629, 6673, 6757, 6806, 6930, 7124, 7317, 7335, 7412, 7439, 7487, 7520, 7565, 7583, 7649, 7780, 7875, 7909, 8011, 8079, 8093, 8190, 8296, 8461, 8495, 8621, 8729, 8752, 8864, 8947, 9011, 9090, 9280, 9374, 9432, 9487]\n"
     ]
    }
   ],
   "source": [
    "signal_idxs_true = [i - 1 for i in signal_idxs]\n",
    "print(signal_idxs_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(signal_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['new_signal'] = 0\n",
    "df.loc[df.index.isin(signal_idxs_true), 'new_signal'] = df.loc[df.index.isin(signal_idxs_true), 'signal'].values\n",
    "# df.loc[~df.index.isin(signal_idxs), 'new_signal'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55, 8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['new_signal']==-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,\n",
       "        1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1,\n",
       "       -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,\n",
       "        1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1,\n",
       "       -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,\n",
       "        1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1,\n",
       "       -1,  1, -1,  1, -1,  1, -1,  1], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.index.isin(signal_idxs_true), 'signal'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['signal_prices'] = 0\n",
    "df.loc[df.index.isin(signal_idxs), 'signal_prices'] = df.loc[df.index.isin(signal_idxs), 'open'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16550. , 16569.6, 16568.5, 16554.5, 16536.9, 16532.7, 16543.3,\n",
       "       16531.5, 16539.6, 16550.4, 16563.7, 16543.6, 16541.3, 16558.2,\n",
       "       16561.6, 16570.8, 16599.9, 16569.1, 16568.7, 16548.6, 16548.2,\n",
       "       16458.4, 16531.8, 16526.2, 16518.8, 16507.5, 16517.5, 16513.5,\n",
       "       16496.3, 16515. , 16524.5, 16530.1, 16527.9, 16529.6, 16527.9,\n",
       "       16578.7, 16604.1, 16589. , 16587.5, 16580.3, 16589.1, 16583.1,\n",
       "       16564.4, 16630.3, 16685.1, 16706. , 16726.4, 16725.5, 16699.3,\n",
       "       16713.8, 16711.6, 16698.5, 16691.5, 16665.2, 16679.5, 16671.6,\n",
       "       16689.8, 16709.7, 16717.2, 16703.6, 16715.1, 16714.4, 16717.4,\n",
       "       16703. , 16716.4, 16606.1, 16640. , 16640.1, 16664.4, 16650.4,\n",
       "       16659.1, 16847.6, 16842.2, 16827. , 16842.5, 16828. , 16829. ,\n",
       "       16803.7, 16873.6, 16791.5, 16826. , 16803.6, 16862.2, 16836.1,\n",
       "       16834.1, 16812.5, 16829.1, 16816.5, 16819.6, 16821.1, 16812. ,\n",
       "       16797. , 16809.9, 16807. , 16816.3, 16799.1, 16820. , 16801.8,\n",
       "       16812. , 16829.9, 16837.5, 16828.6, 16826. , 16826.4, 16818.1,\n",
       "       16813.7, 16777.6, 16790.5, 16779.9, 16771.1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.index.isin(signal_idxs), 'open'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_list = np.zeros((2, df.shape[0]))\n",
    "signal_list[0][1:] = df['new_signal'].values[:-1]\n",
    "signal_list[1] = df['signal_prices'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15, 95, 373, 396, 496, 525, 574, 609, 651, 695, 711, 732, 801, 918, 972, 1088, 1107, 1228, 1376, 1439, 1526, 1566, 1747, 1801, 1870, 1890, 1993, 2061, 2198, 2272, 2294, 2433, 2481, 2521, 2579, 2833, 2860, 2882, 2948, 2970, 3024, 3097, 3242, 3473, 3510, 3764, 3782, 3836, 3990, 4088, 4205, 4427, 4549, 4583, 4720, 4804, 4831, 4939, 4985, 5012, 5061, 5173, 5209, 5220, 5301, 5534, 5701, 5850, 5893, 5965, 6023, 6254, 6311, 6598, 6630, 6674, 6758, 6807, 6931, 7125, 7318, 7336, 7413, 7440, 7488, 7521, 7566, 7584, 7650, 7781, 7876, 7910, 8012, 8080, 8094, 8191, 8297, 8462, 8496, 8622, 8730, 8753, 8865, 8948, 9012, 9091, 9281, 9375, 9433, 9488]\n"
     ]
    }
   ],
   "source": [
    "print([i for i in range(len(signal_list[0])) if signal_list[0][i] != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15, 95, 373, 396, 496, 525, 574, 609, 651, 695, 711, 732, 801, 918, 972, 1088, 1107, 1228, 1376, 1439, 1526, 1566, 1747, 1801, 1870, 1890, 1993, 2061, 2198, 2272, 2294, 2433, 2481, 2521, 2579, 2833, 2860, 2882, 2948, 2970, 3024, 3097, 3242, 3473, 3510, 3764, 3782, 3836, 3990, 4088, 4205, 4427, 4549, 4583, 4720, 4804, 4831, 4939, 4985, 5012, 5061, 5173, 5209, 5220, 5301, 5534, 5701, 5850, 5893, 5965, 6023, 6254, 6311, 6598, 6630, 6674, 6758, 6807, 6931, 7125, 7318, 7336, 7413, 7440, 7488, 7521, 7566, 7584, 7650, 7781, 7876, 7910, 8012, 8080, 8094, 8191, 8297, 8462, 8496, 8622, 8730, 8753, 8865, 8948, 9012, 9091, 9281, 9375, 9433, 9488]\n"
     ]
    }
   ],
   "source": [
    "print(signal_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entry testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed stop and target exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(cache=True)\n",
    "def get_exit_entry_testing1(\n",
    "    close_prices, \n",
    "    open_prices,  \n",
    "    signal_list,\n",
    "    stoploss_th,\n",
    "    takeprofit_th, \n",
    "    commission, \n",
    "    slippage, \n",
    "    init_inv, \n",
    "    trade_size\n",
    "):\n",
    "\n",
    "    exit_list = np.zeros((2, len(close_prices)))\n",
    "\n",
    "    for i in range(len(close_prices)-1):\n",
    "\n",
    "        if signal_list[1][i] == 0:\n",
    "\n",
    "            pass\n",
    "\n",
    "        else:\n",
    "\n",
    "            temp_n_assets = int(init_inv * trade_size / signal_list[1][i])\n",
    "            if signal_list[0][i] == 1:\n",
    "                temp_pnl = temp_n_assets * (close_prices[i] - signal_list[1][i] * (1 + slippage))\n",
    "            else:\n",
    "                temp_pnl = -temp_n_assets * (close_prices[i] - signal_list[1][i] * (1 - slippage))\n",
    "            temp_pnl = temp_pnl * (1 - commission)\n",
    "            init_inv += temp_pnl\n",
    "\n",
    "            if -temp_pnl >= stoploss_th or temp_pnl >= takeprofit_th:\n",
    "                exit_list[0][i+1] = -signal_list[0][i]\n",
    "                exit_list[1][i+1] = open_prices[i+1]\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "    return exit_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "exit_list = get_exit_entry_testing1(\n",
    "    close_prices=df['close'].values, \n",
    "    open_prices=df['open'].values,  \n",
    "    signal_list=signal_list,\n",
    "    stoploss_th=50,\n",
    "    takeprofit_th=100,\n",
    "    commission=COMMISSION, \n",
    "    slippage=SLIPPAGE, \n",
    "    init_inv=AVAILABLE_CAPITAL, \n",
    "    trade_size=TRADE_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8.0, 567961.2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(exit_list[0]), sum(exit_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 34)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.where(exit_list[0]!=0, 1, 0)), np.sum(np.where(exit_list[1]!=0, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16579. , 16538.8, 16569.5, 16562.8, 16562. , 16550. , 16490.6,\n",
       "       16526.3, 16585.7, 16587.5, 16628.7, 16721.4, 16713.5, 16710.3,\n",
       "       16716.5, 16685.4, 16633.6, 16636.5, 16668.5, 16844.7, 16844.9,\n",
       "       16801. , 16862.8, 16828.4, 16812.1, 16831.4, 16794.6, 16812.6,\n",
       "       16838.9, 16816. , 16827.3, 16819.9, 16798.8, 16761.2])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exit_list[1][exit_list[1]!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(cache=True)\n",
    "def get_signals(signal_list, exit_list):\n",
    "\n",
    "    start_idx = 0\n",
    "    exit_idx = 0\n",
    "   \n",
    "    for i in range(len(signal_list[0])):\n",
    "\n",
    "        if i == start_idx:\n",
    "\n",
    "            if signal_list[0][i] == 0:\n",
    "\n",
    "                start_idx += 1\n",
    "\n",
    "                exit_list[0][i] = 0\n",
    "\n",
    "            else:\n",
    "\n",
    "                for j in range(i+1, len(exit_list[0])):\n",
    "                    if exit_list[0][j] == -signal_list[0][i]:\n",
    "                        exit_idx = j\n",
    "                        break\n",
    "                    else:\n",
    "                        exit_idx = j\n",
    "\n",
    "                for k in range(i+1, exit_idx+1):\n",
    "                    if signal_list[0][k] == -signal_list[0][i]:\n",
    "                        exit_idx = k\n",
    "                        exit_list[1][k] = signal_list[1][k]\n",
    "                        break\n",
    "                    else:\n",
    "                        exit_idx = k\n",
    "\n",
    "                for p in range(i+1, exit_idx):\n",
    "                    signal_list[0][p] = 0\n",
    "                    exit_list[0][p] = 0\n",
    "                \n",
    "                if exit_idx == len(signal_list[0]) - 1 and exit_list[0][exit_idx] != -signal_list[0][i]:\n",
    "                    exit_list[0][exit_idx] = 0\n",
    "                    exit_list[0][i] = 0\n",
    "                    signal_list[0][exit_idx] = 0\n",
    "                else:\n",
    "                    exit_list[0][exit_idx] = -signal_list[0][i]\n",
    "                    exit_list[0][i] = 0\n",
    "                    signal_list[0][exit_idx] = 0\n",
    "                \n",
    "                start_idx = exit_idx + 1\n",
    "\n",
    "        else:\n",
    "\n",
    "            continue\n",
    "\n",
    "    if sum(np.abs(signal_list[0])) == sum(np.abs(exit_list[0])):\n",
    "\n",
    "        return signal_list, exit_list\n",
    "    \n",
    "    else:\n",
    "\n",
    "        for i in range(len(signal_list[0])):\n",
    "            if signal_list[0][-(i+1)] != 0:\n",
    "                signal_list[0][-(i+1)] = 0\n",
    "                break\n",
    "\n",
    "        return signal_list, exit_list\n",
    "    \n",
    "@njit(cache=True)\n",
    "def create_position_open_prices(signal_list, exit_list):\n",
    "\n",
    "    pos_open_prices = np.zeros(len(signal_list[0]))\n",
    "    pos_exit_prices = np.zeros(len(exit_list[0]))\n",
    "\n",
    "    start_idx = 0\n",
    "    price_idx = 0\n",
    "\n",
    "    for i in range(len(signal_list[0])):\n",
    "        if exit_list[0][i] != 0:\n",
    "            for j in range(start_idx, i):\n",
    "                if signal_list[0][j] != 0:\n",
    "                    price_idx = j\n",
    "                    break\n",
    "            pos_open_prices[i] = signal_list[1][price_idx]\n",
    "            pos_exit_prices[i] = exit_list[1][i]\n",
    "            start_idx = i\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    return pos_open_prices, pos_exit_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(cache=True)\n",
    "def get_pnl_testing(\n",
    "    trade_close_prices,\n",
    "    signal_list, \n",
    "    trade_open_prices,\n",
    "    commission=0.015,\n",
    "    slippage=0.05,\n",
    "    init_inv=20000,\n",
    "    trade_size=0.1\n",
    "):\n",
    "\n",
    "    pnl_list = np.zeros(len(trade_close_prices))\n",
    "\n",
    "    for i in range(len(trade_close_prices)):\n",
    "\n",
    "        if signal_list[i] == 0 or trade_open_prices[i] == 0:\n",
    "            pass\n",
    "        \n",
    "        # signal_list contains the points where exit occurs\n",
    "        elif signal_list[i] == -1: \n",
    "            temp_n_assets = int(init_inv * trade_size / trade_open_prices[i])\n",
    "            temp_pnl = temp_n_assets * (trade_close_prices[i] - trade_open_prices[i] * (1 + slippage)) \n",
    "            temp_pnl = temp_pnl * (1 - commission)\n",
    "            init_inv += temp_pnl\n",
    "\n",
    "        else:\n",
    "            temp_n_assets = int(init_inv * trade_size / trade_open_prices[i])\n",
    "            temp_pnl = temp_n_assets * (trade_open_prices[i] * (1 - slippage) - trade_close_prices[i])\n",
    "            temp_pnl = temp_pnl * (1 - commission)\n",
    "            init_inv += temp_pnl\n",
    "\n",
    "        pnl_list[i] = temp_pnl\n",
    "\n",
    "    return pnl_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.410714285714285"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_list, exit_list = get_signals(signal_list, exit_list)\n",
    "pos_open_prices, pos_exit_prices = create_position_open_prices(signal_list, exit_list)\n",
    "\n",
    "pnl_list = get_pnl_testing(\n",
    "    trade_close_prices=pos_exit_prices,\n",
    "    signal_list=exit_list[0], \n",
    "    trade_open_prices=pos_open_prices,\n",
    "    commission=COMMISSION, \n",
    "    slippage=SLIPPAGE, \n",
    "    init_inv=AVAILABLE_CAPITAL, \n",
    "    trade_size=TRADE_SIZE\n",
    ")\n",
    "\n",
    "winning_percent = 100 * sum(pnl_list > 0) / len(pnl_list)\n",
    "winning_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.501987281399046"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winning_percent = 100 * sum(pnl_list > 0) / np.sum(np.where(pnl_list!=0, 1, 0))\n",
    "winning_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10064"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.where(pnl_list!=0, 1, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed bar exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(cache=True)\n",
    "def get_exit_entry_testing2( \n",
    "    open_prices,  \n",
    "    signal_list,\n",
    "    n_exit_bars\n",
    "):\n",
    "\n",
    "    exit_list = np.zeros((2, len(signal_list[0])))\n",
    "\n",
    "    n_exit_bars = np.int64(n_exit_bars)\n",
    "\n",
    "    for i in range(len(signal_list[0])-1):\n",
    "\n",
    "        if signal_list[0][i] == 0:\n",
    "\n",
    "            pass\n",
    "\n",
    "        else:\n",
    "            \n",
    "            if i + n_exit_bars < len(signal_list[0]):\n",
    "                exit_list[0][i+n_exit_bars] = -signal_list[0][i]\n",
    "                exit_list[1][i+n_exit_bars] = open_prices[i+n_exit_bars]\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "    return exit_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "exit_list = get_exit_entry_testing2( \n",
    "    open_prices=df['open'].values,  \n",
    "    signal_list=signal_list,\n",
    "    n_exit_bars=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-16.0, 1067607.2)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(exit_list[0]), sum(exit_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.where(exit_list[0]!=0, 1, 0)), np.sum(np.where(exit_list[1]!=0, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.97420634920635"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_list, exit_list = get_signals(signal_list, exit_list)\n",
    "pos_open_prices, pos_exit_prices = create_position_open_prices(signal_list, exit_list)\n",
    "\n",
    "pnl_list = get_pnl_testing(\n",
    "    trade_close_prices=pos_exit_prices,\n",
    "    signal_list=exit_list[0], \n",
    "    trade_open_prices=pos_open_prices,\n",
    "    commission=COMMISSION, \n",
    "    slippage=SLIPPAGE, \n",
    "    init_inv=AVAILABLE_CAPITAL, \n",
    "    trade_size=TRADE_SIZE\n",
    ")\n",
    "\n",
    "winning_percent = 100 * sum(pnl_list > 0) / len(pnl_list)\n",
    "winning_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.04771371769384"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winning_percent = 100 * sum(pnl_list > 0) / np.sum(np.where(pnl_list!=0, 1, 0))\n",
    "winning_percent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(cache=True)\n",
    "def get_exit_entry_testing3( \n",
    "    open_prices,  \n",
    "    signal_list\n",
    "):\n",
    "\n",
    "    exit_list = np.zeros((2, len(signal_list[0])))\n",
    "\n",
    "    for i in range(len(signal_list[0])-1):\n",
    "\n",
    "        if signal_list[0][i] == 0:\n",
    "\n",
    "            pass\n",
    "\n",
    "        else:\n",
    "\n",
    "            for j in range(i+1, len(signal_list[0])):\n",
    "                if signal_list[0][j] != 0:\n",
    "                    j = j - 1\n",
    "                    break\n",
    "                else:\n",
    "                    if np.random.rand() > 0.5:\n",
    "                        break\n",
    "            \n",
    "            exit_list[0][j] = -signal_list[0][i]\n",
    "            exit_list[1][j] = open_prices[j]\n",
    "        \n",
    "    return exit_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "exit_list = get_exit_entry_testing3( \n",
    "    open_prices=df['open'].values,  \n",
    "    signal_list=signal_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-16.0, 1067603.0)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(exit_list[0]), sum(exit_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.where(exit_list[0]!=0, 1, 0)), np.sum(np.where(exit_list[1]!=0, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.172619047619047"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_list, exit_list = get_signals(signal_list, exit_list)\n",
    "pos_open_prices, pos_exit_prices = create_position_open_prices(signal_list, exit_list)\n",
    "\n",
    "pnl_list = get_pnl_testing(\n",
    "    trade_close_prices=pos_exit_prices,\n",
    "    signal_list=exit_list[0], \n",
    "    trade_open_prices=pos_open_prices,\n",
    "    commission=COMMISSION, \n",
    "    slippage=SLIPPAGE, \n",
    "    init_inv=AVAILABLE_CAPITAL, \n",
    "    trade_size=TRADE_SIZE\n",
    ")\n",
    "\n",
    "winning_percent = 100 * sum(pnl_list > 0) / len(pnl_list)\n",
    "winning_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.218523303189905"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winning_percent = 100 * sum(pnl_list > 0) / np.sum(np.where(pnl_list!=0, 1, 0))\n",
    "winning_percent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exit testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['exit_signal'] = 0\n",
    "df.loc[df.index.isin(signal_idxs_true[1:]), 'exit_signal'] = df.loc[df.index.isin(signal_idxs_true[1:]), 'signal'].values\n",
    "\n",
    "df['exit_prices'] = 0\n",
    "df.loc[df.index.isin(signal_idxs[1:]), 'exit_prices'] = df.loc[df.index.isin(signal_idxs[1:]), 'open'].values\n",
    "\n",
    "exit_list = np.zeros((2, df.shape[0]))\n",
    "exit_list[0][1:] = df['exit_signal'].values[:-1]\n",
    "exit_list[1] = df['exit_prices'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[95, 373, 396, 496, 525, 574, 609, 651, 695, 711, 732, 801, 918, 972, 1088, 1107, 1228, 1376, 1439, 1526, 1566, 1747, 1801, 1870, 1890, 1993, 2061, 2198, 2272, 2294, 2433, 2481, 2521, 2579, 2833, 2860, 2882, 2948, 2970, 3024, 3097, 3242, 3473, 3510, 3764, 3782, 3836, 3990, 4088, 4205, 4427, 4549, 4583, 4720, 4804, 4831, 4939, 4985, 5012, 5061, 5173, 5209, 5220, 5301, 5534, 5701, 5850, 5893, 5965, 6023, 6254, 6311, 6598, 6630, 6674, 6758, 6807, 6931, 7125, 7318, 7336, 7413, 7440, 7488, 7521, 7566, 7584, 7650, 7781, 7876, 7910, 8012, 8080, 8094, 8191, 8297, 8462, 8496, 8622, 8730, 8753, 8865, 8948, 9012, 9091, 9281, 9375, 9433, 9488]\n"
     ]
    }
   ],
   "source": [
    "print([i for i in range(len(exit_list[0])) if exit_list[0][i] != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[95, 373, 396, 496, 525, 574, 609, 651, 695, 711, 732, 801, 918, 972, 1088, 1107, 1228, 1376, 1439, 1526, 1566, 1747, 1801, 1870, 1890, 1993, 2061, 2198, 2272, 2294, 2433, 2481, 2521, 2579, 2833, 2860, 2882, 2948, 2970, 3024, 3097, 3242, 3473, 3510, 3764, 3782, 3836, 3990, 4088, 4205, 4427, 4549, 4583, 4720, 4804, 4831, 4939, 4985, 5012, 5061, 5173, 5209, 5220, 5301, 5534, 5701, 5850, 5893, 5965, 6023, 6254, 6311, 6598, 6630, 6674, 6758, 6807, 6931, 7125, 7318, 7336, 7413, 7440, 7488, 7521, 7566, 7584, 7650, 7781, 7876, 7910, 8012, 8080, 8094, 8191, 8297, 8462, 8496, 8622, 8730, 8753, 8865, 8948, 9012, 9091, 9281, 9375, 9433, 9488]\n"
     ]
    }
   ],
   "source": [
    "print(signal_idxs[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similar approach entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(cache=True)\n",
    "def get_entry_exit_testing1(\n",
    "    close_prices,\n",
    "    open_prices,\n",
    "    n_bars\n",
    "):\n",
    "\n",
    "    signal_list = np.zeros((2, len(close_prices)))\n",
    "\n",
    "    # n_bars = np.int64(n_bars)\n",
    "\n",
    "    for i in range(n_bars, len(signal_list[0])):\n",
    "            \n",
    "        if close_prices[i - n_bars] - close_prices[i - 1] > 0:\n",
    "            signal_list[0][i] = 1\n",
    "            signal_list[1][i] = open_prices[i]\n",
    "        elif close_prices[i - n_bars] - close_prices[i - 1] < 0:\n",
    "           signal_list[0][i] = -1\n",
    "           signal_list[1][i] = open_prices[i]\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    return signal_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_list = get_entry_exit_testing1(\n",
    "    close_prices=df['close'].values,\n",
    "    open_prices=df['open'].values,\n",
    "    n_bars=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72.0, 161171668.60000023)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(signal_list[0]), sum(signal_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9654, 9654)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.where(signal_list[0]!=0, 1, 0)), np.sum(np.where(signal_list[1]!=0, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47.291666666666664"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_list, exit_list = get_signals(signal_list, exit_list)\n",
    "pos_open_prices, pos_exit_prices = create_position_open_prices(signal_list, exit_list)\n",
    "\n",
    "pnl_list = get_pnl_testing(\n",
    "    trade_close_prices=pos_exit_prices,\n",
    "    signal_list=exit_list[0], \n",
    "    trade_open_prices=pos_open_prices,\n",
    "    commission=COMMISSION, \n",
    "    slippage=SLIPPAGE, \n",
    "    init_inv=AVAILABLE_CAPITAL, \n",
    "    trade_size=TRADE_SIZE\n",
    ")\n",
    "\n",
    "winning_percent = 100 * sum(pnl_list > 0) / len(pnl_list)\n",
    "winning_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47.3198332340679"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winning_percent = 100 * sum(pnl_list > 0) / np.sum(np.where(pnl_list!=0, 1, 0))\n",
    "winning_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(cache=True)\n",
    "def get_rsi(close_prices, prev_close_prices, length=14):\n",
    "    # Create numpy arrays to store the gain/loss values\n",
    "    gains = np.zeros(len(close_prices))\n",
    "    losses = np.zeros(len(close_prices))\n",
    "\n",
    "    # Iterate through the data frame and calculate the gain/loss for each period\n",
    "    for i in range(1, len(close_prices)):\n",
    "        change = close_prices[i] - prev_close_prices[i]\n",
    "        if change > 0:\n",
    "            gains[i] = change\n",
    "        elif change < 0:\n",
    "            losses[i] = abs(change)\n",
    "\n",
    "    # Calculate the average gain and loss for each period\n",
    "    avg_gains = np.zeros(len(close_prices))\n",
    "    avg_losses = np.zeros(len(close_prices))\n",
    "    for i in range(length, len(close_prices)):\n",
    "        avg_gains[i] = np.mean(gains[i-length:i])\n",
    "        avg_losses[i] = np.mean(losses[i-length:i])\n",
    "\n",
    "    # Calculate the relative strength and RSI for each period\n",
    "    rs = np.zeros(len(close_prices))\n",
    "    rsi = np.zeros(len(close_prices))\n",
    "    \n",
    "    for i in range(len(close_prices)):\n",
    "        if i+1 < length:\n",
    "            rsi[i] = -999\n",
    "        elif avg_losses[i] == 0:\n",
    "            rs[i] = avg_gains[i]\n",
    "            rsi[i] = 100\n",
    "        else:\n",
    "            rs[i] = avg_gains[i] / avg_losses[i]\n",
    "            rsi[i] = 100 - (100 / (1 + rs[i]))\n",
    "\n",
    "    return rsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(cache=True)\n",
    "def get_entry_exit_testing2(\n",
    "    close_prices, open_prices, prev_close_prices, rsi_window_size, rsi_threshold\n",
    "):\n",
    "\n",
    "    signal_list = np.zeros((2, len(close_prices)))\n",
    "\n",
    "    rsi = get_rsi(close_prices, prev_close_prices, length=rsi_window_size)\n",
    "\n",
    "    for i in range(len(close_prices)-1):\n",
    "\n",
    "        if i < rsi_window_size - 1 or rsi[i] == -999:\n",
    "            continue\n",
    "       \n",
    "        if rsi[i] < rsi_threshold:\n",
    "            signal_list[0][i+1] = 1\n",
    "            signal_list[1][i+1] = open_prices[i+1]\n",
    "        elif rsi[i] > (100 - rsi_threshold):\n",
    "            signal_list[0][i+1] = -1\n",
    "            signal_list[1][i+1] = open_prices[i+1]\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    return signal_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_list = get_entry_exit_testing2(\n",
    "    close_prices=df['close'].values, \n",
    "    open_prices=df['open'].values, \n",
    "    prev_close_prices=df['close'].shift(1).fillna(method='bfill').values, \n",
    "    rsi_window_size=10, \n",
    "    rsi_threshold = 20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34.0, 54070094.599999815)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(signal_list[0]), sum(signal_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3242, 3242)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.where(signal_list[0]!=0, 1, 0)), np.sum(np.where(signal_list[1]!=0, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.198412698412696"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_list, exit_list = get_signals(signal_list, exit_list)\n",
    "pos_open_prices, pos_exit_prices = create_position_open_prices(signal_list, exit_list)\n",
    "\n",
    "pnl_list = get_pnl_testing(\n",
    "    trade_close_prices=pos_exit_prices,\n",
    "    signal_list=exit_list[0], \n",
    "    trade_open_prices=pos_open_prices,\n",
    "    commission=COMMISSION, \n",
    "    slippage=SLIPPAGE, \n",
    "    init_inv=AVAILABLE_CAPITAL, \n",
    "    trade_size=TRADE_SIZE\n",
    ")\n",
    "\n",
    "winning_percent = 100 * sum(pnl_list > 0) / len(pnl_list)\n",
    "winning_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.30321105477682"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winning_percent = 100 * sum(pnl_list > 0) / np.sum(np.where(pnl_list!=0, 1, 0))\n",
    "winning_percent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(cache=True)\n",
    "def get_entry_exit_testing3(\n",
    "    open_prices\n",
    "):\n",
    "\n",
    "    signal_list = np.zeros((2, len(open_prices)))\n",
    "\n",
    "    for i in range(len(open_prices)-1):\n",
    "\n",
    "        if np.random.rand() > 0.7:\n",
    "            signal_list[0][i] = 1\n",
    "            signal_list[1][i] = open_prices[i]\n",
    "        elif np.random.rand() < 0.3:\n",
    "            signal_list[0][i] = -1\n",
    "            signal_list[1][i] = open_prices[i]\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    return signal_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_list = get_entry_exit_testing3(\n",
    "    open_prices=df['open'].values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(877.0, 85355821.69999993)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(signal_list[0]), sum(signal_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5113, 5113)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.where(signal_list[0]!=0, 1, 0)), np.sum(np.where(signal_list[1]!=0, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.541666666666664"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_list, exit_list = get_signals(signal_list, exit_list)\n",
    "pos_open_prices, pos_exit_prices = create_position_open_prices(signal_list, exit_list)\n",
    "\n",
    "pnl_list = get_pnl_testing(\n",
    "    trade_close_prices=pos_exit_prices,\n",
    "    signal_list=exit_list[0], \n",
    "    trade_open_prices=pos_open_prices,\n",
    "    commission=COMMISSION, \n",
    "    slippage=SLIPPAGE, \n",
    "    init_inv=AVAILABLE_CAPITAL, \n",
    "    trade_size=TRADE_SIZE\n",
    ")\n",
    "\n",
    "winning_percent = 100 * sum(pnl_list > 0) / len(pnl_list)\n",
    "winning_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.55831265508685"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winning_percent = 100 * sum(pnl_list > 0) / np.sum(np.where(pnl_list!=0, 1, 0))\n",
    "winning_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_52w_data(data_path):\n",
    "    df = pd.read_csv(data_path)\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "    df = df.iloc[-(7 * 60 * 24 * 52):]\n",
    "    df.sort_values('datetime', ascending=True, inplace=True)\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(524160, 6)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = Path(r'C:/\\Users/\\vchar/\\OneDrive/\\Desktop/\\ML Projects/\\Upwork/\\AlgoT_ML_Dev/\\GrammarEvolution/\\PonyGE2/\\datasets/\\BTCUSD_ohlcv.csv')\n",
    "df_52w = generate_52w_data(data_path)\n",
    "df_52w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_signal_txt = 'indicators.RSI(df=df, HistLength=10).values < 20'\n",
    "sell_signal_txt = 'indicators.RSI(df=df, HistLength=10).values > 80'\n",
    "lag_txt = '{i}'\n",
    "\n",
    "text_code = f'''import pandas as pd\n",
    "import numpy as np\n",
    "from src.fitness.indicators import indicators\n",
    "from numba import njit\n",
    "COMMISSION = 0.015\n",
    "SLIPPAGE = 0.00005\n",
    "AVAILABLE_CAPITAL = 700000\n",
    "TRADE_SIZE = 0.5\n",
    "\n",
    "@njit\n",
    "def merge_pnl(arr1, arr2):\n",
    "    out = np.zeros((len(arr1) + len(arr2)))\n",
    "    idx = 1\n",
    "    for i in range(len(arr1) + len(arr2)):\n",
    "        if i % 2 == 0:\n",
    "            out[i] = arr1[int(i/2)]\n",
    "        else:\n",
    "            out[i] = arr2[i-idx]\n",
    "        idx += 1\n",
    "    return out\n",
    "\n",
    "@njit\n",
    "def get_drawdowns(arr):\n",
    "    drawdowns = np.zeros((len(arr)))\n",
    "    max = arr[0]\n",
    "    for i in range(1, len(drawdowns)-1):\n",
    "        if arr[i-1] > arr[i] and arr[i] < arr[i+1]:\n",
    "            min = arr[i]\n",
    "            drawdowns[i] = max - min\n",
    "        elif arr[i-1] < arr[i] and arr[i] > arr[i+1]:\n",
    "            max = arr[i]\n",
    "    return drawdowns\n",
    "\n",
    "@njit\n",
    "def get_pnl(trade_close_prices, trade_open_prices, commission, slippage, init_inv, trade_size, is_buy):\n",
    "    pnl_list = np.zeros(len(trade_close_prices))\n",
    "    for i in range(len(trade_close_prices)):\n",
    "        temp_n_assets = int(init_inv * trade_size / trade_open_prices[i])\n",
    "        if is_buy == 1:\n",
    "            temp_pnl = temp_n_assets * (trade_close_prices[i] - trade_open_prices[i] * (1 + slippage))\n",
    "        else:\n",
    "            temp_pnl = -temp_n_assets * (trade_close_prices[i] - trade_open_prices[i] * (1 - slippage))\n",
    "        temp_pnl = temp_pnl * (1 - commission)\n",
    "        init_inv += temp_pnl\n",
    "        pnl_list[i] = temp_pnl\n",
    "    return pnl_list\n",
    "\n",
    "df = data.copy()\n",
    "# for i in range(1, 6):\n",
    "#     df[f'close_{lag_txt}'] = df['close'].shift(i)\n",
    "#     df[f'open_{lag_txt}'] = df['open'].shift(i)\n",
    "#     df[f'high_{lag_txt}'] = df['high'].shift(i)\n",
    "#     df[f'low_{lag_txt}'] = df['low'].shift(i)\n",
    "#     df[f'volume_{lag_txt}'] = df['volume'].shift(i)\n",
    "# df.dropna(inplace=True)\n",
    "# df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df['buy'] = ({buy_signal_txt}).astype(int)\n",
    "df['sell'] = ({sell_signal_txt}).astype(int)\n",
    "df['signal'] = df['buy'] + df['sell']\n",
    "df['signal'] = df['signal'].apply(lambda x: 1 if x==1 else 0)\n",
    "df['sell'] = df['sell'] * (-1)\n",
    "df['signal'] = df['signal'] * df['sell']\n",
    "df['signal'] = df['signal'] + df['buy']\n",
    "df.drop(columns=['buy', 'sell'], inplace=True)\n",
    "\n",
    "buy_idxs = []\n",
    "sell_idxs = []\n",
    "is_buy = 0\n",
    "is_sell = 0\n",
    "for i, row in enumerate(df.itertuples()):\n",
    "    if row.signal == 1 and is_buy == 0:\n",
    "        buy_idxs.append(i+1)\n",
    "        is_buy = 1\n",
    "        is_sell = 0\n",
    "    elif row.signal == -1 and is_sell == 0:\n",
    "        sell_idxs.append(i+1)\n",
    "        is_sell = 1\n",
    "        is_buy = 0\n",
    "\n",
    "if len(buy_idxs) > len(sell_idxs):\n",
    "    buy_idxs = buy_idxs[:-(len(buy_idxs) - len(sell_idxs))]\n",
    "elif len(buy_idxs) < len(sell_idxs):\n",
    "    sell_idxs = sell_idxs[:-(len(sell_idxs) - len(buy_idxs))]\n",
    "\n",
    "if len(buy_idxs) == 0 or len(sell_idxs) == 0:\n",
    "    print(\"not enough signals\")\n",
    "\n",
    "buy_prices = df[df.index.isin(buy_idxs)]['open'].values\n",
    "sell_prices = df[df.index.isin(sell_idxs)]['open'].values\n",
    "\n",
    "if buy_idxs[0] < sell_idxs[0]:\n",
    "    buy_arr = get_pnl(sell_prices, buy_prices, COMMISSION, SLIPPAGE, AVAILABLE_CAPITAL, TRADE_SIZE, 1)\n",
    "    buy_pnl = np.sum(buy_arr)\n",
    "    sell_arr = get_pnl(buy_prices[1:], sell_prices[:-1], COMMISSION, SLIPPAGE, AVAILABLE_CAPITAL, TRADE_SIZE, 0)\n",
    "    sell_pnl = np.sum(sell_arr)\n",
    "    all_arr = merge_pnl(buy_arr, sell_arr)\n",
    "else:\n",
    "    sell_arr = get_pnl(buy_prices, sell_prices, COMMISSION, SLIPPAGE, AVAILABLE_CAPITAL, TRADE_SIZE, 0)\n",
    "    sell_pnl = np.sum(sell_arr)\n",
    "    buy_arr = get_pnl(sell_prices[1:], buy_prices[:-1], COMMISSION, SLIPPAGE, AVAILABLE_CAPITAL, TRADE_SIZE, 1)\n",
    "    buy_pnl = np.sum(buy_arr)\n",
    "    all_arr = merge_pnl(sell_arr, buy_arr)\n",
    "\n",
    "total_pnl = buy_pnl + sell_pnl\n",
    "equity_curve_arr = np.cumsum(all_arr)\n",
    "drawdowns = get_drawdowns(equity_curve_arr)\n",
    "avg_drawdown = np.sum(drawdowns[drawdowns!=0]) / len(drawdowns[drawdowns!=0])\n",
    "fitness = total_pnl / avg_drawdown'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'data': df}\n",
    "exec(text_code, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20.931649876661233, 622.6980546194997, 13034.09765817344)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['fitness'], d['avg_drawdown'], d['total_pnl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_win_perc_entry_testing(data, text_code):\n",
    "\n",
    "    bars_per_5week = 7 * 60 * 24 * 5\n",
    "    n_bars_per_year = 7 * 60 * 24 * 52\n",
    "\n",
    "    n_not_worked = 0\n",
    "    n_total_cases = 0\n",
    "\n",
    "    entry_walk_forward_dict = defaultdict(list)\n",
    "\n",
    "    for idx in tqdm(range(0, n_bars_per_year, bars_per_5week)):\n",
    "\n",
    "        n_total_cases += 1\n",
    "\n",
    "        df = data.iloc[idx:idx+bars_per_5week, :]\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        try:\n",
    "            exec_dict = {'data': df}\n",
    "            exec(text_code, exec_dict)\n",
    "            df = exec_dict['df']\n",
    "\n",
    "            commission = exec_dict['COMMISSION']\n",
    "            slippage = exec_dict['SLIPPAGE'] \n",
    "            init_inv = exec_dict['AVAILABLE_CAPITAL']\n",
    "            trade_size = exec_dict['TRADE_SIZE'] \n",
    "\n",
    "            signal_idxs = exec_dict['buy_idxs'].copy()\n",
    "            signal_idxs.extend(exec_dict['sell_idxs'])\n",
    "            signal_idxs = sorted(signal_idxs)\n",
    "            signal_idxs_true = [i - 1 for i in signal_idxs]\n",
    "\n",
    "            df['new_signal'] = 0\n",
    "            df.loc[df.index.isin(signal_idxs_true), 'new_signal'] = df.loc[df.index.isin(signal_idxs_true), 'signal'].values\n",
    "            df['signal_prices'] = 0\n",
    "            df.loc[df.index.isin(signal_idxs), 'signal_prices'] = df.loc[df.index.isin(signal_idxs), 'open'].values\n",
    "\n",
    "            signal_list = np.zeros((2, df.shape[0]))\n",
    "            signal_list[0][1:] = df['new_signal'].values[:-1]\n",
    "            signal_list[1] = df['signal_prices'].values\n",
    "\n",
    "            # fixed stop and target exit testing\n",
    "            exit_list = get_exit_entry_testing1(\n",
    "                close_prices=df['close'].values, \n",
    "                open_prices=df['open'].values,  \n",
    "                signal_list=signal_list,\n",
    "                stoploss_th=50,\n",
    "                takeprofit_th=100,\n",
    "                commission=commission, \n",
    "                slippage=slippage, \n",
    "                init_inv=init_inv, \n",
    "                trade_size=trade_size\n",
    "            )\n",
    "\n",
    "            signal_list, exit_list = get_signals(signal_list, exit_list)\n",
    "            pos_open_prices, pos_exit_prices = create_position_open_prices(signal_list, exit_list)\n",
    "\n",
    "            pnl_list = get_pnl_testing(\n",
    "                trade_close_prices=pos_exit_prices,\n",
    "                signal_list=exit_list[0], \n",
    "                trade_open_prices=pos_open_prices,\n",
    "                commission=commission, \n",
    "                slippage=slippage, \n",
    "                init_inv=init_inv, \n",
    "                trade_size=trade_size\n",
    "            )\n",
    "\n",
    "            fixed_winning_percent = 100 * sum(pnl_list > 0) / np.sum(pnl_list != 0)\n",
    "            entry_walk_forward_dict['fixed_sp_testing'].append(fixed_winning_percent)\n",
    "\n",
    "            # fixed bar exit testing\n",
    "            exit_list = get_exit_entry_testing2( \n",
    "                open_prices=df['open'].values,  \n",
    "                signal_list=signal_list,\n",
    "                n_exit_bars=5\n",
    "            )\n",
    "\n",
    "            signal_list, exit_list = get_signals(signal_list, exit_list)\n",
    "            pos_open_prices, pos_exit_prices = create_position_open_prices(signal_list, exit_list)\n",
    "\n",
    "            pnl_list = get_pnl_testing(\n",
    "                trade_close_prices=pos_exit_prices,\n",
    "                signal_list=exit_list[0], \n",
    "                trade_open_prices=pos_open_prices,\n",
    "                commission=commission, \n",
    "                slippage=slippage, \n",
    "                init_inv=init_inv, \n",
    "                trade_size=trade_size\n",
    "            )\n",
    "\n",
    "            fixed_bar_winning_percent = 100 * sum(pnl_list > 0) / np.sum(pnl_list != 0)\n",
    "            entry_walk_forward_dict['fixed_bar_testing'].append(fixed_bar_winning_percent)\n",
    "\n",
    "            # random exit testing\n",
    "            exit_list = get_exit_entry_testing3( \n",
    "                open_prices=df['open'].values,  \n",
    "                signal_list=signal_list\n",
    "            )\n",
    "\n",
    "            signal_list, exit_list = get_signals(signal_list, exit_list)\n",
    "            pos_open_prices, pos_exit_prices = create_position_open_prices(signal_list, exit_list)\n",
    "\n",
    "            pnl_list = get_pnl_testing(\n",
    "                trade_close_prices=pos_exit_prices,\n",
    "                signal_list=exit_list[0], \n",
    "                trade_open_prices=pos_open_prices,\n",
    "                commission=commission, \n",
    "                slippage=slippage, \n",
    "                init_inv=init_inv, \n",
    "                trade_size=trade_size\n",
    "            )\n",
    "\n",
    "            random_winning_percent = 100 * sum(pnl_list > 0) / np.sum(pnl_list != 0)\n",
    "            entry_walk_forward_dict['random_exit_testing'].append(random_winning_percent)\n",
    "\n",
    "        except:\n",
    "\n",
    "            n_not_worked += 1\n",
    "\n",
    "    mean_win_perc_dict = defaultdict(list)\n",
    "\n",
    "    mean_win_perc_dict['Fixed_StopLoss_TakeProfit_testing'].\\\n",
    "        append(np.mean(entry_walk_forward_dict['fixed_sp_testing']))\n",
    "    mean_win_perc_dict['Fixed_Bar_testing'].\\\n",
    "        append(np.mean(entry_walk_forward_dict['fixed_bar_testing']))\n",
    "    mean_win_perc_dict['Random_Exit_testing'].\\\n",
    "        append(np.mean(entry_walk_forward_dict['random_exit_testing']))\n",
    "    mean_win_perc_dict['Not_Working'].\\\n",
    "        append(100 * n_not_worked / n_total_cases)\n",
    "    \n",
    "    win_pc_df = pd.DataFrame(mean_win_perc_dict)\n",
    "\n",
    "    return win_pc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 11/11 [00:11<00:00,  1.08s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buy</th>\n",
       "      <th>sell</th>\n",
       "      <th>Fixed_StopLoss_TakeProfit_testing</th>\n",
       "      <th>Fixed_Bar_testing</th>\n",
       "      <th>Random_Exit_testing</th>\n",
       "      <th>Not_Working</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>indicators.RSI(df=df, HistLength=10).values &lt; 20</td>\n",
       "      <td>indicators.RSI(df=df, HistLength=10).values &gt; 80</td>\n",
       "      <td>52.243935</td>\n",
       "      <td>49.675599</td>\n",
       "      <td>46.452423</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                buy  \\\n",
       "0  indicators.RSI(df=df, HistLength=10).values < 20   \n",
       "\n",
       "                                               sell  \\\n",
       "0  indicators.RSI(df=df, HistLength=10).values > 80   \n",
       "\n",
       "   Fixed_StopLoss_TakeProfit_testing  Fixed_Bar_testing  Random_Exit_testing  \\\n",
       "0                          52.243935          49.675599            46.452423   \n",
       "\n",
       "   Not_Working  \n",
       "0          0.0  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = Path(r'C:/\\Users/\\vchar/\\OneDrive/\\Desktop/\\ML Projects/\\Upwork/\\AlgoT_ML_Dev/\\GrammarEvolution/\\PonyGE2/\\datasets/\\BTCUSD_ohlcv.csv')\n",
    "df_52w = generate_52w_data(data_path)\n",
    "\n",
    "entry_win_pc_df = calculate_mean_win_perc_entry_testing(\n",
    "    data=df_52w, \n",
    "    text_code=text_code\n",
    ")\n",
    "\n",
    "temp_signal_df = pd.DataFrame({'buy': [buy_signal_txt], 'sell': [sell_signal_txt]})\n",
    "\n",
    "entry_win_pc_df = pd.concat([temp_signal_df, entry_win_pc_df], axis=1)\n",
    "entry_win_pc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_win_perc_exit_testing(data, text_code):\n",
    "\n",
    "    bars_per_5week = 7 * 60 * 24 * 5\n",
    "    n_bars_per_year = 7 * 60 * 24 * 52\n",
    "\n",
    "    n_not_worked = 0\n",
    "    n_total_cases = 0\n",
    "\n",
    "    exit_walk_forward_dict = defaultdict(list)\n",
    "\n",
    "    for idx in tqdm(range(0, n_bars_per_year, bars_per_5week)):\n",
    "\n",
    "        n_total_cases += 1\n",
    "\n",
    "        df = data.iloc[idx:idx+bars_per_5week, :]\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        try:\n",
    "\n",
    "            exec_dict = {'data': df}\n",
    "            exec(text_code, exec_dict)\n",
    "            df = exec_dict['df']\n",
    "\n",
    "            commission = exec_dict['COMMISSION']\n",
    "            slippage = exec_dict['SLIPPAGE'] \n",
    "            init_inv = exec_dict['AVAILABLE_CAPITAL']\n",
    "            trade_size = exec_dict['TRADE_SIZE']       \n",
    "\n",
    "            signal_idxs = exec_dict['buy_idxs'].copy()\n",
    "            signal_idxs.extend(exec_dict['sell_idxs'])\n",
    "            signal_idxs = sorted(signal_idxs)\n",
    "            signal_idxs_true = [i - 1 for i in signal_idxs]\n",
    "\n",
    "            df['exit_signal'] = 0\n",
    "            df.loc[df.index.isin(signal_idxs_true[1:]), 'exit_signal'] = df.loc[df.index.isin(signal_idxs_true[1:]), 'signal'].values\n",
    "            df['exit_prices'] = 0\n",
    "            df.loc[df.index.isin(signal_idxs[1:]), 'exit_prices'] = df.loc[df.index.isin(signal_idxs[1:]), 'open'].values\n",
    "\n",
    "            exit_list = np.zeros((2, df.shape[0]))\n",
    "            exit_list[0][1:] = df['exit_signal'].values[:-1]\n",
    "            exit_list[1] = df['exit_prices'].values\n",
    "\n",
    "            # replacing entry with trend following entry\n",
    "            signal_list = get_entry_exit_testing1(\n",
    "                close_prices=df['close'].values,\n",
    "                open_prices=df['open'].values,\n",
    "                n_bars=5\n",
    "            )\n",
    "\n",
    "            signal_list, exit_list = get_signals(signal_list, exit_list)\n",
    "            pos_open_prices, pos_exit_prices = create_position_open_prices(signal_list, exit_list)\n",
    "\n",
    "            pnl_list = get_pnl_testing(\n",
    "                trade_close_prices=pos_exit_prices,\n",
    "                signal_list=exit_list[0], \n",
    "                trade_open_prices=pos_open_prices,\n",
    "                commission=commission, \n",
    "                slippage=slippage, \n",
    "                init_inv=init_inv, \n",
    "                trade_size=trade_size\n",
    "            )\n",
    "\n",
    "            fixed_winning_percent = 100 * sum(pnl_list > 0) / np.sum(pnl_list != 0)\n",
    "            exit_walk_forward_dict['trend_entry_testing'].append(fixed_winning_percent)\n",
    "\n",
    "            # replacing entry with countertrend entry\n",
    "            signal_list = get_entry_exit_testing2(\n",
    "                close_prices=df['close'].values, \n",
    "                open_prices=df['open'].values, \n",
    "                prev_close_prices=df['close'].shift(1).fillna(method='bfill').values, \n",
    "                rsi_window_size=10, \n",
    "                rsi_threshold = 20\n",
    "            )\n",
    "\n",
    "            signal_list, exit_list = get_signals(signal_list, exit_list)\n",
    "            pos_open_prices, pos_exit_prices = create_position_open_prices(signal_list, exit_list)\n",
    "\n",
    "            pnl_list = get_pnl_testing(\n",
    "                trade_close_prices=pos_exit_prices,\n",
    "                signal_list=exit_list[0], \n",
    "                trade_open_prices=pos_open_prices,\n",
    "                commission=commission, \n",
    "                slippage=slippage, \n",
    "                init_inv=init_inv, \n",
    "                trade_size=trade_size\n",
    "            )\n",
    "\n",
    "            fixed_bar_winning_percent = 100 * sum(pnl_list > 0) / np.sum(pnl_list != 0)\n",
    "            exit_walk_forward_dict['countertrend_entry_testing'].append(fixed_bar_winning_percent)\n",
    "\n",
    "            # random entry testing\n",
    "            signal_list = get_entry_exit_testing3(\n",
    "                open_prices=df['open'].values\n",
    "            )\n",
    "\n",
    "            signal_list, exit_list = get_signals(signal_list, exit_list)\n",
    "            pos_open_prices, pos_exit_prices = create_position_open_prices(signal_list, exit_list)\n",
    "\n",
    "            pnl_list = get_pnl_testing(\n",
    "                trade_close_prices=pos_exit_prices,\n",
    "                signal_list=exit_list[0], \n",
    "                trade_open_prices=pos_open_prices,\n",
    "                commission=commission, \n",
    "                slippage=slippage, \n",
    "                init_inv=init_inv, \n",
    "                trade_size=trade_size\n",
    "            )\n",
    "\n",
    "            random_winning_percent = 100 * sum(pnl_list > 0) / np.sum(pnl_list != 0)\n",
    "            exit_walk_forward_dict['random_entry_testing'].append(random_winning_percent)\n",
    "\n",
    "        except:\n",
    "\n",
    "            n_not_worked += 1\n",
    "\n",
    "    mean_win_perc_dict = defaultdict(list)\n",
    "\n",
    "    mean_win_perc_dict['Trend_testing'].\\\n",
    "        append(np.mean(exit_walk_forward_dict['trend_entry_testing']))\n",
    "    mean_win_perc_dict['Countertrend_testing'].\\\n",
    "        append(np.mean(exit_walk_forward_dict['countertrend_entry_testing']))\n",
    "    mean_win_perc_dict['Random_Entry_testing'].\\\n",
    "        append(np.mean(exit_walk_forward_dict['random_entry_testing']))\n",
    "    mean_win_perc_dict['Not_Working'].\\\n",
    "        append(100 * n_not_worked / n_total_cases)\n",
    "    \n",
    "    win_pc_df = pd.DataFrame(mean_win_perc_dict)\n",
    "\n",
    "    return win_pc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 11/11 [00:12<00:00,  1.12s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buy</th>\n",
       "      <th>sell</th>\n",
       "      <th>Trend_testing</th>\n",
       "      <th>Countertrend_testing</th>\n",
       "      <th>Random_Entry_testing</th>\n",
       "      <th>Not_Working</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>indicators.RSI(df=df, HistLength=10).values &lt; 20</td>\n",
       "      <td>indicators.RSI(df=df, HistLength=10).values &gt; 80</td>\n",
       "      <td>57.485339</td>\n",
       "      <td>57.937155</td>\n",
       "      <td>44.505765</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                buy  \\\n",
       "0  indicators.RSI(df=df, HistLength=10).values < 20   \n",
       "\n",
       "                                               sell  Trend_testing  \\\n",
       "0  indicators.RSI(df=df, HistLength=10).values > 80      57.485339   \n",
       "\n",
       "   Countertrend_testing  Random_Entry_testing  Not_Working  \n",
       "0             57.937155             44.505765          0.0  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_path = Path(r'C:/\\Users/\\vchar/\\OneDrive/\\Desktop/\\ML Projects/\\Upwork/\\AlgoT_ML_Dev/\\GrammarEvolution/\\PonyGE2/\\datasets/\\BTCUSD_ohlcv.csv')\n",
    "# df_52w = generate_52w_data(data_path)\n",
    "\n",
    "exit_win_pc_df = calculate_mean_win_perc_exit_testing(\n",
    "    data=df_52w, \n",
    "    text_code=text_code\n",
    ")\n",
    "\n",
    "temp_signal_df = pd.DataFrame({'buy': [buy_signal_txt], 'sell': [sell_signal_txt]})\n",
    "\n",
    "exit_win_pc_df = pd.concat([temp_signal_df, exit_win_pc_df], axis=1)\n",
    "exit_win_pc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_win_perc_core_testing(data, text_code):\n",
    "\n",
    "    bars_per_5week = 7 * 60 * 24 * 5\n",
    "    n_bars_per_year = 7 * 60 * 24 * 52\n",
    "\n",
    "    n_not_worked = 0\n",
    "    n_total_cases = 0\n",
    "\n",
    "    core_walk_forward_dict = defaultdict(list)\n",
    "\n",
    "    for idx in tqdm(range(0, n_bars_per_year, bars_per_5week)):\n",
    "\n",
    "        n_total_cases += 1\n",
    "\n",
    "        df = data.iloc[idx:idx+bars_per_5week, :]\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        try:\n",
    "            exec_dict = {'data': df}\n",
    "            exec(text_code, exec_dict)\n",
    "            df = exec_dict['df']\n",
    "            pnl_list = exec_dict['all_arr']\n",
    "\n",
    "            winning_percent = 100 * sum(pnl_list > 0) / np.sum(pnl_list != 0)\n",
    "            core_walk_forward_dict['core_testing'].append(winning_percent)\n",
    "        except:\n",
    "            n_not_worked += 1\n",
    "\n",
    "    mean_win_perc_dict = defaultdict(list)\n",
    "    mean_win_perc_dict['Core_Testing'].\\\n",
    "        append(np.mean(core_walk_forward_dict['core_testing']))\n",
    "    mean_win_perc_dict['Not_Working'].\\\n",
    "        append(100 * n_not_worked / n_total_cases)\n",
    "    \n",
    "    win_pc_df = pd.DataFrame(mean_win_perc_dict)\n",
    "\n",
    "    return win_pc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 11/11 [00:12<00:00,  1.13s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buy</th>\n",
       "      <th>sell</th>\n",
       "      <th>Core_Testing</th>\n",
       "      <th>Not_Working</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>indicators.RSI(df=df, HistLength=10).values &lt; 20</td>\n",
       "      <td>indicators.RSI(df=df, HistLength=10).values &gt; 80</td>\n",
       "      <td>78.30893</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                buy  \\\n",
       "0  indicators.RSI(df=df, HistLength=10).values < 20   \n",
       "\n",
       "                                               sell  Core_Testing  Not_Working  \n",
       "0  indicators.RSI(df=df, HistLength=10).values > 80      78.30893          0.0  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "core_win_pc_df = calculate_mean_win_perc_core_testing(\n",
    "    data=df_52w, \n",
    "    text_code=text_code\n",
    ")\n",
    "\n",
    "temp_signal_df = pd.DataFrame({'buy': [buy_signal_txt], 'sell': [sell_signal_txt]})\n",
    "coret_win_pc_df = pd.concat([temp_signal_df, core_win_pc_df], axis=1)\n",
    "coret_win_pc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(cache=True)\n",
    "def get_drawdown(pnl_list):\n",
    "\n",
    "    # running_total = np.cumsum(pnl_list)\n",
    "    # max_running_total = np.maximum.accumulate(running_total)\n",
    "\n",
    "    running_total = np.zeros(len(pnl_list))\n",
    "    max_running_total = np.zeros(len(pnl_list))\n",
    "\n",
    "    for i in range(len(pnl_list)):\n",
    "        if i == 0:\n",
    "            running_total[i] = pnl_list[i]\n",
    "            max_running_total[i] = pnl_list[i]\n",
    "        else:\n",
    "            running_total[i] = running_total[i-1] + pnl_list[i]\n",
    "            max_running_total[i] = max([max_running_total[i-1], pnl_list[i]])\n",
    "\n",
    "    min_total = running_total[np.argmin(running_total)]\n",
    "\n",
    "    max_total = max_running_total[np.argmin(running_total)]\n",
    "\n",
    "    if max_total == 0:\n",
    "        max_total = 0.00001\n",
    "\n",
    "    max_drawdown = 100 * (min_total - max_total) / max_total\n",
    "\n",
    "    if max_drawdown == -1:\n",
    "        max_drawdown = 0\n",
    "\n",
    "    return max_drawdown\n",
    "\n",
    "@njit(cache=True)\n",
    "def get_sharpe_ratio(\n",
    "    pnl_list, \n",
    "    risk_free_rate=0\n",
    "):\n",
    "    # mean_return = np.mean(pnl_list)\n",
    "    mean_return = 0\n",
    "    for i in range(len(pnl_list)):\n",
    "        mean_return += pnl_list[i]\n",
    "\n",
    "    if len(pnl_list) == 0:\n",
    "        mean_return = 0\n",
    "    else:\n",
    "        mean_return = mean_return / len(pnl_list)\n",
    "\n",
    "    # std_dev = np.std(pnl_list)\n",
    "    std_dev = 0\n",
    "    for i in range(len(pnl_list)):\n",
    "        std_dev += (pnl_list[i] - mean_return) ** 2\n",
    "\n",
    "    if len(pnl_list) == 1:\n",
    "        std_dev = np.sqrt(std_dev/len(pnl_list))\n",
    "    else:\n",
    "        std_dev = np.sqrt(std_dev/(len(pnl_list) - 1))\n",
    "\n",
    "    if std_dev == 0:\n",
    "        std_dev += 0.0001\n",
    "\n",
    "    sharpe_ratio = (mean_return - risk_free_rate) / std_dev\n",
    "    return sharpe_ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_performance(data, text_code):\n",
    "\n",
    "    bars_per_5week = 7 * 60 * 24 * 5\n",
    "    n_bars_per_year = 7 * 60 * 24 * 52\n",
    "\n",
    "    n_not_worked = 0\n",
    "    n_total_cases = 0\n",
    "\n",
    "    performance_walk_forward_dict = defaultdict(list)\n",
    "\n",
    "    for idx in tqdm(range(0, n_bars_per_year, bars_per_5week)):\n",
    "\n",
    "        n_total_cases += 1\n",
    "\n",
    "        df = data.iloc[idx:idx+bars_per_5week, :]\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        try:\n",
    "            exec_dict = {'data': df}\n",
    "            exec(text_code, exec_dict)\n",
    "            df = exec_dict['df']\n",
    "            pnl_list = exec_dict['all_arr']\n",
    "\n",
    "            init_inv = exec_dict['AVAILABLE_CAPITAL']\n",
    "            trade_size = exec_dict['TRADE_SIZE']       \n",
    "\n",
    "            signal_idxs = exec_dict['buy_idxs'].copy()\n",
    "            signal_idxs.extend(exec_dict['sell_idxs'])\n",
    "            signal_idxs = sorted(signal_idxs)\n",
    "\n",
    "            performance_walk_forward_dict['n_trades'].append(len(signal_idxs) - 1)\n",
    "            performance_walk_forward_dict['pnl'].append(np.sum(pnl_list))\n",
    "            performance_walk_forward_dict['roi'].append(100 * np.sum(pnl_list) / (trade_size * init_inv))\n",
    "            performance_walk_forward_dict['avg_drawdown'].append(exec_dict['avg_drawdown'])\n",
    "            performance_walk_forward_dict['drawdown'].append(get_drawdown(pnl_list))\n",
    "            performance_walk_forward_dict['pnl_avgd_ratio'].append(exec_dict['fitness'])\n",
    "            performance_walk_forward_dict['sharpe_ratio'].append(get_sharpe_ratio(pnl_list, risk_free_rate=0))\n",
    "        except:\n",
    "            n_not_worked += 1\n",
    "\n",
    "    mean_perf_dict = defaultdict(list)\n",
    "    mean_perf_dict['N_Trades'].\\\n",
    "        append(np.mean(performance_walk_forward_dict['n_trades']))\n",
    "    mean_perf_dict['PNL'].\\\n",
    "        append(np.mean(performance_walk_forward_dict['pnl']))\n",
    "    mean_perf_dict['ROI'].\\\n",
    "        append(np.mean(performance_walk_forward_dict['roi']))\n",
    "    mean_perf_dict['AVG_Drawdown'].\\\n",
    "        append(np.mean(performance_walk_forward_dict['avg_drawdown']))\n",
    "    mean_perf_dict['Drawdown'].\\\n",
    "        append(np.mean(performance_walk_forward_dict['drawdown']))\n",
    "    mean_perf_dict['PNL_AVGD_Ratio'].\\\n",
    "        append(np.mean(performance_walk_forward_dict['pnl_avgd_ratio']))\n",
    "    mean_perf_dict['Sharpe_Ratio'].\\\n",
    "        append(np.mean(performance_walk_forward_dict['sharpe_ratio']))\n",
    "    mean_perf_dict['Not_Working'].\\\n",
    "        append(100 * n_not_worked / n_total_cases)\n",
    "    \n",
    "    perf_df = pd.DataFrame(mean_perf_dict)\n",
    "\n",
    "    return perf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 11/11 [00:12<00:00,  1.13s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buy</th>\n",
       "      <th>sell</th>\n",
       "      <th>N_Trades</th>\n",
       "      <th>PNL</th>\n",
       "      <th>ROI</th>\n",
       "      <th>AVG_Drawdown</th>\n",
       "      <th>Drawdown (%)</th>\n",
       "      <th>PNL_AVGD_Ratio</th>\n",
       "      <th>Sharpe_Ratio</th>\n",
       "      <th>Not_Working</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>indicators.RSI(df=df, HistLength=10).values &lt; 20</td>\n",
       "      <td>indicators.RSI(df=df, HistLength=10).values &gt; 80</td>\n",
       "      <td>294.272727</td>\n",
       "      <td>329938.762362</td>\n",
       "      <td>94.268218</td>\n",
       "      <td>2747.807435</td>\n",
       "      <td>-79.734246</td>\n",
       "      <td>13.940902</td>\n",
       "      <td>0.327276</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                buy  \\\n",
       "0  indicators.RSI(df=df, HistLength=10).values < 20   \n",
       "\n",
       "                                               sell    N_Trades  \\\n",
       "0  indicators.RSI(df=df, HistLength=10).values > 80  294.272727   \n",
       "\n",
       "             PNL        ROI  AVG_Drawdown  Drawdown (%)  PNL_AVGD_Ratio  \\\n",
       "0  329938.762362  94.268218   2747.807435    -79.734246       13.940902   \n",
       "\n",
       "   Sharpe_Ratio  Not_Working  \n",
       "0      0.327276          0.0  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_df = calculate_mean_performance(\n",
    "    data=df_52w, \n",
    "    text_code=text_code\n",
    ")\n",
    "\n",
    "temp_signal_df = pd.DataFrame({'buy': [buy_signal_txt], 'sell': [sell_signal_txt]})\n",
    "perf_df = pd.concat([temp_signal_df, perf_df], axis=1)\n",
    "perf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Equity curve simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import njit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(cache=True)\n",
    "def get_max_drawdown(pnl_list):\n",
    "    max_dd = 0.0\n",
    "    peak = pnl_list[0]\n",
    "\n",
    "    for i in range(1, len(pnl_list)):\n",
    "        if pnl_list[i] > peak:\n",
    "            peak = pnl_list[i]\n",
    "        drawdown = 100 * (peak - pnl_list[i]) / peak\n",
    "        if drawdown > max_dd:\n",
    "            max_dd = drawdown\n",
    "\n",
    "    return max_dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median max drawdown: 99.94857352302125\n",
      "Median profit: 1512.5274058036653\n",
      "Median return: 0.4321506873724758\n",
      "Return/Drawdown: 0.0043237304159517405\n",
      "Prob>0: 1.0\n"
     ]
    }
   ],
   "source": [
    "# np.random.seed(42)\n",
    "\n",
    "pnl_list = np.random.rand(3000)\n",
    "\n",
    "init_inv = 700000\n",
    "trade_size = 0.5\n",
    "\n",
    "max_dd_list = []\n",
    "profit_list = []\n",
    "roi_list = []\n",
    "binary_profit_list = []\n",
    "\n",
    "for i in range(10000):\n",
    "\n",
    "    temp_pnl_list = np.random.choice(pnl_list, size=len(pnl_list), replace=True)\n",
    "\n",
    "    max_dd = get_max_drawdown(temp_pnl_list)\n",
    "    max_dd_list.append(max_dd)\n",
    "\n",
    "    profit_list.append(np.sum(temp_pnl_list))\n",
    "    roi_list.append(100 * np.sum(temp_pnl_list) / (init_inv * trade_size))\n",
    "    is_profit = 1 if np.sum(temp_pnl_list) > 0 else 0\n",
    "    binary_profit_list.append(is_profit)\n",
    "\n",
    "median_max_dd = np.median(max_dd_list)\n",
    "median_profit = np.median(profit_list)\n",
    "median_return = np.median(roi_list)\n",
    "return_dd_ratio = median_return / median_max_dd\n",
    "prob_profit = np.sum(binary_profit_list) / len(binary_profit_list)\n",
    "\n",
    "print(f'Median max drawdown: {median_max_dd}')\n",
    "print(f'Median profit: {median_profit}')\n",
    "print(f'Median return: {median_return}')\n",
    "print(f'Return/Drawdown: {return_dd_ratio}')\n",
    "print(f'Prob>0: {prob_profit}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mc_results(pnl_list, init_inv, trade_size, n_runs):\n",
    "\n",
    "    max_dd_list = []\n",
    "    profit_list = []\n",
    "    roi_list = []\n",
    "    binary_profit_list = []\n",
    "\n",
    "    for _ in range(n_runs):\n",
    "\n",
    "        temp_pnl_list = np.random.choice(pnl_list, size=len(pnl_list), replace=True)\n",
    "\n",
    "        max_dd = get_max_drawdown(temp_pnl_list)\n",
    "        max_dd_list.append(max_dd)\n",
    "\n",
    "        profit_list.append(np.sum(temp_pnl_list))\n",
    "        roi_list.append(100 * np.sum(temp_pnl_list) / (init_inv * trade_size))\n",
    "        is_profit = 1 if np.sum(temp_pnl_list) > 0 else 0\n",
    "        binary_profit_list.append(is_profit)\n",
    "\n",
    "    mc_dict = {}\n",
    "    mc_dict['median_max_dd'] = np.median(max_dd_list)\n",
    "    mc_dict['median_profit'] = np.median(profit_list)\n",
    "    mc_dict['median_return'] = np.median(roi_list)\n",
    "    mc_dict['return_dd_ratio'] = np.median(roi_list) / np.median(max_dd_list)\n",
    "    mc_dict['prob_profit'] = np.sum(binary_profit_list) / len(binary_profit_list)\n",
    "\n",
    "    return mc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'median_max_dd': 99.94857352302125,\n",
       " 'median_profit': 1512.4943093197248,\n",
       " 'median_return': 0.43214123123420706,\n",
       " 'return_dd_ratio': 0.004323635805914444,\n",
       " 'prob_profit': 1.0}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_mc_results(pnl_list, init_inv, trade_size, n_runs=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "import numpy as np\n",
    "\n",
    "@cuda.jit\n",
    "def merge_pnl(arr1, arr2, out):\n",
    "    i = cuda.grid(1)\n",
    "    if i < len(out):\n",
    "        if i % 2 == 0:\n",
    "            out[i] = arr1[i // 2]\n",
    "        else:\n",
    "            out[i] = arr2[i // 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def get_drawdowns(arr, drawdowns):\n",
    "    i = cuda.grid(1)\n",
    "    if i == 0:\n",
    "        return\n",
    "    max_val = cuda.shared.array((1,), dtype=np.float32)\n",
    "    if i == 1:\n",
    "        max_val[0] = arr[0]\n",
    "\n",
    "    if i < len(arr) - 1:\n",
    "        if arr[i - 1] > arr[i] < arr[i + 1]:\n",
    "            drawdowns[i] = max_val[0] - arr[i]\n",
    "        elif arr[i - 1] < arr[i] > arr[i + 1]:\n",
    "            max_val[0] = arr[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def get_pnl(trade_close_prices, trade_open_prices, pnl_list, commission, slippage, init_inv, trade_size, is_buy):\n",
    "    i = cuda.grid(1)\n",
    "    if i < len(trade_close_prices):\n",
    "        temp_n_assets = int(init_inv * trade_size / trade_open_prices[i])\n",
    "        temp_pnl = temp_n_assets * (trade_close_prices[i] - trade_open_prices[i] * (1 + slippage)) if is_buy == 1 else -temp_n_assets * (trade_close_prices[i] - trade_open_prices[i] * (1 - slippage))\n",
    "        temp_pnl = temp_pnl * (1 - commission)\n",
    "        init_inv += temp_pnl\n",
    "        pnl_list[i] = temp_pnl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trading_signals(buy_signal, sell_signal):\n",
    "    buy = np.where(buy_signal, 1, 0)\n",
    "    sell = np.where(sell_signal, -1, 0)\n",
    "    signal = buy + sell\n",
    "    buy_idxs, sell_idxs = [], []\n",
    "    is_buy, is_sell = 0, 0\n",
    "    for i in range(len(signal)):\n",
    "        if signal[i] == 1 and is_buy == 0:\n",
    "            buy_idxs.append(i + 1)\n",
    "            is_buy, is_sell = 1, 0\n",
    "        elif signal[i] == -1 and is_sell == 0:\n",
    "            sell_idxs.append(i + 1)\n",
    "            is_sell, is_buy = 1, 0\n",
    "    return buy_idxs[:min(len(buy_idxs), len(sell_idxs))], sell_idxs[:min(len(buy_idxs), len(sell_idxs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def get_lag(prices, result, lag):\n",
    "    i = cuda.grid(1)\n",
    "    if i >= lag:\n",
    "        result[i] = prices[i - lag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize arrays with sample data\n",
    "arr1 = np.array(list(np.random.rand(200000)), dtype=np.float32)  # Replace with actual data\n",
    "arr2 = np.array(list(np.random.rand(200000)), dtype=np.float32)\n",
    "out = np.zeros(len(arr1) + len(arr2), dtype=np.float32)\n",
    "\n",
    "# Transfer data to the GPU\n",
    "d_arr1 = cuda.to_device(arr1)\n",
    "d_arr2 = cuda.to_device(arr2)\n",
    "d_out = cuda.to_device(out)\n",
    "\n",
    "# Define the grid and block sizes\n",
    "threads_per_block = 128\n",
    "blocks_per_grid = (len(out) + threads_per_block - 1) // threads_per_block\n",
    "\n",
    "# Launch the kernel\n",
    "merge_pnl[blocks_per_grid, threads_per_block](d_arr1, d_arr2, d_out)\n",
    "\n",
    "# Copy result back to host\n",
    "result = d_out.copy_to_host()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def generate_52w_data(data_path):\n",
    "    df = pd.read_csv(data_path)\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "    df = df.iloc[-(7 * 60 * 24 * 52):]\n",
    "    df.sort_values('datetime', ascending=True, inplace=True)\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "data_path = Path(r'C:/\\Users/\\vchar/\\OneDrive/\\Desktop/\\ML Projects/\\Upwork/\\AlgoT_ML_Dev/\\GrammarEvolution/\\PonyGE2/\\datasets/\\all_data_1min.csv')\n",
    "df = generate_52w_data(data_path)\n",
    "# price_data.head()\n",
    "\n",
    "price_data = {}\n",
    "for col in df.columns:\n",
    "    if col == 'datetime':\n",
    "        continue\n",
    "    else:\n",
    "        price_data[col] = df[col].values\n",
    "\n",
    "price_data['day_of_week'] = (df['datetime'].dt.dayofweek + 1).values\n",
    "price_data['month'] = df['datetime'].dt.month.values\n",
    "price_data['day_of_year'] = df['datetime'].dt.dayofyear.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "CUR_DIR = os.getcwd()\n",
    "os.chdir('src')\n",
    "#import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from fitness.indicators import numba_indicators\n",
    "from fitness.performance.helper_func import merge_pnl, get_drawdowns, get_pnl, trading_signals, get_lag\n",
    "os.chdir(CUR_DIR)\n",
    "#from numba import njit\n",
    "COMMISSION = 0.015\n",
    "SLIPPAGE = 0.00005\n",
    "AVAILABLE_CAPITAL = 700000\n",
    "TRADE_SIZE = 0.5\n",
    "MAX_LAG = 5\n",
    "buy_signal_txt = get_lag(price_data['aapl_volume'], lag=5)[MAX_LAG:] < get_lag(price_data['aapl_high'], lag=5)[MAX_LAG:]\n",
    "sell_signal_txt = get_lag(price_data['dog_volume'], lag=2)[MAX_LAG:] < get_lag(price_data['pltr_open'], lag=2)[MAX_LAG:]\n",
    "buy_idxs, sell_idxs = trading_signals(buy_signal=buy_signal_txt, sell_signal=sell_signal_txt)\n",
    "if len(buy_idxs) == 0 or len(sell_idxs) == 0:\n",
    "    fitness = -999\n",
    "else:\n",
    "    buy_idxs = np.array(buy_idxs)\n",
    "    sell_idxs = np.array(sell_idxs)\n",
    "    open_prices = price_data['btc_open']\n",
    "    buy_prices = open_prices[np.isin(np.arange(len(open_prices)), buy_idxs)]\n",
    "    sell_prices = open_prices[np.isin(np.arange(len(open_prices)), sell_idxs)]\n",
    "    if buy_idxs[0] < sell_idxs[0]:\n",
    "        buy_arr = get_pnl(sell_prices, buy_prices, COMMISSION, SLIPPAGE, AVAILABLE_CAPITAL, TRADE_SIZE, 1)\n",
    "        buy_pnl = np.sum(buy_arr)\n",
    "        sell_arr = get_pnl(buy_prices[1:], sell_prices[:-1], COMMISSION, SLIPPAGE, AVAILABLE_CAPITAL, TRADE_SIZE, 0)\n",
    "        sell_pnl = np.sum(sell_arr)\n",
    "        all_arr = merge_pnl(buy_arr, sell_arr)\n",
    "    else:\n",
    "        sell_arr = get_pnl(buy_prices, sell_prices, COMMISSION, SLIPPAGE, AVAILABLE_CAPITAL, TRADE_SIZE, 0)\n",
    "        sell_pnl = np.sum(sell_arr)\n",
    "        buy_arr = get_pnl(sell_prices[1:], buy_prices[:-1], COMMISSION, SLIPPAGE, AVAILABLE_CAPITAL, TRADE_SIZE, 1)\n",
    "        buy_pnl = np.sum(buy_arr)\n",
    "        all_arr = merge_pnl(sell_arr, buy_arr)\n",
    "    total_pnl = buy_pnl + sell_pnl\n",
    "    equity_curve_arr = np.cumsum(all_arr)\n",
    "    drawdowns = get_drawdowns(equity_curve_arr)\n",
    "    avg_drawdown = np.sum(drawdowns[drawdowns!=0]) / len(drawdowns[drawdowns!=0])\n",
    "    fitness = total_pnl / avg_drawdown\n",
    "    if np.isnan(fitness) or total_pnl <= 0 or len(drawdowns[drawdowns!=0]) == 0:\n",
    "        fitness = -999\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.783004842293362"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "CUR_DIR = os.getcwd()\n",
    "os.chdir('src')\n",
    "import numpy as np\n",
    "import gc\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor\n",
    "from fitness.indicators import numba_indicators\n",
    "from fitness.performance.helper_func import merge_pnl, get_drawdowns, get_pnl, trading_signals, get_lag\n",
    "\n",
    "os.chdir(CUR_DIR)\n",
    "\n",
    "COMMISSION = 0.015\n",
    "SLIPPAGE = 0.00005\n",
    "AVAILABLE_CAPITAL = 700000\n",
    "TRADE_SIZE = 0.5\n",
    "MAX_LAG = 5\n",
    "\n",
    "# Parallelize the lag and signal calculations\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    future_buy_signal = executor.submit(get_lag, price_data['aapl_volume'], lag=5)\n",
    "    future_sell_signal = executor.submit(get_lag, price_data['dog_volume'], lag=2)\n",
    "    buy_lag = future_buy_signal.result()\n",
    "    sell_lag = future_sell_signal.result()\n",
    "\n",
    "buy_signal_txt = buy_lag[MAX_LAG:] < get_lag(price_data['aapl_high'], lag=5)[MAX_LAG:]\n",
    "sell_signal_txt = sell_lag[MAX_LAG:] < get_lag(price_data['pltr_open'], lag=2)[MAX_LAG:]\n",
    "buy_idxs, sell_idxs = trading_signals(buy_signal=buy_signal_txt, sell_signal=sell_signal_txt)\n",
    "\n",
    "if len(buy_idxs) == 0 or len(sell_idxs) == 0:\n",
    "    fitness = -999\n",
    "else:\n",
    "    buy_idxs = np.array(buy_idxs)\n",
    "    sell_idxs = np.array(sell_idxs)\n",
    "    open_prices = price_data['btc_open']\n",
    "    buy_prices = open_prices[np.isin(np.arange(len(open_prices)), buy_idxs)]\n",
    "    sell_prices = open_prices[np.isin(np.arange(len(open_prices)), sell_idxs)]\n",
    "\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        if buy_idxs[0] < sell_idxs[0]:\n",
    "            # Parallelize pnl calculations\n",
    "            future_buy = executor.submit(get_pnl, sell_prices, buy_prices, COMMISSION, SLIPPAGE, AVAILABLE_CAPITAL, TRADE_SIZE, 1)\n",
    "            future_sell = executor.submit(get_pnl, buy_prices[1:], sell_prices[:-1], COMMISSION, SLIPPAGE, AVAILABLE_CAPITAL, TRADE_SIZE, 0)\n",
    "            buy_arr = future_buy.result()\n",
    "            sell_arr = future_sell.result()\n",
    "            all_arr = merge_pnl(buy_arr, sell_arr)\n",
    "        else:\n",
    "            future_sell = executor.submit(get_pnl, buy_prices, sell_prices, COMMISSION, SLIPPAGE, AVAILABLE_CAPITAL, TRADE_SIZE, 0)\n",
    "            future_buy = executor.submit(get_pnl, sell_prices[1:], buy_prices[:-1], COMMISSION, SLIPPAGE, AVAILABLE_CAPITAL, TRADE_SIZE, 1)\n",
    "            sell_arr = future_sell.result()\n",
    "            buy_arr = future_buy.result()\n",
    "            all_arr = merge_pnl(sell_arr, buy_arr)\n",
    "\n",
    "    buy_pnl = np.sum(buy_arr)\n",
    "    sell_pnl = np.sum(sell_arr)\n",
    "    total_pnl = buy_pnl + sell_pnl\n",
    "\n",
    "    # Calculate drawdowns\n",
    "    equity_curve_arr = np.cumsum(all_arr)\n",
    "    drawdowns = get_drawdowns(equity_curve_arr)\n",
    "    avg_drawdown = np.sum(drawdowns[drawdowns!=0]) / len(drawdowns[drawdowns!=0])\n",
    "    fitness = total_pnl / avg_drawdown if not np.isnan(fitness) and total_pnl > 0 and len(drawdowns[drawdowns!=0]) != 0 else -999\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.783004842293362"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gc\n",
    "import dask\n",
    "from dask import delayed, compute\n",
    "from dask.distributed import Client\n",
    "from fitness.indicators import numba_indicators\n",
    "from fitness.performance.helper_func import merge_pnl, get_drawdowns, get_pnl, trading_signals, get_lag\n",
    "import os\n",
    "\n",
    "os.chdir(CUR_DIR)\n",
    "client = Client()  # Initialize a Dask client\n",
    "\n",
    "COMMISSION = 0.015\n",
    "SLIPPAGE = 0.00005\n",
    "AVAILABLE_CAPITAL = 700000\n",
    "TRADE_SIZE = 0.5\n",
    "MAX_LAG = 5\n",
    "\n",
    "# Define delayed tasks for parallel execution\n",
    "buy_signal_lag = delayed(get_lag)(price_data['aapl_volume'], lag=5)\n",
    "sell_signal_lag = delayed(get_lag)(price_data['dog_volume'], lag=2)\n",
    "aapl_high_lag = delayed(get_lag)(price_data['aapl_high'], lag=5)\n",
    "pltr_open_lag = delayed(get_lag)(price_data['pltr_open'], lag=2)\n",
    "\n",
    "buy_signal_txt = buy_signal_lag[MAX_LAG:] < aapl_high_lag[MAX_LAG:]\n",
    "sell_signal_txt = sell_signal_lag[MAX_LAG:] < pltr_open_lag[MAX_LAG:]\n",
    "\n",
    "# Compute signals\n",
    "buy_signal_txt, sell_signal_txt = compute(buy_signal_txt, sell_signal_txt)\n",
    "buy_idxs, sell_idxs = trading_signals(buy_signal=buy_signal_txt, sell_signal=sell_signal_txt)\n",
    "\n",
    "if len(buy_idxs) == 0 or len(sell_idxs) == 0:\n",
    "    fitness = -999\n",
    "else:\n",
    "    buy_idxs = np.array(buy_idxs)\n",
    "    sell_idxs = np.array(sell_idxs)\n",
    "    open_prices = price_data['btc_open']\n",
    "    buy_prices = open_prices[np.isin(np.arange(len(open_prices)), buy_idxs)]\n",
    "    sell_prices = open_prices[np.isin(np.arange(len(open_prices)), sell_idxs)]\n",
    "\n",
    "    # Define delayed PnL calculations\n",
    "    if buy_idxs[0] < sell_idxs[0]:\n",
    "        buy_task = delayed(get_pnl)(sell_prices, buy_prices, COMMISSION, SLIPPAGE, AVAILABLE_CAPITAL, TRADE_SIZE, 1)\n",
    "        sell_task = delayed(get_pnl)(buy_prices[1:], sell_prices[:-1], COMMISSION, SLIPPAGE, AVAILABLE_CAPITAL, TRADE_SIZE, 0)\n",
    "        all_arr = delayed(merge_pnl)(buy_task, sell_task)\n",
    "    else:\n",
    "        sell_task = delayed(get_pnl)(buy_prices, sell_prices, COMMISSION, SLIPPAGE, AVAILABLE_CAPITAL, TRADE_SIZE, 0)\n",
    "        buy_task = delayed(get_pnl)(sell_prices[1:], buy_prices[:-1], COMMISSION, SLIPPAGE, AVAILABLE_CAPITAL, TRADE_SIZE, 1)\n",
    "        all_arr = delayed(merge_pnl)(sell_task, buy_task)\n",
    "\n",
    "    # Compute PnL and merge results\n",
    "    buy_arr, sell_arr, all_arr = compute(buy_task, sell_task, all_arr)\n",
    "    buy_pnl = np.sum(buy_arr)\n",
    "    sell_pnl = np.sum(sell_arr)\n",
    "    total_pnl = buy_pnl + sell_pnl\n",
    "\n",
    "    # Calculate drawdowns using Dask\n",
    "    equity_curve_arr = np.cumsum(all_arr)\n",
    "    drawdown_task = delayed(get_drawdowns)(equity_curve_arr)\n",
    "    drawdowns = drawdown_task.compute()\n",
    "\n",
    "    # Calculate fitness\n",
    "    avg_drawdown = np.sum(drawdowns[drawdowns != 0]) / len(drawdowns[drawdowns != 0])\n",
    "    fitness = total_pnl / avg_drawdown if not np.isnan(fitness) and total_pnl > 0 and len(drawdowns[drawdowns != 0]) != 0 else -999\n",
    "\n",
    "gc.collect()\n",
    "client.close()  # Close the Dask client when done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.783004842293362"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.8733557466392465"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numba import njit\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "@njit(cache=True)\n",
    "def sortino_ratio(profit_loss, target_pl=0):\n",
    "\n",
    "    downside_pnl = profit_loss[profit_loss < target_pl]\n",
    "    if len(downside_pnl) == 0:\n",
    "        return 0\n",
    "\n",
    "    downside_deviation = np.sqrt(np.mean((downside_pnl - target_pl) ** 2))\n",
    "    if downside_deviation == 0:\n",
    "        return 0\n",
    "\n",
    "    mean_pnl = np.mean(profit_loss)\n",
    "    sortino_ratio = (mean_pnl - target_pl) / downside_deviation\n",
    "\n",
    "    return sortino_ratio\n",
    "\n",
    "temp_arr = np.random.rand(100)\n",
    "temp_arr2 = np.random.rand(100)\n",
    "temp_arr3 = np.random.rand(100)\n",
    "temp_arr4 = np.random.rand(100) * (-1)\n",
    "sortino_ratio(temp_arr4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "csv_path = Path(r'C:/\\Users/\\vchar/\\OneDrive/\\Desktop/\\ML Projects/\\Upwork/\\AlgoT_ML_Dev/\\GrammarEvolution/\\PonyGE2/\\results/\\VCh_24_10_17_205608_321434_47732_321434/\\ge_results_inst_ind_comb_numba.csv')\n",
    "\n",
    "df = pd.read_csv(csv_path, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buy</th>\n",
       "      <th>sell</th>\n",
       "      <th>fitness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>get_lag(price_data['btc_close'], lag=5)[MAX_LA...</td>\n",
       "      <td>get_lag(price_data['nvda_low'], lag=3)[MAX_LAG...</td>\n",
       "      <td>999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>get_lag(price_data['aapl_volume'], lag=4)[MAX_...</td>\n",
       "      <td>get_lag(price_data['cl_high'], lag=4)[MAX_LAG:...</td>\n",
       "      <td>999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>get_lag(price_data['tsla_high'], lag=4)[MAX_LA...</td>\n",
       "      <td>get_lag(price_data['fet_volume'], lag=3)[MAX_L...</td>\n",
       "      <td>999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>get_lag(price_data['aav_open'], lag=4)[MAX_LAG...</td>\n",
       "      <td>get_lag(price_data['sui_low'], lag=1)[MAX_LAG:...</td>\n",
       "      <td>999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>get_lag(price_data['ng_open'], lag=3)[MAX_LAG:...</td>\n",
       "      <td>get_lag(price_data['tsla_high'], lag=1)[MAX_LA...</td>\n",
       "      <td>999.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 buy  \\\n",
       "0  get_lag(price_data['btc_close'], lag=5)[MAX_LA...   \n",
       "1  get_lag(price_data['aapl_volume'], lag=4)[MAX_...   \n",
       "2  get_lag(price_data['tsla_high'], lag=4)[MAX_LA...   \n",
       "3  get_lag(price_data['aav_open'], lag=4)[MAX_LAG...   \n",
       "4  get_lag(price_data['ng_open'], lag=3)[MAX_LAG:...   \n",
       "\n",
       "                                                sell  fitness  \n",
       "0  get_lag(price_data['nvda_low'], lag=3)[MAX_LAG...    999.0  \n",
       "1  get_lag(price_data['cl_high'], lag=4)[MAX_LAG:...    999.0  \n",
       "2  get_lag(price_data['fet_volume'], lag=3)[MAX_L...    999.0  \n",
       "3  get_lag(price_data['sui_low'], lag=1)[MAX_LAG:...    999.0  \n",
       "4  get_lag(price_data['tsla_high'], lag=1)[MAX_LA...    999.0  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49355, 3)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49355, 3)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[~df.duplicated()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49355, 3)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[(~df.duplicated()) & (df['fitness'] != 'fitness')]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['buy', 'sell', 'fitness'], dtype='object')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49355 entries, 0 to 49354\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   buy      49355 non-null  object \n",
      " 1   sell     49355 non-null  object \n",
      " 2   fitness  49355 non-null  float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buy</th>\n",
       "      <th>sell</th>\n",
       "      <th>fitness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>price_data['lin_close'][MAX_LAG:] &gt;= get_lag(p...</td>\n",
       "      <td>get_lag(price_data['pltr_volume'], lag=5)[MAX_...</td>\n",
       "      <td>-96.605888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>get_lag(price_data['tia_open'], lag=4)[MAX_LAG...</td>\n",
       "      <td>get_lag(price_data['fet_volume'], lag=3)[MAX_L...</td>\n",
       "      <td>-33.659914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>get_lag(price_data['aav_low'], lag=5)[MAX_LAG:...</td>\n",
       "      <td>get_lag(price_data['fet_volume'], lag=5)[MAX_L...</td>\n",
       "      <td>-8.925688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(np.sqrt(price_data['sui_open'][MAX_LAG:]) // ...</td>\n",
       "      <td>numba_indicators.on_balance_volume(price=price...</td>\n",
       "      <td>-5.680848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>get_lag(price_data['aav_close'], lag=2)[MAX_LA...</td>\n",
       "      <td>(get_lag(price_data['amzn_close'], lag=3)[MAX_...</td>\n",
       "      <td>-9.228982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>get_lag(price_data['googl_volume'], lag=4)[MAX...</td>\n",
       "      <td>(np.sin(numba_indicators.delta_reactivity(numb...</td>\n",
       "      <td>-50.673933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1654</th>\n",
       "      <td>get_lag(price_data['sui_volume'], lag=4)[MAX_L...</td>\n",
       "      <td>(get_lag(price_data['btc_volume'], lag=3)[MAX_...</td>\n",
       "      <td>-4128.236283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1655</th>\n",
       "      <td>get_lag(price_data['sui_volume'], lag=4)[MAX_L...</td>\n",
       "      <td>price_data['googl_volume'][MAX_LAG:] &lt;= 630</td>\n",
       "      <td>-21.908317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1656</th>\n",
       "      <td>get_lag(price_data['googl_volume'], lag=4)[MAX...</td>\n",
       "      <td>(np.sin(numba_indicators.delta_reactivity(numb...</td>\n",
       "      <td>-15.606512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>get_lag(price_data['sui_volume'], lag=4)[MAX_L...</td>\n",
       "      <td>(get_lag(price_data['btc_volume'], lag=3)[MAX_...</td>\n",
       "      <td>-4128.236283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1658 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    buy  \\\n",
       "0     price_data['lin_close'][MAX_LAG:] >= get_lag(p...   \n",
       "1     get_lag(price_data['tia_open'], lag=4)[MAX_LAG...   \n",
       "2     get_lag(price_data['aav_low'], lag=5)[MAX_LAG:...   \n",
       "3     (np.sqrt(price_data['sui_open'][MAX_LAG:]) // ...   \n",
       "4     get_lag(price_data['aav_close'], lag=2)[MAX_LA...   \n",
       "...                                                 ...   \n",
       "1653  get_lag(price_data['googl_volume'], lag=4)[MAX...   \n",
       "1654  get_lag(price_data['sui_volume'], lag=4)[MAX_L...   \n",
       "1655  get_lag(price_data['sui_volume'], lag=4)[MAX_L...   \n",
       "1656  get_lag(price_data['googl_volume'], lag=4)[MAX...   \n",
       "1657  get_lag(price_data['sui_volume'], lag=4)[MAX_L...   \n",
       "\n",
       "                                                   sell      fitness  \n",
       "0     get_lag(price_data['pltr_volume'], lag=5)[MAX_...   -96.605888  \n",
       "1     get_lag(price_data['fet_volume'], lag=3)[MAX_L...   -33.659914  \n",
       "2     get_lag(price_data['fet_volume'], lag=5)[MAX_L...    -8.925688  \n",
       "3     numba_indicators.on_balance_volume(price=price...    -5.680848  \n",
       "4     (get_lag(price_data['amzn_close'], lag=3)[MAX_...    -9.228982  \n",
       "...                                                 ...          ...  \n",
       "1653  (np.sin(numba_indicators.delta_reactivity(numb...   -50.673933  \n",
       "1654  (get_lag(price_data['btc_volume'], lag=3)[MAX_... -4128.236283  \n",
       "1655        price_data['googl_volume'][MAX_LAG:] <= 630   -21.908317  \n",
       "1656  (np.sin(numba_indicators.delta_reactivity(numb...   -15.606512  \n",
       "1657  (get_lag(price_data['btc_volume'], lag=3)[MAX_... -4128.236283  \n",
       "\n",
       "[1658 rows x 3 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df['fitness'] = df['fitness'].apply(lambda x: float(x.strip()))\n",
    "df = df[df['fitness'] < 0].reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([27, 52, 53, 69, 89], [18, 19, 28, 85, 96])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "temp_arr = np.random.rand(100)\n",
    "\n",
    "buy_idxs = np.array([1, 14, 47, 69, 97])\n",
    "sell_idxs = np.array([7, 31, 55, 81, 99])\n",
    "\n",
    "new_buy_idxs = sorted(np.random.choice(np.arange(100), size=len(buy_idxs), replace=False))\n",
    "possible_sell_idxs_arr = np.arange(100)\n",
    "possible_sell_idxs_arr = [i for i in possible_sell_idxs_arr if i not in new_buy_idxs]\n",
    "new_sell_idxs = sorted(np.random.choice(np.arange(100), size=len(sell_idxs), replace=False))\n",
    "new_buy_idxs, new_sell_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.11402232, 0.65989122, 0.59174298, 0.46496872, 0.2422387 ]),\n",
       " array([0.70276495, 0.58868152, 0.94868271, 0.68164955, 0.34086948]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buy_prices = temp_arr[np.isin(np.arange(len(temp_arr)), new_buy_idxs)]\n",
    "sell_prices = temp_arr[np.isin(np.arange(len(temp_arr)), new_sell_idxs)]\n",
    "buy_prices, sell_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "CUR_DIR = os.getcwd()\n",
    "os.chdir('src')\n",
    "#import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from fitness.indicators import numba_indicators\n",
    "from fitness.performance.helper_func import merge_pnl, get_drawdowns, get_pnl, trading_signals, get_lag, get_monkey_entry_results\n",
    "os.chdir(CUR_DIR)\n",
    "#from numba import njit\n",
    "COMMISSION = 0.015\n",
    "SLIPPAGE = 0.00005\n",
    "AVAILABLE_CAPITAL = 700000\n",
    "TRADE_SIZE = 0.5\n",
    "MAX_LAG = 5\n",
    "buy_idxs, sell_idxs = trading_signals(buy_signal={buy_signal_txt}, sell_signal={sell_signal_txt})\n",
    "pnl_arr, max_dd_arr = get_monkey_entry_results(open_prices, buy_idxs, sell_idxs, COMMISSION, SLIPPAGE, AVAILABLE_CAPITAL, TRADE_SIZE)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import njit\n",
    "\n",
    "@njit(cache=True)\n",
    "def merge_pnl(arr1, arr2):\n",
    "\n",
    "    out = np.zeros((len(arr1) + len(arr2)))\n",
    "    idx = 1\n",
    "\n",
    "    for i in range(len(arr1) + len(arr2)):\n",
    "        \n",
    "        if i % 2 == 0:\n",
    "            out[i] = arr1[int(i/2)]\n",
    "        else:\n",
    "            out[i] = arr2[i-idx]\n",
    "\n",
    "        idx += 1\n",
    "\n",
    "    return out\n",
    "\n",
    "@njit(cache=True)\n",
    "def get_drawdowns(arr):\n",
    "\n",
    "    drawdowns = np.zeros((len(arr)))\n",
    "    max = arr[0]\n",
    "\n",
    "    for i in range(1, len(drawdowns)-1):\n",
    "\n",
    "        if arr[i-1] > arr[i] and arr[i] < arr[i+1]:\n",
    "            min = arr[i]\n",
    "            drawdowns[i] = max - min\n",
    "        elif arr[i-1] < arr[i] and arr[i] > arr[i+1]:\n",
    "            max = arr[i]\n",
    "\n",
    "    return drawdowns\n",
    "\n",
    "@njit(cache=True)\n",
    "def get_pnl(trade_close_prices, trade_open_prices, commission, slippage, init_inv, trade_size, is_buy):\n",
    "\n",
    "    pnl_list = np.zeros(len(trade_close_prices))\n",
    "\n",
    "    for i in range(len(trade_close_prices)):\n",
    "\n",
    "        temp_n_assets = int(init_inv * trade_size / trade_open_prices[i])\n",
    "\n",
    "        if is_buy == 1:\n",
    "            temp_pnl = temp_n_assets * (trade_close_prices[i] - trade_open_prices[i] * (1 + slippage))\n",
    "        else:\n",
    "            temp_pnl = -temp_n_assets * (trade_close_prices[i] - trade_open_prices[i] * (1 - slippage))\n",
    "\n",
    "        temp_pnl = temp_pnl * (1 - commission)\n",
    "        init_inv += temp_pnl\n",
    "        pnl_list[i] = temp_pnl\n",
    "\n",
    "    return pnl_list\n",
    "\n",
    "@njit(cache=True)\n",
    "def trading_signals(buy_signal, sell_signal):\n",
    "    buy = np.where(buy_signal, 1, 0)\n",
    "    sell = np.where(sell_signal, -1, 0)\n",
    "    signal = buy + sell\n",
    "    buy_idxs = []\n",
    "    sell_idxs = []\n",
    "    is_buy = 0\n",
    "    is_sell = 0\n",
    "    for i in range(len(signal)):\n",
    "        if signal[i] == 1 and is_buy == 0:\n",
    "            buy_idxs.append(i + 1)\n",
    "            is_buy = 1\n",
    "            is_sell = 0\n",
    "        elif signal[i] == -1 and is_sell == 0:\n",
    "            sell_idxs.append(i + 1)\n",
    "            is_sell = 1\n",
    "            is_buy = 0\n",
    "    if len(buy_idxs) > len(sell_idxs):\n",
    "        buy_idxs = buy_idxs[:-(len(buy_idxs) - len(sell_idxs))]\n",
    "    elif len(buy_idxs) < len(sell_idxs):\n",
    "        sell_idxs = sell_idxs[:-(len(sell_idxs) - len(buy_idxs))]\n",
    "    return buy_idxs, sell_idxs\n",
    "\n",
    "@njit(cache=True)\n",
    "def get_lag(prices, lag=1):\n",
    "    n = len(prices)\n",
    "    result = np.full(n, -999, dtype=np.float64)  # Initialize with -999\n",
    "\n",
    "    for i in range(lag, n):\n",
    "        result[i] = prices[i - lag]\n",
    "\n",
    "    return result\n",
    "\n",
    "@njit(cache=True)\n",
    "def get_max_drawdown(pnl_list):\n",
    "    max_dd = 0.0\n",
    "    peak = pnl_list[0]\n",
    "\n",
    "    for i in range(1, len(pnl_list)):\n",
    "        if pnl_list[i] > peak:\n",
    "            peak = pnl_list[i]\n",
    "        drawdown = 100 * (peak - pnl_list[i]) / peak\n",
    "        if drawdown > max_dd:\n",
    "            max_dd = drawdown\n",
    "\n",
    "    return max_dd\n",
    "\n",
    "@njit(cache=True)\n",
    "def get_drawdown(pnl_list):\n",
    "    max_dd = 0.0\n",
    "    peak = pnl_list[0]\n",
    "\n",
    "    for i in range(1, len(pnl_list)):\n",
    "        if pnl_list[i] > peak:\n",
    "            peak = pnl_list[i]\n",
    "        drawdown = 100 * (peak - pnl_list[i]) / peak\n",
    "        if drawdown > max_dd:\n",
    "            max_dd = drawdown\n",
    "\n",
    "    return max_dd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([26, 38, 87, 89, 95])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numba import njit\n",
    "\n",
    "@njit(cache=True)\n",
    "def get_random_idxs(arr, num_elements, exclude_arr=np.array([])):\n",
    "    # Get the length of the input array\n",
    "    n = len(arr)\n",
    "\n",
    "    if num_elements > n:\n",
    "        raise ValueError(\"num_elements must be less than or equal to the length of the array.\")\n",
    "\n",
    "    # Set up the set of excluded indices for quick look-up\n",
    "    exclude_set = set(exclude_arr)\n",
    "\n",
    "    # Create an array to hold unique indices\n",
    "    indices = np.zeros(num_elements, dtype=np.int32)\n",
    "    chosen_set = set()\n",
    "\n",
    "    for i in range(num_elements):\n",
    "        idx = np.random.randint(0, n)\n",
    "\n",
    "        # Ensure the index is unique and not in the exclude_arr\n",
    "        while idx in chosen_set or idx in exclude_set:\n",
    "            idx = np.random.randint(0, n)\n",
    "\n",
    "        indices[i] = idx\n",
    "        chosen_set.add(idx)\n",
    "\n",
    "    # Return the randomly selected elements, sorted\n",
    "    return np.sort(indices)\n",
    "\n",
    "\n",
    "\n",
    "random_choice(np.random.rand(100), num_elements=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import njit, prange\n",
    "\n",
    "COMMISSION = 0.015\n",
    "SLIPPAGE = 0.00005\n",
    "AVAILABLE_CAPITAL = 700000\n",
    "TRADE_SIZE = 0.5\n",
    "# open_prices = price_data['btc_open']\n",
    "\n",
    "open_prices = np.random.rand(100)\n",
    "\n",
    "buy_idxs = np.array([1, 14, 47, 69, 97])\n",
    "sell_idxs = np.array([7, 31, 55, 81, 99])\n",
    "\n",
    "@njit(cache=True)\n",
    "def get_monkey_entry_results(open_prices, buy_idxs, sell_idxs, COMMISSION, SLIPPAGE, AVAILABLE_CAPITAL, TRADE_SIZE, n_runs=8000):\n",
    "    \n",
    "    pnl_arr = np.zeros(n_runs)\n",
    "    max_dd_arr = np.zeros(n_runs)\n",
    "    \n",
    "    for i in prange(n_runs):\n",
    "        # Generate new buy indexes\n",
    "        new_buy_idxs = get_random_idxs(np.arange(len(open_prices)), num_elements=len(buy_idxs))\n",
    "\n",
    "        # Generate new sell indexes\n",
    "        new_sell_idxs = get_random_idxs(np.arange(len(open_prices)), num_elements=len(sell_idxs), exclude_arr=new_buy_idxs)\n",
    "\n",
    "        # Filter sell indexes to avoid overlaps\n",
    "        buy_idxs = new_buy_idxs\n",
    "        sell_idxs = new_sell_idxs\n",
    "\n",
    "        # Fetch buy and sell prices\n",
    "        buy_prices = open_prices[buy_idxs]\n",
    "        sell_prices = open_prices[sell_idxs]\n",
    "\n",
    "        # Calculate P&L and merge results based on buy/sell sequence\n",
    "        if buy_idxs[0] < sell_idxs[0]:\n",
    "            buy_arr = get_pnl(sell_prices, buy_prices, COMMISSION, SLIPPAGE, AVAILABLE_CAPITAL, TRADE_SIZE, 1)\n",
    "            buy_pnl = np.sum(buy_arr)\n",
    "            sell_arr = get_pnl(buy_prices[1:], sell_prices[:-1], COMMISSION, SLIPPAGE, AVAILABLE_CAPITAL, TRADE_SIZE, 0)\n",
    "            sell_pnl = np.sum(sell_arr)\n",
    "            all_arr = merge_pnl(buy_arr, sell_arr)\n",
    "        else:\n",
    "            sell_arr = get_pnl(buy_prices, sell_prices, COMMISSION, SLIPPAGE, AVAILABLE_CAPITAL, TRADE_SIZE, 0)\n",
    "            sell_pnl = np.sum(sell_arr)\n",
    "            buy_arr = get_pnl(sell_prices[1:], buy_prices[:-1], COMMISSION, SLIPPAGE, AVAILABLE_CAPITAL, TRADE_SIZE, 1)\n",
    "            buy_pnl = np.sum(buy_arr)\n",
    "            all_arr = merge_pnl(sell_arr, buy_arr)\n",
    "\n",
    "        pnl_arr[i] = buy_pnl + sell_pnl\n",
    "        max_dd_arr[i] = get_drawdown(all_arr)\n",
    "    \n",
    "    return pnl_arr, max_dd_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnl_arr, max_dd_arr = get_monkey_entry_results(open_prices, buy_idxs, sell_idxs, COMMISSION, SLIPPAGE, AVAILABLE_CAPITAL, TRADE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  397300.85564778,  -438232.43888039,   713614.96445566, ...,\n",
       "       35751595.27918512,  4360012.42009901,  3924407.90467627])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pnl_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([340.48159655, 105.29302598, 145.87187729, ...,  98.66884267,\n",
       "       119.46601797, 158.60561921])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_dd_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7744"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.where(30 < max_dd_arr, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monkey_random_entry_txt = f'''import os\n",
    "CUR_DIR = os.getcwd()\n",
    "os.chdir('src')\n",
    "#import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from fitness.indicators import numba_indicators\n",
    "from fitness.performance.helper_func import merge_pnl, get_drawdowns, get_pnl, trading_signals, get_lag, get_monkey_entry_results\n",
    "os.chdir(CUR_DIR)\n",
    "#from numba import njit\n",
    "COMMISSION = 0.015\n",
    "SLIPPAGE = 0.00005\n",
    "AVAILABLE_CAPITAL = 700000\n",
    "TRADE_SIZE = 0.5\n",
    "MAX_LAG = 5\n",
    "buy_idxs, sell_idxs = trading_signals(buy_signal={buy_signal_txt}, sell_signal={sell_signal_txt})\n",
    "open_prices = price_data['btc_open']\n",
    "pnl_mren_arr, max_dd_mren_arr = get_monkey_entry_results(open_prices, buy_idxs, sell_idxs, COMMISSION, SLIPPAGE, AVAILABLE_CAPITAL, TRADE_SIZE)\n",
    "gc.collect()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before removing duplicates is (2603141, 3).\n",
      "Shape after removing duplicates is (120892, 3).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(120892, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "path1 = Path(r'C:/\\Users/\\vchar/\\OneDrive/\\Desktop/\\ML Projects/\\Upwork/\\AlgoT_ML_Dev/\\GrammarEvolution/\\PonyGE2/\\results/\\VCh_24_10_17_172107_709806_6984_709806/\\ge_results_dd_inst_ind_comb_numba.csv')\n",
    "path2 = Path(r'C:/\\Users/\\vchar/\\OneDrive/\\Desktop/\\ML Projects/\\Upwork/\\AlgoT_ML_Dev/\\GrammarEvolution/\\PonyGE2/\\derived_strategies/\\ge_results_dd_inst_ind_comb_numba.csv')\n",
    "\n",
    "df1 = pd.read_csv(path1, sep=';')\n",
    "df2 = pd.read_csv(path2)\n",
    "\n",
    "df = pd.concat([df1, df2], axis=0)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f\"Shape before removing duplicates is {df.shape}.\")\n",
    "\n",
    "df = df[~df.duplicated()]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(f\"Shape after removing duplicates is {df.shape}.\")\n",
    "\n",
    "df.to_csv(path2, index=False)\n",
    "\n",
    "df = pd.read_csv(path2)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import njit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(cache=True)\n",
    "def trading_signals_buy(buy_signal, exit_signal):\n",
    "\n",
    "    buy = np.where(buy_signal, 1, 0)\n",
    "    sell = np.where(exit_signal, -1, 0)\n",
    "    signal = buy + sell\n",
    "    buy_idxs = []\n",
    "    sell_idxs = []\n",
    "    is_buy = 0\n",
    "    is_sell = 0\n",
    "\n",
    "    for i in range(len(signal)):\n",
    "        if signal[i] == 1 and is_buy == 0:\n",
    "            buy_idxs.append(i + 1)\n",
    "            is_buy = 1\n",
    "            is_sell = 0\n",
    "        elif signal[i] == -1 and is_sell == 0:\n",
    "            sell_idxs.append(i + 1)\n",
    "            is_sell = 1\n",
    "            is_buy = 0\n",
    "\n",
    "    sell_start_idx = -1\n",
    "    for i in range(len(sell_idxs)):\n",
    "        if sell_idxs[i] < buy_idxs[0]:\n",
    "            sell_start_idx = i\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    if sell_start_idx != -1:\n",
    "        sell_idxs = sell_idxs[sell_start_idx+1:]\n",
    "\n",
    "    if len(buy_idxs) > len(sell_idxs):\n",
    "        buy_idxs = buy_idxs[:-(len(buy_idxs) - len(sell_idxs))]\n",
    "    elif len(buy_idxs) < len(sell_idxs):\n",
    "        sell_idxs = sell_idxs[:-(len(sell_idxs) - len(buy_idxs))]\n",
    "    return buy_idxs, sell_idxs\n",
    "\n",
    "@njit(cache=True)\n",
    "def trading_signals_sell(sell_signal, exit_signal):\n",
    "\n",
    "    buy = np.where(exit_signal, 1, 0)\n",
    "    sell = np.where(sell_signal, -1, 0)\n",
    "    signal = buy + sell\n",
    "    buy_idxs = []\n",
    "    sell_idxs = []\n",
    "    is_buy = 0\n",
    "    is_sell = 0\n",
    "\n",
    "    for i in range(len(signal)):\n",
    "        if signal[i] == 1 and is_buy == 0:\n",
    "            buy_idxs.append(i + 1)\n",
    "            is_buy = 1\n",
    "            is_sell = 0\n",
    "        elif signal[i] == -1 and is_sell == 0:\n",
    "            sell_idxs.append(i + 1)\n",
    "            is_sell = 1\n",
    "            is_buy = 0\n",
    "\n",
    "    buy_start_idx = -1\n",
    "    for i in range(len(buy_idxs)):\n",
    "        if buy_idxs[i] < sell_idxs[0]:\n",
    "            buy_start_idx = i\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    if buy_start_idx != -1:\n",
    "        buy_idxs = buy_idxs[buy_start_idx+1:]\n",
    "\n",
    "    if len(buy_idxs) > len(sell_idxs):\n",
    "        buy_idxs = buy_idxs[:-(len(buy_idxs) - len(sell_idxs))]\n",
    "    elif len(buy_idxs) < len(sell_idxs):\n",
    "        sell_idxs = sell_idxs[:-(len(sell_idxs) - len(buy_idxs))]\n",
    "    return sell_idxs, buy_idxs\n",
    "\n",
    "@njit(cache=True)\n",
    "def change_exit(buy_idxs, buy_exit_idxs, sell_idxs, sell_exit_idxs):\n",
    "\n",
    "    remove_buy_idxs = []\n",
    "    remove_sell_idxs = []\n",
    "\n",
    "    for i in range(len(buy_idxs)):\n",
    "        for j in range(len(sell_idxs)):\n",
    "            if buy_idxs[i] > sell_idxs[j] and buy_idxs[i] < sell_exit_idxs[j]:\n",
    "                sell_exit_idxs[j] = buy_idxs[i]\n",
    "            elif sell_idxs[j] > buy_idxs[i] and sell_idxs[j] < buy_exit_idxs[i]:\n",
    "                buy_exit_idxs[i] = sell_idxs[j]\n",
    "            elif buy_idxs[i] == sell_idxs[j]:\n",
    "                remove_buy_idxs.append(i)\n",
    "                remove_sell_idxs.append(j)\n",
    "\n",
    "    remove_buy_idxs = set(remove_buy_idxs)\n",
    "    remove_sell_idxs = set(remove_sell_idxs)\n",
    "\n",
    "    buy_idxs = np.array([buy_idxs[k] for k in range(len(buy_idxs)) if k not in remove_buy_idxs])\n",
    "    buy_exit_idxs = np.array([buy_exit_idxs[k] for k in range(len(buy_exit_idxs)) if k not in remove_buy_idxs])\n",
    "\n",
    "    sell_idxs = np.array([sell_idxs[k] for k in range(len(sell_idxs)) if k not in remove_sell_idxs])\n",
    "    sell_exit_idxs = np.array([sell_exit_idxs[k] for k in range(len(sell_exit_idxs)) if k not in remove_sell_idxs])\n",
    "\n",
    "    return buy_idxs, buy_exit_idxs, sell_idxs, sell_exit_idxs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_signal = RSI(df=data, HistLength=10).values < 30\n",
    "\n",
    "exit_signal = np.zeros((len(buy_signal), 1))\n",
    "\n",
    "for i in range(len(buy_signal)):\n",
    "    if buy_signal[i] and i + 3 < len(buy_signal):\n",
    "        exit_signal[i+3] = 1\n",
    "\n",
    "buy_idxs, buy_exit_idxs = trading_signals_buy(buy_signal, exit_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70, 90, 204, 252, 279, 317, 383, 389, 430, 465, 478, 525, 553, 608, 639, 695, 728, 738, 772, 885, 917, 939, 1078, 1083, 1123, 1151, 1171, 1195, 1228, 1304, 1340, 1360, 1392, 1439, 1478, 1502, 1507, 1534, 1554, 1566, 1646, 1672, 1797, 1816, 1884, 1896, 1922, 2061, 2069, 2130, 2153, 2181, 2270, 2428, 2451, 2461, 2517, 2521, 2557, 2638, 2765, 2822, 2831, 2880, 2895, 2900, 2970, 2990, 3092, 3114, 3130, 3141, 3152, 3158, 3196, 3281, 3383, 3398, 3467, 3557, 3609, 3700, 3715, 3739, 3754, 3836, 3889, 3941, 3952, 3983, 4088, 4107, 4162, 4171, 4199, 4240, 4278, 4342, 4423, 4432, 4444, 4449, 4490, 4503, 4568, 4582, 4593, 4683, 4696, 4780, 4797, 4811, 4916, 4923, 4935, 4958, 4967, 5005, 5020, 5037, 5127, 5137, 5149, 5169, 5195, 5219, 5238, 5284, 5408, 5414, 5429, 5435, 5527, 5531, 5580, 5667, 5850, 5877, 5957, 5962, 5972, 5991, 6001, 6249, 6300, 6410, 6429, 6464, 6469, 6547, 6570, 6596, 6662, 6666, 6672, 6679, 6712, 6722, 6801, 6828, 6962, 7036, 7099, 7105, 7119, 7192, 7212, 7292, 7334, 7432, 7438, 7451, 7462, 7516, 7581, 7612, 7760, 7776, 7785, 7819, 7835, 7839, 7895, 7907, 7940, 7973, 7983, 8075, 8128, 8135, 8142, 8169, 8181, 8191, 8214, 8234, 8278, 8352, 8357, 8378, 8394, 8436, 8461, 8468, 8473, 8477, 8565, 8618, 8677, 8688, 8751, 8763, 8788, 8803, 8917, 8945, 9075, 9087, 9104, 9152, 9165, 9179, 9186, 9220, 9253, 9302, 9373, 9413, 9483, 9487, 9502, 9513, 9526, 9556, 9584, 9617, 9645, 9695, 9720, 9813, 9871, 9909]\n"
     ]
    }
   ],
   "source": [
    "print(buy_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[76, 104, 217, 273, 282, 322, 386, 421, 444, 469, 488, 538, 557, 611, 642, 705, 735, 745, 796, 894, 930, 963, 1081, 1091, 1126, 1154, 1175, 1198, 1240, 1319, 1344, 1363, 1412, 1442, 1483, 1505, 1525, 1538, 1560, 1569, 1654, 1675, 1803, 1836, 1893, 1911, 1927, 2066, 2085, 2134, 2170, 2186, 2274, 2446, 2458, 2473, 2520, 2543, 2564, 2642, 2768, 2825, 2834, 2885, 2898, 2912, 2977, 2997, 3108, 3119, 3133, 3147, 3155, 3161, 3199, 3284, 3386, 3401, 3480, 3560, 3612, 3703, 3719, 3744, 3774, 3871, 3902, 3949, 3954, 3986, 4099, 4110, 4165, 4177, 4202, 4243, 4282, 4345, 4429, 4433, 4447, 4452, 4496, 4519, 4572, 4589, 4602, 4686, 4699, 4784, 4806, 4814, 4919, 4931, 4942, 4964, 4975, 5015, 5025, 5041, 5131, 5140, 5154, 5183, 5208, 5222, 5258, 5295, 5411, 5417, 5432, 5438, 5530, 5539, 5584, 5670, 5856, 5882, 5960, 5967, 5975, 5997, 6004, 6277, 6307, 6413, 6432, 6467, 6472, 6552, 6573, 6602, 6665, 6669, 6676, 6680, 6716, 6731, 6812, 6831, 6965, 7039, 7102, 7111, 7129, 7204, 7215, 7296, 7337, 7435, 7448, 7457, 7467, 7522, 7590, 7615, 7769, 7782, 7794, 7822, 7838, 7846, 7902, 7919, 7946, 7976, 7986, 8091, 8132, 8138, 8145, 8177, 8184, 8194, 8217, 8237, 8281, 8355, 8360, 8383, 8399, 8439, 8465, 8470, 8474, 8482, 8570, 8624, 8681, 8691, 8760, 8776, 8791, 8806, 8920, 8963, 9078, 9098, 9107, 9158, 9171, 9183, 9189, 9232, 9263, 9307, 9400, 9417, 9486, 9499, 9507, 9516, 9536, 9559, 9587, 9620, 9648, 9698, 9723, 9816, 9877, 9912]\n"
     ]
    }
   ],
   "source": [
    "print(buy_exit_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sell_signal = RSI(df=data, HistLength=10).values > 70\n",
    "sell_signal = PRICE_MOMENTUM(df=data, HistLength=10, StdDevLength=2).values > 45\n",
    "\n",
    "exit_signal = np.zeros((len(sell_signal), 1))\n",
    "\n",
    "for i in range(len(sell_signal)):\n",
    "    if sell_signal[i] and i + 3 < len(sell_signal):\n",
    "        exit_signal[i+3] = 1\n",
    "\n",
    "sell_idxs, sell_exit_idxs = trading_signals_sell(sell_signal, exit_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 28, 53, 65, 77, 98, 107, 113, 123, 128, 140, 148, 153, 176, 181, 188, 195, 203, 207, 215, 221, 231, 239, 248, 258, 271, 280, 284, 297, 304, 312, 321, 327, 338, 348, 353, 355, 357, 362, 367, 375, 380, 386, 393, 399, 411, 422, 435, 446, 451, 458, 464, 468, 481, 485, 491, 500, 512, 518, 528, 541, 550, 558, 572, 578, 584, 594, 600, 612, 622, 632, 645, 655, 663, 674, 691, 698, 704, 714, 721, 727, 738, 744, 751, 760, 775, 779, 786, 794, 799, 806, 811, 831, 835, 842, 852, 860, 878, 886, 890, 901, 909, 920, 925, 929, 942, 957, 969, 975, 981, 989, 996, 1007, 1014, 1018, 1025, 1030, 1037, 1050, 1067, 1090, 1094, 1101, 1112, 1118, 1131, 1138, 1143, 1161, 1168, 1173, 1182, 1188, 1199, 1207, 1215, 1219, 1221, 1231, 1242, 1249, 1259, 1264, 1273, 1277, 1284, 1291, 1300, 1307, 1314, 1324, 1331, 1342, 1346, 1352, 1357, 1361, 1374, 1388, 1394, 1406, 1417, 1424, 1442, 1452, 1466, 1472, 1476, 1481, 1488, 1499, 1505, 1510, 1514, 1528, 1537, 1565, 1572, 1605, 1617, 1621, 1626, 1632, 1641, 1650, 1664, 1671, 1679, 1688, 1698, 1717, 1722, 1733, 1741, 1746, 1750, 1755, 1759, 1768, 1773, 1781, 1789, 1793, 1799, 1811, 1820, 1824, 1835, 1840, 1845, 1850, 1857, 1873, 1877, 1882, 1887, 1899, 1907, 1928, 1938, 1946, 1960, 1969, 1978, 1984, 1989, 1995, 2000, 2006, 2015, 2023, 2036, 2041, 2048, 2074, 2078, 2087, 2093, 2101, 2110, 2121, 2128, 2136, 2141, 2154, 2163, 2176, 2189, 2194, 2208, 2210, 2214, 2223, 2229, 2235, 2240, 2253, 2264, 2273, 2281, 2286, 2297, 2301, 2311, 2321, 2330, 2336, 2345, 2356, 2365, 2377, 2392, 2397, 2405, 2413, 2418, 2424, 2429, 2437, 2447, 2454, 2462, 2470, 2476, 2480, 2484, 2489, 2500, 2515, 2520, 2525, 2536, 2546, 2554, 2561, 2565, 2580, 2601, 2607, 2612, 2620, 2628, 2635, 2640, 2645, 2653, 2660, 2666, 2670, 2678, 2690, 2696, 2705, 2714, 2723, 2731, 2741, 2745, 2757, 2766, 2775, 2790, 2796, 2810, 2819, 2823, 2835, 2849, 2854, 2866, 2874, 2883, 2888, 2892, 2901, 2907, 2915, 2923, 2935, 2941, 2955, 2967, 2972, 2979, 2984, 2993, 3001, 3014, 3019, 3029, 3040, 3050, 3058, 3062, 3068, 3076, 3083, 3091, 3098, 3113, 3121, 3125, 3140, 3156, 3160, 3165, 3175, 3179, 3188, 3202, 3213, 3222, 3233, 3255, 3263, 3270, 3279, 3291, 3297, 3301, 3305, 3326, 3330, 3341, 3350, 3358, 3363, 3368, 3373, 3380, 3385, 3395, 3401, 3411, 3417, 3421, 3428, 3434, 3444, 3451, 3465, 3475, 3483, 3487, 3494, 3505, 3530, 3567, 3596, 3602, 3611, 3615, 3626, 3631, 3640, 3650, 3654, 3664, 3680, 3690, 3694, 3708, 3718, 3728, 3740, 3747, 3756, 3765, 3767, 3777, 3785, 3791, 3795, 3801, 3805, 3814, 3818, 3820, 3822, 3826, 3837, 3842, 3852, 3856, 3861, 3866, 3878, 3880, 3882, 3892, 3903, 3910, 3915, 3923, 3933, 3946, 3954, 3961, 3967, 3981, 3986, 4005, 4010, 4016, 4020, 4028, 4040, 4044, 4051, 4059, 4065, 4076, 4086, 4093, 4101, 4113, 4123, 4129, 4135, 4140, 4144, 4156, 4165, 4172, 4180, 4184, 4190, 4204, 4224, 4236, 4242, 4251, 4264, 4283, 4290, 4295, 4297, 4301, 4306, 4311, 4316, 4325, 4330, 4334, 4344, 4360, 4366, 4377, 4381, 4386, 4396, 4402, 4408, 4416, 4421, 4428, 4436, 4449, 4455, 4468, 4474, 4489, 4494, 4500, 4510, 4520, 4532, 4542, 4552, 4560, 4571, 4578, 4585, 4603, 4614, 4622, 4628, 4644, 4664, 4674, 4680, 4688, 4694, 4706, 4711, 4722, 4734, 4748, 4753, 4763, 4775, 4789, 4800, 4807, 4809, 4813, 4821, 4826, 4845, 4859, 4863, 4873, 4878, 4884, 4900, 4915, 4925, 4930, 4934, 4944, 4957, 4967, 4974, 4980, 4984, 4993, 5007, 5014, 5022, 5027, 5034, 5038, 5042, 5047, 5055, 5065, 5073, 5077, 5093, 5100, 5107, 5109, 5120, 5129, 5133, 5143, 5153, 5164, 5174, 5187, 5198, 5211, 5223, 5241, 5252, 5256, 5270, 5277, 5282, 5291, 5298, 5307, 5311, 5315, 5327, 5338, 5346, 5352, 5359, 5372, 5385, 5421, 5512, 5519, 5532, 5538, 5547, 5555, 5563, 5586, 5596, 5604, 5612, 5617, 5626, 5635, 5640, 5646, 5662, 5692, 5710, 5714, 5725, 5730, 5739, 5749, 5755, 5760, 5771, 5779, 5784, 5790, 5803, 5809, 5816, 5821, 5828, 5836, 5860, 5872, 5880, 5885, 5890, 5896, 5901, 5913, 5924, 5932, 5945, 5955, 5963, 5969, 5974, 5980, 5987, 5997, 6004, 6008, 6015, 6017, 6022, 6038, 6053, 6066, 6073, 6081, 6088, 6097, 6101, 6107, 6117, 6125, 6132, 6155, 6172, 6182, 6216, 6222, 6230, 6244, 6251, 6256, 6262, 6266, 6272, 6282, 6293, 6303, 6315, 6319, 6326, 6332, 6351, 6357, 6363, 6389, 6397, 6401, 6413, 6422, 6430, 6435, 6439, 6454, 6487, 6496, 6514, 6522, 6529, 6538, 6544, 6557, 6565, 6575, 6585, 6589, 6593, 6600, 6608, 6626, 6633, 6640, 6648, 6652, 6659, 6664, 6675, 6686, 6691, 6697, 6709, 6721, 6728, 6734, 6741, 6745, 6751, 6766, 6793, 6799, 6803, 6817, 6851, 6918, 6939, 6950, 6958, 6967, 6973, 6981, 6986, 6992, 6999, 7040, 7044, 7082, 7092, 7172, 7193, 7202, 7209, 7222, 7231, 7247, 7258, 7264, 7268, 7275, 7304, 7325, 7329, 7335, 7343, 7352, 7363, 7380, 7389, 7402, 7424, 7435, 7460, 7470, 7480, 7485, 7496, 7505, 7512, 7517, 7536, 7542, 7549, 7554, 7562, 7564, 7570, 7574, 7576, 7578, 7588, 7601, 7616, 7620, 7626, 7633, 7641, 7647, 7657, 7666, 7673, 7683, 7689, 7696, 7704, 7713, 7719, 7723, 7729, 7738, 7745, 7749, 7757, 7762, 7772, 7779, 7787, 7797, 7804, 7809, 7818, 7825, 7838, 7848, 7852, 7864, 7870, 7879, 7889, 7896, 7900, 7922, 7930, 7952, 7962, 7994, 8001, 8019, 8027, 8032, 8038, 8044, 8051, 8055, 8059, 8064, 8071, 8078, 8083, 8089, 8097, 8106, 8123, 8131, 8138, 8144, 8151, 8157, 8163, 8170, 8180, 8188, 8204, 8225, 8238, 8258, 8272, 8296, 8329, 8344, 8376, 8386, 8397, 8404, 8414, 8428, 8444, 8453, 8463, 8477, 8484, 8492, 8501, 8520, 8527, 8537, 8545, 8551, 8555, 8570, 8576, 8580, 8601, 8611, 8615, 8623, 8627, 8633, 8638, 8649, 8651, 8661, 8668, 8672, 8683, 8693, 8704, 8716, 8734, 8742, 8749, 8759, 8766, 8786, 8800, 8808, 8813, 8825, 8831, 8839, 8849, 8854, 8859, 8878, 8891, 8897, 8905, 8913, 8920, 8928, 8934, 8943, 8951, 8969, 8975, 8981, 8993, 9001, 9006, 9014, 9024, 9036, 9041, 9047, 9054, 9065, 9069, 9077, 9084, 9090, 9102, 9123, 9131, 9143, 9145, 9150, 9157, 9169, 9185, 9193, 9202, 9206, 9211, 9219, 9228, 9234, 9256, 9261, 9270, 9278, 9282, 9288, 9304, 9310, 9315, 9324, 9336, 9344, 9348, 9356, 9364, 9379, 9385, 9390, 9403, 9416, 9422, 9436, 9438, 9446, 9451, 9457, 9464, 9471, 9486, 9518, 9524, 9530, 9542, 9550, 9565, 9595, 9685, 9691, 9702, 9734, 9742, 9746, 9767, 9787, 9817, 9825, 9833, 9838, 9853, 9861, 9866, 9874, 9882, 9888, 9897, 9903, 9910, 9935, 9950, 9957, 9968, 9977, 9984, 10003]\n"
     ]
    }
   ],
   "source": [
    "print(sell_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15, 31, 56, 68, 90, 102, 110, 118, 126, 131, 143, 151, 159, 179, 184, 192, 197, 206, 210, 218, 225, 234, 242, 251, 263, 277, 283, 288, 298, 308, 313, 324, 332, 343, 352, 354, 356, 358, 365, 372, 378, 383, 389, 396, 405, 419, 430, 439, 449, 455, 461, 466, 478, 482, 488, 494, 505, 515, 519, 538, 544, 553, 563, 574, 581, 591, 597, 603, 616, 629, 639, 647, 658, 668, 688, 692, 701, 707, 717, 724, 730, 741, 747, 754, 770, 777, 783, 791, 796, 801, 809, 820, 834, 838, 850, 855, 868, 881, 889, 897, 906, 917, 923, 928, 939, 951, 960, 972, 978, 986, 992, 999, 1010, 1017, 1022, 1027, 1033, 1045, 1053, 1070, 1093, 1097, 1104, 1115, 1121, 1135, 1141, 1146, 1167, 1171, 1176, 1185, 1192, 1206, 1208, 1218, 1220, 1227, 1237, 1245, 1257, 1261, 1267, 1274, 1279, 1288, 1297, 1304, 1308, 1317, 1327, 1339, 1344, 1349, 1355, 1360, 1370, 1381, 1391, 1403, 1414, 1419, 1439, 1449, 1457, 1469, 1474, 1478, 1483, 1491, 1502, 1507, 1513, 1520, 1531, 1540, 1568, 1575, 1608, 1620, 1622, 1629, 1635, 1644, 1653, 1667, 1674, 1682, 1691, 1707, 1720, 1727, 1736, 1744, 1749, 1753, 1758, 1765, 1769, 1778, 1782, 1792, 1796, 1808, 1814, 1823, 1827, 1838, 1843, 1848, 1854, 1870, 1876, 1880, 1884, 1890, 1902, 1920, 1934, 1939, 1950, 1963, 1975, 1981, 1987, 1992, 1999, 2003, 2011, 2018, 2029, 2039, 2047, 2061, 2077, 2083, 2090, 2099, 2104, 2113, 2126, 2130, 2139, 2147, 2157, 2168, 2186, 2192, 2204, 2209, 2211, 2219, 2226, 2232, 2238, 2248, 2261, 2267, 2279, 2283, 2294, 2299, 2303, 2317, 2327, 2333, 2339, 2353, 2359, 2368, 2382, 2395, 2402, 2407, 2416, 2421, 2426, 2433, 2443, 2451, 2459, 2467, 2473, 2477, 2481, 2486, 2497, 2512, 2517, 2522, 2532, 2543, 2551, 2557, 2564, 2577, 2592, 2604, 2610, 2615, 2623, 2631, 2638, 2643, 2650, 2656, 2663, 2669, 2673, 2681, 2693, 2699, 2708, 2717, 2726, 2734, 2744, 2750, 2763, 2769, 2778, 2793, 2802, 2813, 2822, 2829, 2841, 2852, 2857, 2869, 2877, 2886, 2891, 2895, 2904, 2912, 2921, 2928, 2938, 2944, 2964, 2970, 2974, 2982, 2990, 2997, 3007, 3017, 3024, 3032, 3046, 3056, 3061, 3065, 3071, 3079, 3086, 3094, 3101, 3116, 3124, 3128, 3143, 3159, 3163, 3168, 3178, 3185, 3192, 3209, 3219, 3230, 3240, 3260, 3264, 3273, 3281, 3294, 3299, 3303, 3309, 3329, 3333, 3344, 3353, 3361, 3366, 3371, 3376, 3381, 3392, 3398, 3404, 3414, 3420, 3424, 3431, 3438, 3445, 3456, 3471, 3480, 3485, 3490, 3498, 3510, 3533, 3571, 3599, 3605, 3614, 3618, 3629, 3634, 3643, 3653, 3657, 3667, 3683, 3693, 3700, 3714, 3723, 3736, 3741, 3750, 3762, 3766, 3770, 3782, 3788, 3792, 3798, 3804, 3808, 3817, 3819, 3821, 3823, 3834, 3840, 3849, 3853, 3858, 3862, 3871, 3879, 3881, 3889, 3895, 3906, 3913, 3919, 3926, 3937, 3949, 3957, 3964, 3976, 3983, 3990, 4008, 4013, 4019, 4024, 4034, 4043, 4048, 4053, 4062, 4073, 4083, 4089, 4096, 4107, 4120, 4126, 4132, 4138, 4143, 4153, 4162, 4169, 4177, 4183, 4187, 4197, 4207, 4232, 4239, 4245, 4257, 4273, 4287, 4292, 4296, 4298, 4303, 4308, 4313, 4319, 4328, 4332, 4337, 4353, 4361, 4371, 4379, 4384, 4390, 4399, 4405, 4411, 4419, 4423, 4434, 4439, 4452, 4458, 4471, 4480, 4492, 4497, 4503, 4513, 4523, 4538, 4545, 4555, 4568, 4573, 4583, 4593, 4606, 4617, 4625, 4632, 4650, 4670, 4677, 4683, 4691, 4695, 4709, 4714, 4728, 4737, 4751, 4762, 4766, 4781, 4797, 4806, 4808, 4810, 4819, 4823, 4831, 4854, 4862, 4868, 4876, 4881, 4897, 4903, 4920, 4927, 4931, 4935, 4948, 4963, 4973, 4977, 4983, 4990, 4996, 5013, 5020, 5025, 5030, 5037, 5041, 5045, 5050, 5058, 5070, 5074, 5082, 5097, 5104, 5108, 5112, 5126, 5131, 5136, 5148, 5161, 5168, 5182, 5195, 5206, 5218, 5237, 5249, 5255, 5257, 5275, 5280, 5284, 5297, 5301, 5310, 5314, 5318, 5330, 5341, 5349, 5355, 5362, 5381, 5388, 5424, 5515, 5525, 5535, 5541, 5553, 5561, 5567, 5589, 5602, 5607, 5615, 5620, 5629, 5638, 5643, 5655, 5665, 5698, 5713, 5717, 5728, 5733, 5742, 5752, 5758, 5763, 5774, 5782, 5787, 5799, 5806, 5812, 5819, 5824, 5834, 5850, 5864, 5877, 5882, 5887, 5893, 5898, 5904, 5919, 5927, 5942, 5949, 5958, 5966, 5972, 5977, 5983, 5990, 6000, 6007, 6012, 6016, 6020, 6025, 6041, 6056, 6069, 6076, 6084, 6092, 6100, 6104, 6108, 6120, 6131, 6138, 6158, 6175, 6185, 6219, 6225, 6239, 6247, 6254, 6259, 6265, 6269, 6277, 6290, 6297, 6307, 6318, 6322, 6329, 6348, 6354, 6360, 6373, 6392, 6400, 6407, 6416, 6426, 6433, 6437, 6446, 6460, 6490, 6504, 6517, 6528, 6532, 6540, 6547, 6560, 6569, 6580, 6588, 6592, 6596, 6603, 6622, 6629, 6637, 6646, 6651, 6656, 6661, 6667, 6678, 6689, 6694, 6700, 6712, 6724, 6731, 6737, 6744, 6748, 6756, 6775, 6796, 6802, 6806, 6820, 6854, 6921, 6942, 6953, 6964, 6970, 6979, 6984, 6989, 6995, 7002, 7043, 7047, 7085, 7095, 7175, 7196, 7205, 7212, 7228, 7234, 7253, 7261, 7266, 7271, 7290, 7307, 7328, 7332, 7338, 7346, 7355, 7366, 7383, 7392, 7405, 7430, 7438, 7463, 7476, 7481, 7488, 7499, 7508, 7515, 7521, 7539, 7545, 7552, 7559, 7563, 7565, 7573, 7575, 7577, 7581, 7591, 7610, 7619, 7623, 7627, 7638, 7642, 7650, 7663, 7668, 7679, 7686, 7690, 7702, 7707, 7715, 7722, 7724, 7735, 7741, 7748, 7752, 7760, 7769, 7776, 7782, 7790, 7800, 7807, 7815, 7821, 7833, 7840, 7851, 7861, 7867, 7876, 7882, 7893, 7899, 7903, 7925, 7936, 7955, 7968, 7997, 8007, 8023, 8028, 8033, 8041, 8048, 8054, 8058, 8063, 8067, 8075, 8081, 8086, 8090, 8101, 8109, 8128, 8132, 8141, 8147, 8154, 8160, 8167, 8177, 8186, 8191, 8207, 8229, 8241, 8261, 8275, 8299, 8332, 8347, 8382, 8389, 8400, 8411, 8417, 8432, 8447, 8459, 8466, 8480, 8489, 8493, 8504, 8523, 8533, 8543, 8548, 8554, 8558, 8573, 8579, 8583, 8604, 8614, 8618, 8626, 8630, 8636, 8643, 8650, 8655, 8664, 8671, 8675, 8687, 8697, 8707, 8730, 8739, 8748, 8752, 8762, 8772, 8789, 8803, 8811, 8816, 8828, 8837, 8842, 8852, 8857, 8862, 8883, 8894, 8900, 8908, 8916, 8924, 8931, 8938, 8946, 8954, 8972, 8978, 8985, 8997, 9004, 9010, 9020, 9033, 9038, 9044, 9050, 9057, 9067, 9074, 9081, 9086, 9091, 9105, 9126, 9136, 9144, 9146, 9154, 9163, 9175, 9188, 9196, 9205, 9209, 9213, 9225, 9230, 9253, 9258, 9263, 9276, 9281, 9285, 9300, 9307, 9312, 9321, 9327, 9342, 9347, 9353, 9360, 9370, 9382, 9388, 9393, 9409, 9419, 9427, 9437, 9444, 9449, 9454, 9460, 9467, 9483, 9489, 9521, 9526, 9533, 9545, 9553, 9568, 9598, 9688, 9694, 9705, 9737, 9745, 9749, 9770, 9790, 9820, 9828, 9836, 9844, 9856, 9864, 9869, 9877, 9885, 9891, 9900, 9906, 9913, 9940, 9953, 9960, 9971, 9983, 9990, 10006]\n"
     ]
    }
   ],
   "source": [
    "print(sell_exit_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_idxs, buy_exit_idxs, sell_idxs, sell_exit_idxs = change_exit(buy_idxs, buy_exit_idxs, sell_idxs, sell_exit_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  70   90  204  252  279  317  383  389  430  465  478  525  553  608\n",
      "  639  695  728  772  885  917  939 1078 1083 1123 1151 1171 1195 1228\n",
      " 1304 1340 1360 1392 1439 1478 1502 1507 1534 1554 1566 1646 1672 1797\n",
      " 1816 1884 1896 1922 2061 2069 2130 2153 2181 2270 2428 2451 2461 2517\n",
      " 2521 2557 2638 2765 2822 2831 2880 2895 2900 2970 2990 3092 3114 3130\n",
      " 3141 3152 3158 3196 3281 3383 3398 3467 3557 3609 3700 3715 3739 3754\n",
      " 3836 3889 3941 3952 3983 4088 4107 4162 4171 4199 4240 4278 4342 4423\n",
      " 4432 4444 4490 4503 4568 4582 4593 4683 4696 4780 4797 4811 4916 4923\n",
      " 4935 4958 5005 5020 5037 5127 5137 5149 5169 5195 5219 5238 5284 5408\n",
      " 5414 5429 5435 5527 5531 5580 5667 5850 5877 5957 5962 5972 5991 6001\n",
      " 6249 6300 6410 6429 6464 6469 6547 6570 6596 6662 6666 6672 6679 6712\n",
      " 6722 6801 6828 6962 7036 7099 7105 7119 7192 7212 7292 7334 7432 7438\n",
      " 7451 7462 7516 7581 7612 7760 7776 7785 7819 7835 7839 7895 7907 7940\n",
      " 7973 7983 8075 8128 8135 8142 8169 8181 8191 8214 8234 8278 8352 8357\n",
      " 8378 8394 8436 8461 8468 8473 8565 8618 8677 8688 8751 8763 8788 8803\n",
      " 8917 8945 9075 9087 9104 9152 9165 9179 9186 9220 9253 9302 9373 9413\n",
      " 9483 9487 9502 9513 9526 9556 9584 9617 9645 9695 9720 9813 9871 9909]\n",
      "[  76   98  207  258  280  321  386  393  435  468  481  528  557  611\n",
      "  642  698  735  775  886  920  942 1081 1090 1126 1154 1173 1198 1231\n",
      " 1307 1342 1361 1394 1442 1481 1505 1510 1537 1560 1569 1650 1675 1799\n",
      " 1820 1887 1899 1927 2066 2074 2134 2154 2186 2273 2429 2454 2462 2520\n",
      " 2525 2561 2640 2766 2823 2834 2883 2898 2901 2972 2993 3098 3119 3133\n",
      " 3147 3155 3160 3199 3284 3385 3401 3475 3560 3611 3703 3718 3740 3756\n",
      " 3837 3892 3946 3954 3986 4093 4110 4165 4172 4202 4242 4282 4344 4428\n",
      " 4433 4447 4494 4510 4571 4585 4602 4686 4699 4784 4800 4813 4919 4925\n",
      " 4942 4964 5007 5022 5038 5129 5140 5153 5174 5198 5222 5241 5291 5411\n",
      " 5417 5432 5438 5530 5532 5584 5670 5856 5880 5960 5963 5974 5997 6004\n",
      " 6251 6303 6413 6430 6467 6472 6552 6573 6600 6664 6669 6675 6680 6716\n",
      " 6728 6803 6831 6965 7039 7102 7111 7129 7193 7215 7296 7335 7435 7448\n",
      " 7457 7467 7517 7588 7615 7762 7779 7787 7822 7838 7846 7896 7919 7946\n",
      " 7976 7986 8078 8131 8138 8144 8170 8184 8194 8217 8237 8281 8355 8360\n",
      " 8383 8397 8439 8463 8470 8474 8570 8623 8681 8691 8759 8766 8791 8806\n",
      " 8920 8951 9077 9090 9107 9157 9169 9183 9189 9228 9256 9304 9379 9416\n",
      " 9486 9499 9507 9516 9530 9559 9587 9620 9648 9698 9723 9816 9874 9910]\n"
     ]
    }
   ],
   "source": [
    "print(buy_idxs)\n",
    "print(buy_exit_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   11    28    53 ...  9977  9984 10003]\n",
      "[   15    31    56 ...  9983  9990 10006]\n"
     ]
    }
   ],
   "source": [
    "print(sell_idxs)\n",
    "print(sell_exit_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(cache=True)\n",
    "def get_pnl(trade_close_prices, trade_open_prices, commission, slippage, init_inv, trade_size, is_buy):\n",
    "\n",
    "    pnl_list = np.zeros(len(trade_close_prices))\n",
    "\n",
    "    for i in range(len(trade_close_prices)):\n",
    "\n",
    "        temp_n_assets = int(init_inv * trade_size / trade_open_prices[i])\n",
    "\n",
    "        if is_buy == 1:\n",
    "            temp_pnl = temp_n_assets * (trade_close_prices[i] - trade_open_prices[i] * (1 + slippage))\n",
    "        else:\n",
    "            temp_pnl = -temp_n_assets * (trade_close_prices[i] - trade_open_prices[i] * (1 - slippage))\n",
    "\n",
    "        temp_pnl = temp_pnl * (1 - commission)\n",
    "        init_inv += temp_pnl\n",
    "        pnl_list[i] = temp_pnl\n",
    "\n",
    "    return pnl_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(cache=True)\n",
    "def merge_buy_sell_pnl(buy_idxs, sell_idxs, buy_arr, sell_arr):\n",
    "    # Determine the size of the merged array\n",
    "    total_size = len(buy_idxs) + len(sell_idxs)\n",
    "    merged_arr = np.empty(total_size, dtype=buy_arr.dtype)\n",
    "\n",
    "    # Indices for buy, sell, and merged arrays\n",
    "    i, j, k = 0, 0, 0\n",
    "\n",
    "    # Merge by comparing indices\n",
    "    while i < len(buy_idxs) and j < len(sell_idxs):\n",
    "        if buy_idxs[i] < sell_idxs[j]:\n",
    "            merged_arr[k] = buy_arr[i]\n",
    "            i += 1\n",
    "        else:\n",
    "            merged_arr[k] = sell_arr[j]\n",
    "            j += 1\n",
    "        k += 1\n",
    "\n",
    "    # If there are remaining elements in buy_arr\n",
    "    while i < len(buy_idxs):\n",
    "        merged_arr[k] = buy_arr[i]\n",
    "        i += 1\n",
    "        k += 1\n",
    "\n",
    "    # If there are remaining elements in sell_arr\n",
    "    while j < len(sell_idxs):\n",
    "        merged_arr[k] = sell_arr[j]\n",
    "        j += 1\n",
    "        k += 1\n",
    "\n",
    "    return merged_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMMISSION = 0.015\n",
    "SLIPPAGE = 0.00005\n",
    "AVAILABLE_CAPITAL = 700000\n",
    "TRADE_SIZE = 0.5\n",
    "\n",
    "open_prices = df[\"open\"].values\n",
    "\n",
    "buy_prices = open_prices[np.isin(np.arange(len(open_prices)), buy_idxs)]\n",
    "buy_exit_prices = open_prices[np.isin(np.arange(len(open_prices)), buy_exit_idxs)]\n",
    "\n",
    "sell_prices = open_prices[np.isin(np.arange(len(open_prices)), sell_idxs)]\n",
    "sell_exit_prices = open_prices[np.isin(np.arange(len(open_prices)), sell_exit_idxs)]\n",
    "\n",
    "\n",
    "buy_arr = get_pnl(buy_exit_prices, buy_prices, COMMISSION, SLIPPAGE, AVAILABLE_CAPITAL, TRADE_SIZE, 1)\n",
    "buy_pnl = np.sum(buy_arr)\n",
    "sell_arr = get_pnl(sell_exit_prices, sell_prices, COMMISSION, SLIPPAGE, AVAILABLE_CAPITAL, TRADE_SIZE, 0)\n",
    "sell_pnl = np.sum(sell_arr)\n",
    "all_arr = merge_buy_sell_pnl(buy_idxs, sell_idxs, buy_arr, sell_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-23667.60009892901"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_pnl = buy_pnl + sell_pnl\n",
    "total_pnl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "equity_curve_arr = np.cumsum(all_arr)\n",
    "plt.plot(equity_curve_arr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import njit\n",
    "\n",
    "@njit(cache=True)\n",
    "def moving_percentile(arr, window, percentile):\n",
    "    # Initialize the result array with NaNs (or you can use 999 for insufficient data if needed)\n",
    "    result = np.full(len(arr), np.nan, dtype=arr.dtype)\n",
    "    \n",
    "    for i in range(len(arr)):\n",
    "        if i + 1 >= window:\n",
    "            # Calculate percentile for the current window\n",
    "            window_values = arr[i + 1 - window:i + 1]\n",
    "            result[i] = np.percentile(window_values, percentile * 100)\n",
    "        else:\n",
    "            result[i] = 999  # Not enough data to calculate the percentile\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 999,  999,  999,  999,  999,  999,  999,  999,  999,  999,  999,\n",
       "        999,  999,  258,  288,  333,  384,  399,  438,  468,  489,  532,\n",
       "        566,  615,  653,  703,  739,  800,  893,  922,  973, 1079, 1093,\n",
       "       1130, 1156, 1177, 1203, 1247, 1313, 1345, 1368, 1403, 1448, 1484,\n",
       "       1503, 1513, 1539, 1557, 1586, 1652, 1703, 1801, 1833, 1887, 1902,\n",
       "       1956, 2063, 2084, 2135, 2160, 2203, 2309, 2433, 2453, 2475, 2518,\n",
       "       2530, 2577, 2669, 2779, 2824, 2843, 2883, 2896, 2917, 2975, 3015,\n",
       "       3097, 3118, 3132, 3143, 3153, 3167, 3217, 3306, 3386, 3415, 3489,\n",
       "       3570, 3631, 3703, 3721, 3742, 3774, 3849, 3902, 3943, 3959, 4009,\n",
       "       4092, 4120, 4164, 4178, 4209, 4249, 4294, 4362, 4425, 4435, 4455,\n",
       "       4493, 4519, 4571, 4584, 4615, 4686, 4717, 4784, 4800, 4837, 4917,\n",
       "       4926, 4940, 4969, 5008, 5024, 5059, 5129, 5140, 5154, 5175, 5201,\n",
       "       5223, 5249, 5315, 5409, 5417, 5430, 5458, 5528, 5543, 5601, 5712,\n",
       "       5856, 5897, 5958, 5964, 5976, 5993, 6063, 6261, 6327, 6414, 6437,\n",
       "       6465, 6488, 6552, 6576, 6612, 6663, 6667, 6673, 6687, 6714, 6741,\n",
       "       6807, 6861, 6980, 7051, 7100, 7108, 7137, 7197, 7232, 7302, 7358,\n",
       "       7433, 7441, 7453, 7475, 7532, 7588, 7649, 7764, 7778, 7793, 7823,\n",
       "       7836, 7853, 7898, 7915, 7948, 7975, 8006, 8088, 8129, 8136, 8148,\n",
       "       8172, 8183, 8196, 8219, 8245, 8296, 8353, 8362, 8382, 8404, 8442,\n",
       "       8462, 8469, 8496, 8578, 8632, 8679, 8703, 8754, 8769, 8791, 8831,\n",
       "       8924, 8977, 9078, 9091, 9116, 9155, 9168, 9180, 9194, 9228, 9265,\n",
       "       9319, 9383, 9430, 9484, 9490, 9504, 9516], dtype=int64)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moving_percentile(arr=buy_idxs, window=14, percentile=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging all data revised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>btc_open</th>\n",
       "      <th>btc_high</th>\n",
       "      <th>btc_low</th>\n",
       "      <th>btc_close</th>\n",
       "      <th>btc_volume</th>\n",
       "      <th>6e_open</th>\n",
       "      <th>6e_high</th>\n",
       "      <th>6e_low</th>\n",
       "      <th>6e_close</th>\n",
       "      <th>...</th>\n",
       "      <th>zf_open</th>\n",
       "      <th>zf_high</th>\n",
       "      <th>zf_low</th>\n",
       "      <th>zf_close</th>\n",
       "      <th>zf_volume</th>\n",
       "      <th>zn_open</th>\n",
       "      <th>zn_high</th>\n",
       "      <th>zn_low</th>\n",
       "      <th>zn_close</th>\n",
       "      <th>zn_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-11-01 18:14:00</td>\n",
       "      <td>34553.59</td>\n",
       "      <td>34565.88</td>\n",
       "      <td>34546.16</td>\n",
       "      <td>34549.35</td>\n",
       "      <td>6.687855</td>\n",
       "      <td>1.0557</td>\n",
       "      <td>1.05570</td>\n",
       "      <td>1.05515</td>\n",
       "      <td>1.05520</td>\n",
       "      <td>...</td>\n",
       "      <td>104.867188</td>\n",
       "      <td>104.867188</td>\n",
       "      <td>104.843750</td>\n",
       "      <td>104.843750</td>\n",
       "      <td>1640.0</td>\n",
       "      <td>106.750000</td>\n",
       "      <td>106.765625</td>\n",
       "      <td>106.703125</td>\n",
       "      <td>106.703125</td>\n",
       "      <td>2238.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-11-01 18:15:00</td>\n",
       "      <td>34549.33</td>\n",
       "      <td>34552.58</td>\n",
       "      <td>34507.30</td>\n",
       "      <td>34507.39</td>\n",
       "      <td>14.284419</td>\n",
       "      <td>1.0552</td>\n",
       "      <td>1.05530</td>\n",
       "      <td>1.05465</td>\n",
       "      <td>1.05465</td>\n",
       "      <td>...</td>\n",
       "      <td>104.843750</td>\n",
       "      <td>104.851562</td>\n",
       "      <td>104.828125</td>\n",
       "      <td>104.835938</td>\n",
       "      <td>6235.0</td>\n",
       "      <td>106.718750</td>\n",
       "      <td>106.734375</td>\n",
       "      <td>106.703125</td>\n",
       "      <td>106.703125</td>\n",
       "      <td>4672.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-11-01 18:16:00</td>\n",
       "      <td>34507.49</td>\n",
       "      <td>34525.83</td>\n",
       "      <td>34486.81</td>\n",
       "      <td>34522.14</td>\n",
       "      <td>7.825300</td>\n",
       "      <td>1.0546</td>\n",
       "      <td>1.05505</td>\n",
       "      <td>1.05445</td>\n",
       "      <td>1.05505</td>\n",
       "      <td>...</td>\n",
       "      <td>104.835938</td>\n",
       "      <td>104.859375</td>\n",
       "      <td>104.835938</td>\n",
       "      <td>104.851562</td>\n",
       "      <td>2477.0</td>\n",
       "      <td>106.703125</td>\n",
       "      <td>106.734375</td>\n",
       "      <td>106.687500</td>\n",
       "      <td>106.734375</td>\n",
       "      <td>2382.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-11-01 18:17:00</td>\n",
       "      <td>34522.14</td>\n",
       "      <td>34530.14</td>\n",
       "      <td>34500.18</td>\n",
       "      <td>34526.96</td>\n",
       "      <td>7.512638</td>\n",
       "      <td>1.0550</td>\n",
       "      <td>1.05525</td>\n",
       "      <td>1.05490</td>\n",
       "      <td>1.05515</td>\n",
       "      <td>...</td>\n",
       "      <td>104.851562</td>\n",
       "      <td>104.867188</td>\n",
       "      <td>104.843750</td>\n",
       "      <td>104.851562</td>\n",
       "      <td>3767.0</td>\n",
       "      <td>106.734375</td>\n",
       "      <td>106.750000</td>\n",
       "      <td>106.734375</td>\n",
       "      <td>106.750000</td>\n",
       "      <td>2937.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-11-01 18:18:00</td>\n",
       "      <td>34526.20</td>\n",
       "      <td>34545.63</td>\n",
       "      <td>34525.18</td>\n",
       "      <td>34540.48</td>\n",
       "      <td>13.100650</td>\n",
       "      <td>1.0551</td>\n",
       "      <td>1.05535</td>\n",
       "      <td>1.05510</td>\n",
       "      <td>1.05530</td>\n",
       "      <td>...</td>\n",
       "      <td>104.851562</td>\n",
       "      <td>104.859375</td>\n",
       "      <td>104.851562</td>\n",
       "      <td>104.851562</td>\n",
       "      <td>1634.0</td>\n",
       "      <td>106.734375</td>\n",
       "      <td>106.750000</td>\n",
       "      <td>106.734375</td>\n",
       "      <td>106.734375</td>\n",
       "      <td>962.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime  btc_open  btc_high   btc_low  btc_close  btc_volume  \\\n",
       "0 2023-11-01 18:14:00  34553.59  34565.88  34546.16   34549.35    6.687855   \n",
       "1 2023-11-01 18:15:00  34549.33  34552.58  34507.30   34507.39   14.284419   \n",
       "2 2023-11-01 18:16:00  34507.49  34525.83  34486.81   34522.14    7.825300   \n",
       "3 2023-11-01 18:17:00  34522.14  34530.14  34500.18   34526.96    7.512638   \n",
       "4 2023-11-01 18:18:00  34526.20  34545.63  34525.18   34540.48   13.100650   \n",
       "\n",
       "   6e_open  6e_high   6e_low  6e_close  ...     zf_open     zf_high  \\\n",
       "0   1.0557  1.05570  1.05515   1.05520  ...  104.867188  104.867188   \n",
       "1   1.0552  1.05530  1.05465   1.05465  ...  104.843750  104.851562   \n",
       "2   1.0546  1.05505  1.05445   1.05505  ...  104.835938  104.859375   \n",
       "3   1.0550  1.05525  1.05490   1.05515  ...  104.851562  104.867188   \n",
       "4   1.0551  1.05535  1.05510   1.05530  ...  104.851562  104.859375   \n",
       "\n",
       "       zf_low    zf_close  zf_volume     zn_open     zn_high      zn_low  \\\n",
       "0  104.843750  104.843750     1640.0  106.750000  106.765625  106.703125   \n",
       "1  104.828125  104.835938     6235.0  106.718750  106.734375  106.703125   \n",
       "2  104.835938  104.851562     2477.0  106.703125  106.734375  106.687500   \n",
       "3  104.843750  104.851562     3767.0  106.734375  106.750000  106.734375   \n",
       "4  104.851562  104.851562     1634.0  106.734375  106.750000  106.734375   \n",
       "\n",
       "     zn_close  zn_volume  \n",
       "0  106.703125     2238.0  \n",
       "1  106.703125     4672.0  \n",
       "2  106.734375     2382.0  \n",
       "3  106.750000     2937.0  \n",
       "4  106.734375      962.0  \n",
       "\n",
       "[5 rows x 131 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# df = pd.read_csv(Path(r'C:/\\Users/\\vchar/\\OneDrive/\\Desktop/\\ML Projects/\\Upwork/\\AlgoT_ML_Dev/\\GrammarEvolution/\\PonyGE2/\\datasets/\\all_data_1min.csv'))\n",
    "df = pd.read_csv(Path(r'/\\Users/\\vchar/\\OneDrive/\\Desktop/\\ML Projects/\\Upwork/\\AlgoT_ML_Dev/\\GrammarEvolution/\\PonyGE2/\\all_data_1min.csv'))\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "df.sort_values('datetime', ascending=True, inplace=True)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "instrument_list = [col.split('_')[0] for col in df.columns if col.endswith('_open')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(457520, 131)\n",
      "(414836, 1326)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['btc_open', 'btc_high', 'btc_low', 'btc_close', 'btc_volume', '6e_open',\n",
       "       '6e_high', '6e_low', '6e_close', '6e_volume',\n",
       "       ...\n",
       "       'zn_high_1w_ago', 'zn_low_1w_ago', 'zn_open_1w_ago', 'zn_close_1w_ago',\n",
       "       'zn_volume_1w_ago', 'zn_high_1m_ago', 'zn_low_1m_ago', 'zn_open_1m_ago',\n",
       "       'zn_close_1m_ago', 'zn_volume_1m_ago'],\n",
       "      dtype='object', length=1326)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import timedelta, datetime\n",
    "\n",
    "print(df.shape)\n",
    "df.set_index('datetime', inplace=True)\n",
    "\n",
    "# Grouping by date\n",
    "df['date'] = df.index.date\n",
    "grouped = df.groupby('date')\n",
    "\n",
    "df['weekend_date'] = df.index\n",
    "df['weekend_date'] = df['weekend_date'].apply(lambda x: (x + timedelta(days=6 - x.weekday())).date())\n",
    "\n",
    "df['month_date'] = df.index\n",
    "df['month_date'] = df['month_date'].apply(\n",
    "    lambda x: (\n",
    "        datetime(x.year + int(x.month % 12 == 0), x.month % 12 + 1, 1) - timedelta(days=1)\n",
    "    ).date()\n",
    ")\n",
    "\n",
    "for instrument in instrument_list:\n",
    "\n",
    "    daily_data = df.resample('1D').agg({\n",
    "        f'{instrument}_open': 'first',\n",
    "        f'{instrument}_high': 'max',\n",
    "        f'{instrument}_low': 'min',\n",
    "        f'{instrument}_close': 'last',\n",
    "        f'{instrument}_volume': 'sum'\n",
    "    })\n",
    "\n",
    "    weekly_data = df.resample('W').agg({\n",
    "        f'{instrument}_open': 'first',\n",
    "        f'{instrument}_high': 'max',\n",
    "        f'{instrument}_low': 'min',\n",
    "        f'{instrument}_close': 'last',\n",
    "        f'{instrument}_volume': 'sum'\n",
    "    })\n",
    "\n",
    "    monthly_data = df.resample('ME').agg({\n",
    "        f'{instrument}_open': 'first',\n",
    "        f'{instrument}_high': 'max',\n",
    "        f'{instrument}_low': 'min',\n",
    "        f'{instrument}_close': 'last',\n",
    "        f'{instrument}_volume': 'sum'\n",
    "    })\n",
    "\n",
    "    df[f'{instrument}_mean'] = (df[f'{instrument}_close'] + df[f'{instrument}_low'] + df[f'{instrument}_high'] + df[f'{instrument}_open']) / 4\n",
    "\n",
    "    df[f'{instrument}_rmean_day'] = grouped[f'{instrument}_close'].transform(lambda x: x.shift(1).rolling(window=len(x), min_periods=1).mean())\n",
    "    df[f'{instrument}_rhigh_day'] = grouped[f'{instrument}_high'].transform(lambda x: x.shift(1).rolling(window=len(x), min_periods=1).max())\n",
    "    df[f'{instrument}_rlow_day'] = grouped[f'{instrument}_low'].transform(lambda x: x.shift(1).rolling(window=len(x), min_periods=1).min())\n",
    "    df[f'{instrument}_rstd_day'] = grouped[f'{instrument}_close'].transform(lambda x: x.shift(1).rolling(window=len(x), min_periods=1).std())\n",
    "    df[f'{instrument}_rvolume_day'] = grouped[f'{instrument}_volume'].transform(lambda x: x.shift(1).rolling(window=len(x), min_periods=1).sum())\n",
    "\n",
    "    df[f'{instrument}_rmean_2h'] = df[f'{instrument}_close'].shift(1).rolling(window=120, min_periods=1).mean()\n",
    "    df[f'{instrument}_rmax_2h'] = df[f'{instrument}_high'].shift(1).rolling(window=120, min_periods=1).max()\n",
    "    df[f'{instrument}_rmin_2h'] = df[f'{instrument}_low'].shift(1).rolling(window=120, min_periods=1).min()\n",
    "    df[f'{instrument}_rstd_2h'] = df[f'{instrument}_close'].shift(1).rolling(window=120, min_periods=1).std()\n",
    "    df[f'{instrument}_rvolume_2h'] = df[f'{instrument}_volume'].shift(1).rolling(window=120, min_periods=1).sum()\n",
    "\n",
    "    df[f'{instrument}_rmean_4h'] = df[f'{instrument}_close'].shift(1).rolling(window=240, min_periods=1).mean()\n",
    "    df[f'{instrument}_rmax_4h'] = df[f'{instrument}_high'].shift(1).rolling(window=240, min_periods=1).max()\n",
    "    df[f'{instrument}_rmin_4h'] = df[f'{instrument}_low'].shift(1).rolling(window=240, min_periods=1).min()\n",
    "    df[f'{instrument}_rstd_4h'] = df[f'{instrument}_close'].shift(1).rolling(window=240, min_periods=1).std()\n",
    "    df[f'{instrument}_rvolume_4h'] = df[f'{instrument}_volume'].shift(1).rolling(window=240, min_periods=1).sum()\n",
    "\n",
    "    df[f'{instrument}_rmean_1h'] = df[f'{instrument}_close'].shift(1).rolling(window=60, min_periods=1).mean()\n",
    "    df[f'{instrument}_rmax_1h'] = df[f'{instrument}_high'].shift(1).rolling(window=60, min_periods=1).max()\n",
    "    df[f'{instrument}_rmin_1h'] = df[f'{instrument}_low'].shift(1).rolling(window=60, min_periods=1).min()\n",
    "    df[f'{instrument}_rstd_1h'] = df[f'{instrument}_close'].shift(1).rolling(window=60, min_periods=1).std()\n",
    "    df[f'{instrument}_rvolume_1h'] = df[f'{instrument}_volume'].shift(1).rolling(window=60, min_periods=1).sum()\n",
    "    \n",
    "    daily_cols = []\n",
    "    weekly_cols = []\n",
    "    monthly_cols = []\n",
    "\n",
    "    for col in ['high', 'low', 'open', 'close', 'volume']:\n",
    "\n",
    "        for n_lag in [1, 3, 5]:\n",
    "            daily_data[f'{instrument}_{col}_{n_lag}d_ago'] = daily_data[f'{instrument}_{col}'].shift(n_lag)\n",
    "            daily_cols.append(f'{instrument}_{col}_{n_lag}d_ago')\n",
    "\n",
    "        weekly_data[f'{instrument}_{col}_1w_ago'] = weekly_data[f'{instrument}_{col}'].shift(1)\n",
    "        weekly_cols.append(f'{instrument}_{col}_1w_ago')\n",
    "\n",
    "        monthly_data[f'{instrument}_{col}_1m_ago'] = monthly_data[f'{instrument}_{col}'].shift(1)\n",
    "        monthly_cols.append(f'{instrument}_{col}_1m_ago')\n",
    "\n",
    "    daily_data = daily_data[daily_cols].reset_index()\n",
    "    weekly_data = weekly_data[weekly_cols].reset_index()\n",
    "    monthly_data = monthly_data[monthly_cols].reset_index()\n",
    "\n",
    "    daily_map_dict = daily_data.set_index('datetime').to_dict()\n",
    "    for k in daily_map_dict.keys():\n",
    "        df[k] = df['date'].map(daily_map_dict[k])\n",
    "\n",
    "    weekly_map_dict = weekly_data.set_index('datetime').to_dict()\n",
    "    for k in weekly_map_dict.keys():\n",
    "        df[k] = df['weekend_date'].map(weekly_map_dict[k])\n",
    "\n",
    "    monthly_map_dict = monthly_data.set_index('datetime').to_dict()\n",
    "    for k in monthly_map_dict.keys():\n",
    "        df[k] = df['month_date'].map(monthly_map_dict[k])\n",
    "\n",
    "df.drop(columns=['date', 'weekend_date', 'month_date'], inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(inplace=True)\n",
    "print(df.shape)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"all_data_1min.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating folds for 1 min data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "df = pd.read_csv(Path(r'C:/\\Users/\\vchar/\\OneDrive/\\Desktop/\\ML Projects/\\Upwork/\\AlgoT_ML_Dev/\\GrammarEvolution/\\PonyGE2/\\all_data_1min_all.csv'))\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "df.sort_values('datetime', ascending=True, inplace=True)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "df['week'] = df['datetime'].dt.isocalendar().week\n",
    "df['year'] = df['datetime'].dt.year\n",
    "df['year_week_id'] = df['year'].apply(str) + '_' + df['week'].apply(str)\n",
    "\n",
    "year_week_list = list(df['year_week_id'].unique())\n",
    "fold_id_list = [year_week_list[i:i+5] for i in range(0, len(year_week_list), 5) if len(year_week_list[i:i+5]) == 5]\n",
    "\n",
    "for i in range(len(fold_id_list)):\n",
    "\n",
    "    temp_df = df[df['year_week_id'].isin(fold_id_list[i])].copy()\n",
    "    temp_df.sort_values('datetime', ascending=True, inplace=True)\n",
    "    temp_df.reset_index(drop=True, inplace=True)\n",
    "    temp_df.drop(columns=['week', 'year', 'year_week_id'], inplace=True)\n",
    "    \n",
    "    if not os.path.exists('data_folds_1min'):\n",
    "        os.mkdir('data_folds_1min')\n",
    "\n",
    "    temp_df.to_csv(f'data_folds_1min/data_fold{i+1}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing the timeframes of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6E_1m_databento_symbol_final_1min.csv',\n",
       " 'AAPL_1m_databento.csv',\n",
       " 'AAV-1m-1000wks-data.csv',\n",
       " 'AMZN_1m_databento.csv',\n",
       " 'BTC-1m-1000wks-data.csv',\n",
       " 'CL_1m_databento_symbol_final_1min.csv',\n",
       " 'COIN_1m_databento.csv',\n",
       " 'DOG-1m-1000wks-data.csv',\n",
       " 'ES_1m_databento_symbol_final_1min.csv',\n",
       " 'ETH-1m-1000wks-data.csv_backup.csv',\n",
       " 'FET-1m-1000wks-data.csv_backup.csv',\n",
       " 'GC_1m_databento_symbol_final_1min.csv',\n",
       " 'GOOGL_1m_databento.csv',\n",
       " 'INJ-1m-1000wks-data.csv',\n",
       " 'LIN-1m-1000wks-data.csv_backup.csv',\n",
       " 'META_1m_databento.csv',\n",
       " 'MSFT_1m_databento.csv',\n",
       " 'NG_1m_databento_symbol_final_1min.csv',\n",
       " 'NQ_1m_databento_symbol_final_1min.csv',\n",
       " 'NVDA_1m_databento.csv',\n",
       " 'PLTR_1m_databento.csv',\n",
       " 'SOL-1m-1000wks-data.csv_backup.csv',\n",
       " 'SUI-1m-1000wks-data.csv',\n",
       " 'TIA-1m-1000wks-data.csv',\n",
       " 'TSLA_1m_databento.csv',\n",
       " 'XRP-1m-1000wks-data.csv',\n",
       " 'ZF_1m_databento_symbol_final_1min.csv',\n",
       " 'ZN_1m_databento_symbol_final_1min.csv']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_path = Path(r'C:/\\Users/\\vchar/\\Downloads/\\FULL DATA LIBRARY')\n",
    "\n",
    "files_list = os.listdir(main_path)\n",
    "files_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>btc_open</th>\n",
       "      <th>btc_high</th>\n",
       "      <th>btc_low</th>\n",
       "      <th>btc_close</th>\n",
       "      <th>btc_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-07-20 21:35:00</td>\n",
       "      <td>277.98</td>\n",
       "      <td>277.99</td>\n",
       "      <td>277.97</td>\n",
       "      <td>277.97</td>\n",
       "      <td>1.501500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-07-20 21:40:00</td>\n",
       "      <td>277.98</td>\n",
       "      <td>278.00</td>\n",
       "      <td>277.98</td>\n",
       "      <td>277.99</td>\n",
       "      <td>17.756475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-07-20 21:45:00</td>\n",
       "      <td>278.00</td>\n",
       "      <td>278.00</td>\n",
       "      <td>277.98</td>\n",
       "      <td>277.99</td>\n",
       "      <td>13.655500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-07-20 21:50:00</td>\n",
       "      <td>277.98</td>\n",
       "      <td>278.00</td>\n",
       "      <td>277.92</td>\n",
       "      <td>277.94</td>\n",
       "      <td>12.433782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-07-20 21:55:00</td>\n",
       "      <td>278.00</td>\n",
       "      <td>278.00</td>\n",
       "      <td>277.95</td>\n",
       "      <td>278.00</td>\n",
       "      <td>13.913200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime  btc_open  btc_high  btc_low  btc_close  btc_volume\n",
       "0 2015-07-20 21:35:00    277.98    277.99   277.97     277.97    1.501500\n",
       "1 2015-07-20 21:40:00    277.98    278.00   277.98     277.99   17.756475\n",
       "2 2015-07-20 21:45:00    278.00    278.00   277.98     277.99   13.655500\n",
       "3 2015-07-20 21:50:00    277.98    278.00   277.92     277.94   12.433782\n",
       "4 2015-07-20 21:55:00    278.00    278.00   277.95     278.00   13.913200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instrument_name = files_list[4].replace('-', '_').split('_')[0].lower()\n",
    "\n",
    "final_df_any = pd.read_csv(os.path.join(main_path, files_list[4]))\n",
    "final_df_any['datetime'] = pd.to_datetime(final_df_any['datetime'])\n",
    "final_df_any.set_index('datetime', inplace=True)\n",
    "final_df_any = final_df_any.resample('5min').agg({\n",
    "        'open': 'first',\n",
    "        'high': 'max',\n",
    "        'low': 'min',\n",
    "        'close': 'last',\n",
    "        'volume': 'sum'\n",
    "    })\n",
    "final_df_any.reset_index(inplace=True)\n",
    "\n",
    "final_df_any.rename(\n",
    "    columns={\n",
    "        'open': f'{instrument_name}_open', \n",
    "        'close': f'{instrument_name}_close', \n",
    "        'low': f'{instrument_name}_low', \n",
    "        'high': f'{instrument_name}_high', \n",
    "        'volume': f'{instrument_name}_volume'\n",
    "    },\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "final_df_any.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|      | 9/28 [00:13<00:32,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETH-1m-1000wks-data.csv_backup.csv doesn't contain overlapping data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|  | 21/28 [00:29<00:09,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOL-1m-1000wks-data.csv_backup.csv doesn't contain overlapping data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 28/28 [00:37<00:00,  1.35s/it]\n"
     ]
    }
   ],
   "source": [
    "FREQUENCY = '1D'\n",
    "\n",
    "instrument_name = files_list[4].replace('-', '_').split('_')[0].lower()\n",
    "\n",
    "final_df_any = pd.read_csv(os.path.join(main_path, files_list[4]))\n",
    "final_df_any['datetime'] = pd.to_datetime(final_df_any['datetime'])\n",
    "final_df_any.sort_values('datetime', ascending=True, inplace=True)\n",
    "final_df_any.set_index('datetime', inplace=True)\n",
    "final_df_any = final_df_any.resample(FREQUENCY).agg({\n",
    "        'open': 'first',\n",
    "        'high': 'max',\n",
    "        'low': 'min',\n",
    "        'close': 'last',\n",
    "        'volume': 'sum'\n",
    "    })\n",
    "# final_df_any.reset_index(inplace=True)\n",
    "\n",
    "final_df_any.rename(\n",
    "    columns={\n",
    "        'open': f'{instrument_name}_open', \n",
    "        'close': f'{instrument_name}_close', \n",
    "        'low': f'{instrument_name}_low', \n",
    "        'high': f'{instrument_name}_high', \n",
    "        'volume': f'{instrument_name}_volume'\n",
    "    },\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "# final_df_any.set_index('datetime', inplace=True)\n",
    "complete_time_index = pd.date_range(start=final_df_any.index.min(), end=final_df_any.index.max(), freq=FREQUENCY)\n",
    "final_df_any = final_df_any.reindex(complete_time_index)\n",
    "final_df_any = final_df_any.ffill()\n",
    "final_df_any.reset_index(inplace=True)\n",
    "final_df_any.rename(columns={'index': 'datetime'}, inplace=True)\n",
    "\n",
    "for i in tqdm(range(len(files_list))):\n",
    "\n",
    "    if i in [4, 9, 21]:\n",
    "        if i != 4:\n",
    "            print(f\"{files_list[i]} doesn't contain overlapping data.\")\n",
    "        continue\n",
    "    \n",
    "    instrument_name = files_list[i].replace('-', '_').split('_')[0].lower()\n",
    "\n",
    "    temp_df = pd.read_csv(os.path.join(main_path, files_list[i]))\n",
    "    temp_df['datetime'] = pd.to_datetime(temp_df['datetime'])\n",
    "    temp_df.sort_values('datetime', ascending=True, inplace=True)\n",
    "    temp_df.set_index('datetime', inplace=True)\n",
    "    temp_df = temp_df.resample(FREQUENCY).agg({\n",
    "            'open': 'first',\n",
    "            'high': 'max',\n",
    "            'low': 'min',\n",
    "            'close': 'last',\n",
    "            'volume': 'sum'\n",
    "        })\n",
    "    temp_df.reset_index(inplace=True)\n",
    "    temp_df.rename(\n",
    "        columns={\n",
    "            'open': f'{instrument_name}_open', \n",
    "            'close': f'{instrument_name}_close', \n",
    "            'low': f'{instrument_name}_low', \n",
    "            'high': f'{instrument_name}_high', \n",
    "            'volume': f'{instrument_name}_volume'\n",
    "        },\n",
    "        inplace=True\n",
    "    )\n",
    "    # print(f\"{i}: {files_list[i]}: start_date = {temp_df.iloc[0]['datetime']} end_date = {temp_df.iloc[-1]['datetime']}\")\n",
    "    # if i == 0:\n",
    "    #     final_df_any = temp_df.copy()\n",
    "    # else:\n",
    "    #     final_df_any = pd.merge(final_df_any, temp_df, on='datetime')\n",
    "    # temp_df.ffill(inplace=True)\n",
    "    final_df_any = pd.merge(final_df_any, temp_df, on='datetime', how='left')\n",
    "    final_df_any.ffill(inplace=True)\n",
    "\n",
    "    if final_df_any.shape[0] == 0:\n",
    "        print(i)\n",
    "\n",
    "    del temp_df\n",
    "\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3345, 131)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(319, 131)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(final_df_any.shape)\n",
    "final_df_any.dropna(inplace=True)\n",
    "final_df_any.reset_index(drop=True, inplace=True)\n",
    "final_df_any.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "319"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(final_df_any['datetime'].diff().apply(lambda x: x if pd.isna(x) else x.total_seconds()/60) != 5).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>btc_open</th>\n",
       "      <th>btc_high</th>\n",
       "      <th>btc_low</th>\n",
       "      <th>btc_close</th>\n",
       "      <th>btc_volume</th>\n",
       "      <th>6e_open</th>\n",
       "      <th>6e_high</th>\n",
       "      <th>6e_low</th>\n",
       "      <th>6e_close</th>\n",
       "      <th>...</th>\n",
       "      <th>zf_open</th>\n",
       "      <th>zf_high</th>\n",
       "      <th>zf_low</th>\n",
       "      <th>zf_close</th>\n",
       "      <th>zf_volume</th>\n",
       "      <th>zn_open</th>\n",
       "      <th>zn_high</th>\n",
       "      <th>zn_low</th>\n",
       "      <th>zn_close</th>\n",
       "      <th>zn_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-11-01</td>\n",
       "      <td>34656.38</td>\n",
       "      <td>35647.19</td>\n",
       "      <td>34079.46</td>\n",
       "      <td>35440.10</td>\n",
       "      <td>16196.302638</td>\n",
       "      <td>1.0598</td>\n",
       "      <td>1.06060</td>\n",
       "      <td>1.05365</td>\n",
       "      <td>1.06055</td>\n",
       "      <td>...</td>\n",
       "      <td>104.367188</td>\n",
       "      <td>105.265625</td>\n",
       "      <td>104.343750</td>\n",
       "      <td>105.226562</td>\n",
       "      <td>1638972.0</td>\n",
       "      <td>105.921875</td>\n",
       "      <td>107.390625</td>\n",
       "      <td>105.859375</td>\n",
       "      <td>107.328125</td>\n",
       "      <td>2517584.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-11-02</td>\n",
       "      <td>35440.10</td>\n",
       "      <td>35997.80</td>\n",
       "      <td>34311.73</td>\n",
       "      <td>34950.00</td>\n",
       "      <td>13455.655270</td>\n",
       "      <td>1.0606</td>\n",
       "      <td>1.06865</td>\n",
       "      <td>1.06025</td>\n",
       "      <td>1.06340</td>\n",
       "      <td>...</td>\n",
       "      <td>105.226562</td>\n",
       "      <td>105.484375</td>\n",
       "      <td>105.062500</td>\n",
       "      <td>105.109375</td>\n",
       "      <td>1587834.0</td>\n",
       "      <td>107.312500</td>\n",
       "      <td>107.875000</td>\n",
       "      <td>107.078125</td>\n",
       "      <td>107.421875</td>\n",
       "      <td>2162119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-11-03</td>\n",
       "      <td>34947.92</td>\n",
       "      <td>34954.60</td>\n",
       "      <td>34100.00</td>\n",
       "      <td>34731.27</td>\n",
       "      <td>13961.700145</td>\n",
       "      <td>1.0634</td>\n",
       "      <td>1.07655</td>\n",
       "      <td>1.06330</td>\n",
       "      <td>1.07505</td>\n",
       "      <td>...</td>\n",
       "      <td>105.117188</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>105.070312</td>\n",
       "      <td>105.734375</td>\n",
       "      <td>1821627.0</td>\n",
       "      <td>107.421875</td>\n",
       "      <td>108.781250</td>\n",
       "      <td>107.390625</td>\n",
       "      <td>108.250000</td>\n",
       "      <td>2599995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-11-04</td>\n",
       "      <td>34730.32</td>\n",
       "      <td>35278.40</td>\n",
       "      <td>34599.85</td>\n",
       "      <td>35087.01</td>\n",
       "      <td>4696.701483</td>\n",
       "      <td>1.0634</td>\n",
       "      <td>1.07655</td>\n",
       "      <td>1.06330</td>\n",
       "      <td>1.07505</td>\n",
       "      <td>...</td>\n",
       "      <td>105.117188</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>105.070312</td>\n",
       "      <td>105.734375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107.421875</td>\n",
       "      <td>108.781250</td>\n",
       "      <td>107.390625</td>\n",
       "      <td>108.250000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-11-05</td>\n",
       "      <td>35087.43</td>\n",
       "      <td>35410.00</td>\n",
       "      <td>34500.00</td>\n",
       "      <td>35035.42</td>\n",
       "      <td>5796.961673</td>\n",
       "      <td>1.0747</td>\n",
       "      <td>1.07520</td>\n",
       "      <td>1.07420</td>\n",
       "      <td>1.07495</td>\n",
       "      <td>...</td>\n",
       "      <td>105.726562</td>\n",
       "      <td>105.734375</td>\n",
       "      <td>105.656250</td>\n",
       "      <td>105.656250</td>\n",
       "      <td>11787.0</td>\n",
       "      <td>108.234375</td>\n",
       "      <td>108.234375</td>\n",
       "      <td>108.125000</td>\n",
       "      <td>108.140625</td>\n",
       "      <td>19554.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    datetime  btc_open  btc_high   btc_low  btc_close    btc_volume  6e_open  \\\n",
       "0 2023-11-01  34656.38  35647.19  34079.46   35440.10  16196.302638   1.0598   \n",
       "1 2023-11-02  35440.10  35997.80  34311.73   34950.00  13455.655270   1.0606   \n",
       "2 2023-11-03  34947.92  34954.60  34100.00   34731.27  13961.700145   1.0634   \n",
       "3 2023-11-04  34730.32  35278.40  34599.85   35087.01   4696.701483   1.0634   \n",
       "4 2023-11-05  35087.43  35410.00  34500.00   35035.42   5796.961673   1.0747   \n",
       "\n",
       "   6e_high   6e_low  6e_close  ...     zf_open     zf_high      zf_low  \\\n",
       "0  1.06060  1.05365   1.06055  ...  104.367188  105.265625  104.343750   \n",
       "1  1.06865  1.06025   1.06340  ...  105.226562  105.484375  105.062500   \n",
       "2  1.07655  1.06330   1.07505  ...  105.117188  106.000000  105.070312   \n",
       "3  1.07655  1.06330   1.07505  ...  105.117188  106.000000  105.070312   \n",
       "4  1.07520  1.07420   1.07495  ...  105.726562  105.734375  105.656250   \n",
       "\n",
       "     zf_close  zf_volume     zn_open     zn_high      zn_low    zn_close  \\\n",
       "0  105.226562  1638972.0  105.921875  107.390625  105.859375  107.328125   \n",
       "1  105.109375  1587834.0  107.312500  107.875000  107.078125  107.421875   \n",
       "2  105.734375  1821627.0  107.421875  108.781250  107.390625  108.250000   \n",
       "3  105.734375        0.0  107.421875  108.781250  107.390625  108.250000   \n",
       "4  105.656250    11787.0  108.234375  108.234375  108.125000  108.140625   \n",
       "\n",
       "   zn_volume  \n",
       "0  2517584.0  \n",
       "1  2162119.0  \n",
       "2  2599995.0  \n",
       "3        0.0  \n",
       "4    19554.0  \n",
       "\n",
       "[5 rows x 131 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df_any.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_any.to_csv(f'data_{FREQUENCY}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating strategies for testing from KJD book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "inds_params = [5, 10, 14, 30, 50, 65]\n",
    "filters_params = [100, 150, 200, 250, 300, 350]\n",
    "\n",
    "buy_strs = []\n",
    "sell_strs = []\n",
    "\n",
    "for i in tqdm(range(len(inds_params))):\n",
    "\n",
    "    for j in range(len(filters_params)):\n",
    "\n",
    "\n",
    "        window1 = inds_params[i]\n",
    "        window2 = filters_params[j]\n",
    "        lag1 = inds_params[i]\n",
    "        lag2 = filters_params[j]\n",
    "\n",
    "        buy_txt = f'''(price_data['btc_close'][MAX_LAG:] == signals.moving_max(price_data['btc_close'], window={window1})[MAX_LAG:])\n",
    "(price_data['btc_close'][MAX_LAG:] == signals.moving_min(price_data['btc_close'], window={window1})[MAX_LAG:])\n",
    "(numba_indicators.relative_strength_index(prices=price_data['btc_close'], window={window1})[MAX_LAG:] < 30)\n",
    "(numba_indicators.relative_strength_index(prices=price_data['btc_close'], window={window1})[MAX_LAG:] > 70)\n",
    "(price_data['btc_close'][MAX_LAG:] > get_lag(price_data['btc_close'], lag={lag1})[MAX_LAG:])\n",
    "(price_data['btc_close'][MAX_LAG:] < get_lag(price_data['btc_close'], lag={lag1})[MAX_LAG:])\n",
    "(price_data['btc_close'][MAX_LAG:] > numba_indicators.moving_average(prices=price_data['btc_close'], window={window1})[MAX_LAG:])\n",
    "(price_data['btc_close'][MAX_LAG:] < numba_indicators.moving_average(prices=price_data['btc_close'], window={window1})[MAX_LAG:])\n",
    "((price_data['btc_close'][MAX_LAG:] == signals.moving_max(price_data['btc_close'], window={window1})[MAX_LAG:]) & (price_data['btc_close'][MAX_LAG:] > numba_indicators.moving_average(prices=price_data['btc_close'], window={window2})[MAX_LAG:]))\n",
    "((price_data['btc_close'][MAX_LAG:] == signals.moving_min(price_data['btc_close'], window={window1})[MAX_LAG:]) & (price_data['btc_close'][MAX_LAG:] > numba_indicators.moving_average(prices=price_data['btc_close'], window={window2})[MAX_LAG:]))\n",
    "((numba_indicators.relative_strength_index(prices=price_data['btc_close'], window={window1})[MAX_LAG:] < 30) & (price_data['btc_close'][MAX_LAG:] > numba_indicators.moving_average(prices=price_data['btc_close'], window={window2})[MAX_LAG:]))\n",
    "((numba_indicators.relative_strength_index(prices=price_data['btc_close'], window={window1})[MAX_LAG:] > 70) & (price_data['btc_close'][MAX_LAG:] > numba_indicators.moving_average(prices=price_data['btc_close'], window={window2})[MAX_LAG:]))\n",
    "((price_data['btc_close'][MAX_LAG:] > get_lag(price_data['btc_close'], lag={lag1})[MAX_LAG:]) & (price_data['btc_close'][MAX_LAG:] > numba_indicators.moving_average(prices=price_data['btc_close'], window={window2})[MAX_LAG:]))\n",
    "((price_data['btc_close'][MAX_LAG:] < get_lag(price_data['btc_close'], lag={lag1})[MAX_LAG:]) & (price_data['btc_close'][MAX_LAG:] > numba_indicators.moving_average(prices=price_data['btc_close'], window={window2})[MAX_LAG:]))\n",
    "((price_data['btc_close'][MAX_LAG:] > numba_indicators.moving_average(prices=price_data['btc_close'], window={window1})[MAX_LAG:]) & (price_data['btc_close'][MAX_LAG:] > numba_indicators.moving_average(prices=price_data['btc_close'], window={window2})[MAX_LAG:]))\n",
    "((price_data['btc_close'][MAX_LAG:] < numba_indicators.moving_average(prices=price_data['btc_close'], window={window1})[MAX_LAG:]) & (price_data['btc_close'][MAX_LAG:] > numba_indicators.moving_average(prices=price_data['btc_close'], window={window2})[MAX_LAG:]))\n",
    "((price_data['btc_close'][MAX_LAG:] == signals.moving_max(price_data['btc_close'], window={window1})[MAX_LAG:]) & (price_data['btc_close'][MAX_LAG:] > get_lag(price_data['btc_close'], lag={lag2})[MAX_LAG:]))\n",
    "((price_data['btc_close'][MAX_LAG:] == signals.moving_min(price_data['btc_close'], window={window1})[MAX_LAG:]) & (price_data['btc_close'][MAX_LAG:] > get_lag(price_data['btc_close'], lag={lag2})[MAX_LAG:]))\n",
    "((numba_indicators.relative_strength_index(prices=price_data['btc_close'], window={window1})[MAX_LAG:] < 30) & (price_data['btc_close'][MAX_LAG:] > get_lag(price_data['btc_close'], lag={lag2})[MAX_LAG:]))\n",
    "((numba_indicators.relative_strength_index(prices=price_data['btc_close'], window={window1})[MAX_LAG:] > 70) & (price_data['btc_close'][MAX_LAG:] > get_lag(price_data['btc_close'], lag={lag2})[MAX_LAG:]))\n",
    "((price_data['btc_close'][MAX_LAG:] > get_lag(price_data['btc_close'], lag={lag1})[MAX_LAG:]) & (price_data['btc_close'][MAX_LAG:] > get_lag(price_data['btc_close'], lag={lag2})[MAX_LAG:]))\n",
    "((price_data['btc_close'][MAX_LAG:] < get_lag(price_data['btc_close'], lag={lag1})[MAX_LAG:]) & (price_data['btc_close'][MAX_LAG:] > get_lag(price_data['btc_close'], lag={lag2})[MAX_LAG:]))\n",
    "((price_data['btc_close'][MAX_LAG:] > numba_indicators.moving_average(prices=price_data['btc_close'], window={window1})[MAX_LAG:]) & (price_data['btc_close'][MAX_LAG:] > get_lag(price_data['btc_close'], lag={lag2})[MAX_LAG:]))\n",
    "((price_data['btc_close'][MAX_LAG:] < numba_indicators.moving_average(prices=price_data['btc_close'], window={window1})[MAX_LAG:]) & (price_data['btc_close'][MAX_LAG:] > get_lag(price_data['btc_close'], lag={lag2})[MAX_LAG:]))\n",
    "((price_data['btc_close'][MAX_LAG:] == signals.moving_max(price_data['btc_close'], window={window1})[MAX_LAG:]) & (numba_indicators.adx(high=price_data['btc_high'], low=price_data['btc_low'], close=price_data['btc_close'], window={window2})[MAX_LAG:] > 15))\n",
    "((price_data['btc_close'][MAX_LAG:] == signals.moving_min(price_data['btc_close'], window={window1})[MAX_LAG:]) & (numba_indicators.adx(high=price_data['btc_high'], low=price_data['btc_low'], close=price_data['btc_close'], window={window2})[MAX_LAG:] > 15))\n",
    "((numba_indicators.relative_strength_index(prices=price_data['btc_close'], window={window1})[MAX_LAG:] < 30) & (numba_indicators.adx(high=price_data['btc_high'], low=price_data['btc_low'], close=price_data['btc_close'], window={window2})[MAX_LAG:] > 15))\n",
    "((numba_indicators.relative_strength_index(prices=price_data['btc_close'], window={window1})[MAX_LAG:] > 70) & (numba_indicators.adx(high=price_data['btc_high'], low=price_data['btc_low'], close=price_data['btc_close'], window={window2})[MAX_LAG:] > 15))\n",
    "((price_data['btc_close'][MAX_LAG:] > get_lag(price_data['btc_close'], lag={lag1})[MAX_LAG:]) & (numba_indicators.adx(high=price_data['btc_high'], low=price_data['btc_low'], close=price_data['btc_close'], window={window2})[MAX_LAG:] > 15))\n",
    "((price_data['btc_close'][MAX_LAG:] < get_lag(price_data['btc_close'], lag={lag1})[MAX_LAG:]) & (numba_indicators.adx(high=price_data['btc_high'], low=price_data['btc_low'], close=price_data['btc_close'], window={window2})[MAX_LAG:] > 15))\n",
    "((price_data['btc_close'][MAX_LAG:] > numba_indicators.moving_average(prices=price_data['btc_close'], window={window1})[MAX_LAG:]) & (numba_indicators.adx(high=price_data['btc_high'], low=price_data['btc_low'], close=price_data['btc_close'], window={window2})[MAX_LAG:] > 15))\n",
    "((price_data['btc_close'][MAX_LAG:] < numba_indicators.moving_average(prices=price_data['btc_close'], window={window1})[MAX_LAG:]) & (numba_indicators.adx(high=price_data['btc_high'], low=price_data['btc_low'], close=price_data['btc_close'], window={window2})[MAX_LAG:] > 15))\n",
    "((price_data['btc_close'][MAX_LAG:] == signals.moving_max(price_data['btc_close'], window={window1})[MAX_LAG:]) & (numba_indicators.relative_strength_index(prices=price_data['btc_close'], window={window2})[MAX_LAG:] < 70))\n",
    "((price_data['btc_close'][MAX_LAG:] == signals.moving_min(price_data['btc_close'], window={window1})[MAX_LAG:]) & (numba_indicators.relative_strength_index(prices=price_data['btc_close'], window={window2})[MAX_LAG:] < 70))\n",
    "((numba_indicators.relative_strength_index(prices=price_data['btc_close'], window={window1})[MAX_LAG:] < 30) & (numba_indicators.relative_strength_index(prices=price_data['btc_close'], window={window2})[MAX_LAG:] < 70))\n",
    "((numba_indicators.relative_strength_index(prices=price_data['btc_close'], window={window1})[MAX_LAG:] > 70) & (numba_indicators.relative_strength_index(prices=price_data['btc_close'], window={window2})[MAX_LAG:] < 70))\n",
    "((price_data['btc_close'][MAX_LAG:] > get_lag(price_data['btc_close'], lag={lag1})[MAX_LAG:]) & (numba_indicators.relative_strength_index(prices=price_data['btc_close'], window={window2})[MAX_LAG:] < 70))\n",
    "((price_data['btc_close'][MAX_LAG:] < get_lag(price_data['btc_close'], lag={lag1})[MAX_LAG:]) & (numba_indicators.relative_strength_index(prices=price_data['btc_close'], window={window2})[MAX_LAG:] < 70))\n",
    "((price_data['btc_close'][MAX_LAG:] > numba_indicators.moving_average(prices=price_data['btc_close'], window={window1})[MAX_LAG:]) & (numba_indicators.relative_strength_index(prices=price_data['btc_close'], window={window2})[MAX_LAG:] < 70))\n",
    "((price_data['btc_close'][MAX_LAG:] < numba_indicators.moving_average(prices=price_data['btc_close'], window={window1})[MAX_LAG:]) & (numba_indicators.relative_strength_index(prices=price_data['btc_close'], window={window2})[MAX_LAG:] < 70))\n",
    "((price_data['btc_close'][MAX_LAG:] == signals.moving_max(price_data['btc_close'], window={window1})[MAX_LAG:]) & (numba_indicators.rolling_max_index(price_data['btc_high'], window={window2})[MAX_LAG:] > numba_indicators.rolling_min_index(price_data['btc_low'], window={window2})[MAX_LAG:]))\n",
    "((price_data['btc_close'][MAX_LAG:] == signals.moving_min(price_data['btc_close'], window={window1})[MAX_LAG:]) & (numba_indicators.rolling_max_index(price_data['btc_high'], window={window2})[MAX_LAG:] > numba_indicators.rolling_min_index(price_data['btc_low'], window={window2})[MAX_LAG:]))\n",
    "((numba_indicators.relative_strength_index(prices=price_data['btc_close'], window={window1})[MAX_LAG:] < 30) & (numba_indicators.rolling_max_index(price_data['btc_high'], window={window2})[MAX_LAG:] > numba_indicators.rolling_min_index(price_data['btc_low'], window={window2})[MAX_LAG:]))\n",
    "((numba_indicators.relative_strength_index(prices=price_data['btc_close'], window={window1})[MAX_LAG:] > 70) & (numba_indicators.rolling_max_index(price_data['btc_high'], window={window2})[MAX_LAG:] > numba_indicators.rolling_min_index(price_data['btc_low'], window={window2})[MAX_LAG:]))\n",
    "((price_data['btc_close'][MAX_LAG:] > get_lag(price_data['btc_close'], lag={lag1})[MAX_LAG:]) & (numba_indicators.rolling_max_index(price_data['btc_high'], window={window2})[MAX_LAG:] > numba_indicators.rolling_min_index(price_data['btc_low'], window={window2})[MAX_LAG:]))\n",
    "((price_data['btc_close'][MAX_LAG:] < get_lag(price_data['btc_close'], lag={lag1})[MAX_LAG:]) & (numba_indicators.rolling_max_index(price_data['btc_high'], window={window2})[MAX_LAG:] > numba_indicators.rolling_min_index(price_data['btc_low'], window={window2})[MAX_LAG:]))\n",
    "((price_data['btc_close'][MAX_LAG:] > numba_indicators.moving_average(prices=price_data['btc_close'], window={window1})[MAX_LAG:]) & (numba_indicators.rolling_max_index(price_data['btc_high'], window={window2})[MAX_LAG:] > numba_indicators.rolling_min_index(price_data['btc_low'], window={window2})[MAX_LAG:]))\n",
    "((price_data['btc_close'][MAX_LAG:] < numba_indicators.moving_average(prices=price_data['btc_close'], window={window1})[MAX_LAG:]) & (numba_indicators.rolling_max_index(price_data['btc_high'], window={window2})[MAX_LAG:] > numba_indicators.rolling_min_index(price_data['btc_low'], window={window2})[MAX_LAG:]))'''\n",
    "\n",
    "        temp_buy_strs = buy_txt.split('\\n')\n",
    "        buy_strs.extend(temp_buy_strs)\n",
    "\n",
    "        sell_txt = f'''(price_data['btc_close'][MAX_LAG:] == signals.moving_max(price_data['btc_close'], window={window1})[MAX_LAG:])\n",
    "(price_data['btc_close'][MAX_LAG:] == signals.moving_min(price_data['btc_close'], window={window1})[MAX_LAG:])\n",
    "(numba_indicators.relative_strength_index(prices=price_data['btc_close'], window={window1})[MAX_LAG:] < 30)\n",
    "(numba_indicators.relative_strength_index(prices=price_data['btc_close'], window={window1})[MAX_LAG:] > 70)\n",
    "(price_data['btc_close'][MAX_LAG:] > get_lag(price_data['btc_close'], lag={lag1})[MAX_LAG:])\n",
    "(price_data['btc_close'][MAX_LAG:] < get_lag(price_data['btc_close'], lag={lag1})[MAX_LAG:])\n",
    "(price_data['btc_close'][MAX_LAG:] > numba_indicators.moving_average(prices=price_data['btc_close'], window={window1})[MAX_LAG:])\n",
    "(price_data['btc_close'][MAX_LAG:] < numba_indicators.moving_average(prices=price_data['btc_close'], window={window1})[MAX_LAG:])\n",
    "((price_data['btc_close'][MAX_LAG:] == signals.moving_max(price_data['btc_close'], window={window1})[MAX_LAG:]) & (price_data['btc_close'][MAX_LAG:] < numba_indicators.moving_average(prices=price_data['btc_close'], window={window2})[MAX_LAG:]))\n",
    "((price_data['btc_close'][MAX_LAG:] == signals.moving_min(price_data['btc_close'], window={window1})[MAX_LAG:]) & (price_data['btc_close'][MAX_LAG:] < numba_indicators.moving_average(prices=price_data['btc_close'], window={window2})[MAX_LAG:]))\n",
    "((numba_indicators.relative_strength_index(prices=price_data['btc_close'], window={window1})[MAX_LAG:] < 30) & (price_data['btc_close'][MAX_LAG:] < numba_indicators.moving_average(prices=price_data['btc_close'], window={window2})[MAX_LAG:]))\n",
    "((numba_indicators.relative_strength_index(prices=price_data['btc_close'], window={window1})[MAX_LAG:] > 70) & (price_data['btc_close'][MAX_LAG:] < numba_indicators.moving_average(prices=price_data['btc_close'], window={window2})[MAX_LAG:]))\n",
    "((price_data['btc_close'][MAX_LAG:] > get_lag(price_data['btc_close'], lag={lag1})[MAX_LAG:]) & (price_data['btc_close'][MAX_LAG:] < numba_indicators.moving_average(prices=price_data['btc_close'], window={window2})[MAX_LAG:]))\n",
    "((price_data['btc_close'][MAX_LAG:] < get_lag(price_data['btc_close'], lag={lag1})[MAX_LAG:]) & (price_data['btc_close'][MAX_LAG:] < numba_indicators.moving_average(prices=price_data['btc_close'], window={window2})[MAX_LAG:]))\n",
    "((price_data['btc_close'][MAX_LAG:] > numba_indicators.moving_average(prices=price_data['btc_close'], window={window1})[MAX_LAG:]) & (price_data['btc_close'][MAX_LAG:] < numba_indicators.moving_average(prices=price_data['btc_close'], window={window2})[MAX_LAG:]))\n",
    "((price_data['btc_close'][MAX_LAG:] < numba_indicators.moving_average(prices=price_data['btc_close'], window={window1})[MAX_LAG:]) & (price_data['btc_close'][MAX_LAG:] < numba_indicators.moving_average(prices=price_data['btc_close'], window={window2})[MAX_LAG:]))\n",
    "((price_data['btc_close'][MAX_LAG:] == signals.moving_max(price_data['btc_close'], window={window1})[MAX_LAG:]) & (price_data['btc_close'][MAX_LAG:] < get_lag(price_data['btc_close'], lag={lag2})[MAX_LAG:]))\n",
    "((price_data['btc_close'][MAX_LAG:] == signals.moving_min(price_data['btc_close'], window={window1})[MAX_LAG:]) & (price_data['btc_close'][MAX_LAG:] < get_lag(price_data['btc_close'], lag={lag2})[MAX_LAG:]))\n",
    "((numba_indicators.relative_strength_index(prices=price_data['btc_close'], window={window1})[MAX_LAG:] < 30) & (price_data['btc_close'][MAX_LAG:] < get_lag(price_data['btc_close'], lag={lag2})[MAX_LAG:]))\n",
    "((numba_indicators.relative_strength_index(prices=price_data['btc_close'], window={window1})[MAX_LAG:] > 70) & (price_data['btc_close'][MAX_LAG:] < get_lag(price_data['btc_close'], lag={lag2})[MAX_LAG:]))\n",
    "((price_data['btc_close'][MAX_LAG:] > get_lag(price_data['btc_close'], lag={lag1})[MAX_LAG:]) & (price_data['btc_close'][MAX_LAG:] < get_lag(price_data['btc_close'], lag={lag2})[MAX_LAG:]))\n",
    "((price_data['btc_close'][MAX_LAG:] < get_lag(price_data['btc_close'], lag={lag1})[MAX_LAG:]) & (price_data['btc_close'][MAX_LAG:] < get_lag(price_data['btc_close'], lag={lag2})[MAX_LAG:]))\n",
    "((price_data['btc_close'][MAX_LAG:] > numba_indicators.moving_average(prices=price_data['btc_close'], window={window1})[MAX_LAG:]) & (price_data['btc_close'][MAX_LAG:] < get_lag(price_data['btc_close'], lag={lag2})[MAX_LAG:]))\n",
    "((price_data['btc_close'][MAX_LAG:] < numba_indicators.moving_average(prices=price_data['btc_close'], window={window1})[MAX_LAG:]) & (price_data['btc_close'][MAX_LAG:] < get_lag(price_data['btc_close'], lag={lag2})[MAX_LAG:]))\n",
    "((price_data['btc_close'][MAX_LAG:] == signals.moving_max(price_data['btc_close'], window={window1})[MAX_LAG:]) & (numba_indicators.adx(high=price_data['btc_high'], low=price_data['btc_low'], close=price_data['btc_close'], window={window2})[MAX_LAG:] > 15))\n",
    "((price_data['btc_close'][MAX_LAG:] == signals.moving_min(price_data['btc_close'], window={window1})[MAX_LAG:]) & (numba_indicators.adx(high=price_data['btc_high'], low=price_data['btc_low'], close=price_data['btc_close'], window={window2})[MAX_LAG:] > 15))\n",
    "((numba_indicators.relative_strength_index(prices=price_data['btc_close'], window={window1})[MAX_LAG:] < 30) & (numba_indicators.adx(high=price_data['btc_high'], low=price_data['btc_low'], close=price_data['btc_close'], window={window2})[MAX_LAG:] > 15))\n",
    "((numba_indicators.relative_strength_index(prices=price_data['btc_close'], window={window1})[MAX_LAG:] > 70) & (numba_indicators.adx(high=price_data['btc_high'], low=price_data['btc_low'], close=price_data['btc_close'], window={window2})[MAX_LAG:] > 15))\n",
    "((price_data['btc_close'][MAX_LAG:] > get_lag(price_data['btc_close'], lag={lag1})[MAX_LAG:]) & (numba_indicators.adx(high=price_data['btc_high'], low=price_data['btc_low'], close=price_data['btc_close'], window={window2})[MAX_LAG:] > 15))\n",
    "((price_data['btc_close'][MAX_LAG:] < get_lag(price_data['btc_close'], lag={lag1})[MAX_LAG:]) & (numba_indicators.adx(high=price_data['btc_high'], low=price_data['btc_low'], close=price_data['btc_close'], window={window2})[MAX_LAG:] > 15))\n",
    "((price_data['btc_close'][MAX_LAG:] > numba_indicators.moving_average(prices=price_data['btc_close'], window={window1})[MAX_LAG:]) & (numba_indicators.adx(high=price_data['btc_high'], low=price_data['btc_low'], close=price_data['btc_close'], window={window2})[MAX_LAG:] > 15))\n",
    "((price_data['btc_close'][MAX_LAG:] < numba_indicators.moving_average(prices=price_data['btc_close'], window={window1})[MAX_LAG:]) & (numba_indicators.adx(high=price_data['btc_high'], low=price_data['btc_low'], close=price_data['btc_close'], window={window2})[MAX_LAG:] > 15))\n",
    "((price_data['btc_close'][MAX_LAG:] == signals.moving_max(price_data['btc_close'], window={window1})[MAX_LAG:]) & (numba_indicators.relative_strength_index(prices=price_data['btc_close'], window={window2})[MAX_LAG:] > 30))\n",
    "((price_data['btc_close'][MAX_LAG:] == signals.moving_min(price_data['btc_close'], window={window1})[MAX_LAG:]) & (numba_indicators.relative_strength_index(prices=price_data['btc_close'], window={window2})[MAX_LAG:] > 30))\n",
    "((numba_indicators.relative_strength_index(prices=price_data['btc_close'], window={window1})[MAX_LAG:] < 30) & (numba_indicators.relative_strength_index(prices=price_data['btc_close'], window={window2})[MAX_LAG:] > 30))\n",
    "((numba_indicators.relative_strength_index(prices=price_data['btc_close'], window={window1})[MAX_LAG:] > 70) & (numba_indicators.relative_strength_index(prices=price_data['btc_close'], window={window2})[MAX_LAG:] > 30))\n",
    "((price_data['btc_close'][MAX_LAG:] > get_lag(price_data['btc_close'], lag={lag1})[MAX_LAG:]) & (numba_indicators.relative_strength_index(prices=price_data['btc_close'], window={window2})[MAX_LAG:] > 30))\n",
    "((price_data['btc_close'][MAX_LAG:] < get_lag(price_data['btc_close'], lag={lag1})[MAX_LAG:]) & (numba_indicators.relative_strength_index(prices=price_data['btc_close'], window={window2})[MAX_LAG:] > 30))\n",
    "((price_data['btc_close'][MAX_LAG:] > numba_indicators.moving_average(prices=price_data['btc_close'], window={window1})[MAX_LAG:]) & (numba_indicators.relative_strength_index(prices=price_data['btc_close'], window={window2})[MAX_LAG:] > 30))\n",
    "((price_data['btc_close'][MAX_LAG:] < numba_indicators.moving_average(prices=price_data['btc_close'], window={window1})[MAX_LAG:]) & (numba_indicators.relative_strength_index(prices=price_data['btc_close'], window={window2})[MAX_LAG:] > 30))\n",
    "((price_data['btc_close'][MAX_LAG:] == signals.moving_max(price_data['btc_close'], window={window1})[MAX_LAG:]) & (numba_indicators.rolling_max_index(price_data['btc_high'], window={window2})[MAX_LAG:] < numba_indicators.rolling_min_index(price_data['btc_low'], window={window2})[MAX_LAG:]))\n",
    "((price_data['btc_close'][MAX_LAG:] == signals.moving_min(price_data['btc_close'], window={window1})[MAX_LAG:]) & (numba_indicators.rolling_max_index(price_data['btc_high'], window={window2})[MAX_LAG:] < numba_indicators.rolling_min_index(price_data['btc_low'], window={window2})[MAX_LAG:]))\n",
    "((numba_indicators.relative_strength_index(prices=price_data['btc_close'], window={window1})[MAX_LAG:] < 30) & (numba_indicators.rolling_max_index(price_data['btc_high'], window={window2})[MAX_LAG:] < numba_indicators.rolling_min_index(price_data['btc_low'], window={window2})[MAX_LAG:]))\n",
    "((numba_indicators.relative_strength_index(prices=price_data['btc_close'], window={window1})[MAX_LAG:] > 70) & (numba_indicators.rolling_max_index(price_data['btc_high'], window={window2})[MAX_LAG:] < numba_indicators.rolling_min_index(price_data['btc_low'], window={window2})[MAX_LAG:]))\n",
    "((price_data['btc_close'][MAX_LAG:] > get_lag(price_data['btc_close'], lag={lag1})[MAX_LAG:]) & (numba_indicators.rolling_max_index(price_data['btc_high'], window={window2})[MAX_LAG:] < numba_indicators.rolling_min_index(price_data['btc_low'], window={window2})[MAX_LAG:]))\n",
    "((price_data['btc_close'][MAX_LAG:] < get_lag(price_data['btc_close'], lag={lag1})[MAX_LAG:]) & (numba_indicators.rolling_max_index(price_data['btc_high'], window={window2})[MAX_LAG:] < numba_indicators.rolling_min_index(price_data['btc_low'], window={window2})[MAX_LAG:]))\n",
    "((price_data['btc_close'][MAX_LAG:] > numba_indicators.moving_average(prices=price_data['btc_close'], window={window1})[MAX_LAG:]) & (numba_indicators.rolling_max_index(price_data['btc_high'], window={window2})[MAX_LAG:] < numba_indicators.rolling_min_index(price_data['btc_low'], window={window2})[MAX_LAG:]))\n",
    "((price_data['btc_close'][MAX_LAG:] < numba_indicators.moving_average(prices=price_data['btc_close'], window={window1})[MAX_LAG:]) & (numba_indicators.rolling_max_index(price_data['btc_high'], window={window2})[MAX_LAG:] < numba_indicators.rolling_min_index(price_data['btc_low'], window={window2})[MAX_LAG:]))'''\n",
    "\n",
    "        temp_sell_strs = sell_txt.split('\\n')\n",
    "        sell_strs.extend(temp_sell_strs)\n",
    "\n",
    "df_test_str = pd.DataFrame()\n",
    "df_test_str['buy'] = buy_strs\n",
    "df_test_str['sell'] = sell_strs\n",
    "\n",
    "df_test_str.to_csv('test_strategies.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buy</th>\n",
       "      <th>sell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(price_data['btc_close'][MAX_LAG:] == signals....</td>\n",
       "      <td>(price_data['btc_close'][MAX_LAG:] == signals....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(price_data['btc_close'][MAX_LAG:] == signals....</td>\n",
       "      <td>(price_data['btc_close'][MAX_LAG:] == signals....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(numba_indicators.relative_strength_index(pric...</td>\n",
       "      <td>(numba_indicators.relative_strength_index(pric...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(numba_indicators.relative_strength_index(pric...</td>\n",
       "      <td>(numba_indicators.relative_strength_index(pric...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(price_data['btc_close'][MAX_LAG:] &gt; get_lag(p...</td>\n",
       "      <td>(price_data['btc_close'][MAX_LAG:] &gt; get_lag(p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 buy  \\\n",
       "0  (price_data['btc_close'][MAX_LAG:] == signals....   \n",
       "1  (price_data['btc_close'][MAX_LAG:] == signals....   \n",
       "2  (numba_indicators.relative_strength_index(pric...   \n",
       "3  (numba_indicators.relative_strength_index(pric...   \n",
       "4  (price_data['btc_close'][MAX_LAG:] > get_lag(p...   \n",
       "\n",
       "                                                sell  \n",
       "0  (price_data['btc_close'][MAX_LAG:] == signals....  \n",
       "1  (price_data['btc_close'][MAX_LAG:] == signals....  \n",
       "2  (numba_indicators.relative_strength_index(pric...  \n",
       "3  (numba_indicators.relative_strength_index(pric...  \n",
       "4  (price_data['btc_close'][MAX_LAG:] > get_lag(p...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_str.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>btc_open</th>\n",
       "      <th>btc_high</th>\n",
       "      <th>btc_low</th>\n",
       "      <th>btc_close</th>\n",
       "      <th>btc_volume</th>\n",
       "      <th>6e_open</th>\n",
       "      <th>6e_high</th>\n",
       "      <th>6e_low</th>\n",
       "      <th>6e_close</th>\n",
       "      <th>...</th>\n",
       "      <th>zf_open</th>\n",
       "      <th>zf_high</th>\n",
       "      <th>zf_low</th>\n",
       "      <th>zf_close</th>\n",
       "      <th>zf_volume</th>\n",
       "      <th>zn_open</th>\n",
       "      <th>zn_high</th>\n",
       "      <th>zn_low</th>\n",
       "      <th>zn_close</th>\n",
       "      <th>zn_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-11-01 18:14:00</td>\n",
       "      <td>34553.59</td>\n",
       "      <td>34565.88</td>\n",
       "      <td>34546.16</td>\n",
       "      <td>34549.35</td>\n",
       "      <td>6.687855</td>\n",
       "      <td>1.0557</td>\n",
       "      <td>1.05570</td>\n",
       "      <td>1.05515</td>\n",
       "      <td>1.05520</td>\n",
       "      <td>...</td>\n",
       "      <td>104.867188</td>\n",
       "      <td>104.867188</td>\n",
       "      <td>104.843750</td>\n",
       "      <td>104.843750</td>\n",
       "      <td>1640.0</td>\n",
       "      <td>106.750000</td>\n",
       "      <td>106.765625</td>\n",
       "      <td>106.703125</td>\n",
       "      <td>106.703125</td>\n",
       "      <td>2238.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-11-01 18:15:00</td>\n",
       "      <td>34549.33</td>\n",
       "      <td>34552.58</td>\n",
       "      <td>34507.30</td>\n",
       "      <td>34507.39</td>\n",
       "      <td>14.284419</td>\n",
       "      <td>1.0552</td>\n",
       "      <td>1.05530</td>\n",
       "      <td>1.05465</td>\n",
       "      <td>1.05465</td>\n",
       "      <td>...</td>\n",
       "      <td>104.843750</td>\n",
       "      <td>104.851562</td>\n",
       "      <td>104.828125</td>\n",
       "      <td>104.835938</td>\n",
       "      <td>6235.0</td>\n",
       "      <td>106.718750</td>\n",
       "      <td>106.734375</td>\n",
       "      <td>106.703125</td>\n",
       "      <td>106.703125</td>\n",
       "      <td>4672.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-11-01 18:16:00</td>\n",
       "      <td>34507.49</td>\n",
       "      <td>34525.83</td>\n",
       "      <td>34486.81</td>\n",
       "      <td>34522.14</td>\n",
       "      <td>7.825300</td>\n",
       "      <td>1.0546</td>\n",
       "      <td>1.05505</td>\n",
       "      <td>1.05445</td>\n",
       "      <td>1.05505</td>\n",
       "      <td>...</td>\n",
       "      <td>104.835938</td>\n",
       "      <td>104.859375</td>\n",
       "      <td>104.835938</td>\n",
       "      <td>104.851562</td>\n",
       "      <td>2477.0</td>\n",
       "      <td>106.703125</td>\n",
       "      <td>106.734375</td>\n",
       "      <td>106.687500</td>\n",
       "      <td>106.734375</td>\n",
       "      <td>2382.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-11-01 18:17:00</td>\n",
       "      <td>34522.14</td>\n",
       "      <td>34530.14</td>\n",
       "      <td>34500.18</td>\n",
       "      <td>34526.96</td>\n",
       "      <td>7.512638</td>\n",
       "      <td>1.0550</td>\n",
       "      <td>1.05525</td>\n",
       "      <td>1.05490</td>\n",
       "      <td>1.05515</td>\n",
       "      <td>...</td>\n",
       "      <td>104.851562</td>\n",
       "      <td>104.867188</td>\n",
       "      <td>104.843750</td>\n",
       "      <td>104.851562</td>\n",
       "      <td>3767.0</td>\n",
       "      <td>106.734375</td>\n",
       "      <td>106.750000</td>\n",
       "      <td>106.734375</td>\n",
       "      <td>106.750000</td>\n",
       "      <td>2937.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-11-01 18:18:00</td>\n",
       "      <td>34526.20</td>\n",
       "      <td>34545.63</td>\n",
       "      <td>34525.18</td>\n",
       "      <td>34540.48</td>\n",
       "      <td>13.100650</td>\n",
       "      <td>1.0551</td>\n",
       "      <td>1.05535</td>\n",
       "      <td>1.05510</td>\n",
       "      <td>1.05530</td>\n",
       "      <td>...</td>\n",
       "      <td>104.851562</td>\n",
       "      <td>104.859375</td>\n",
       "      <td>104.851562</td>\n",
       "      <td>104.851562</td>\n",
       "      <td>1634.0</td>\n",
       "      <td>106.734375</td>\n",
       "      <td>106.750000</td>\n",
       "      <td>106.734375</td>\n",
       "      <td>106.734375</td>\n",
       "      <td>962.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime  btc_open  btc_high   btc_low  btc_close  btc_volume  \\\n",
       "0 2023-11-01 18:14:00  34553.59  34565.88  34546.16   34549.35    6.687855   \n",
       "1 2023-11-01 18:15:00  34549.33  34552.58  34507.30   34507.39   14.284419   \n",
       "2 2023-11-01 18:16:00  34507.49  34525.83  34486.81   34522.14    7.825300   \n",
       "3 2023-11-01 18:17:00  34522.14  34530.14  34500.18   34526.96    7.512638   \n",
       "4 2023-11-01 18:18:00  34526.20  34545.63  34525.18   34540.48   13.100650   \n",
       "\n",
       "   6e_open  6e_high   6e_low  6e_close  ...     zf_open     zf_high  \\\n",
       "0   1.0557  1.05570  1.05515   1.05520  ...  104.867188  104.867188   \n",
       "1   1.0552  1.05530  1.05465   1.05465  ...  104.843750  104.851562   \n",
       "2   1.0546  1.05505  1.05445   1.05505  ...  104.835938  104.859375   \n",
       "3   1.0550  1.05525  1.05490   1.05515  ...  104.851562  104.867188   \n",
       "4   1.0551  1.05535  1.05510   1.05530  ...  104.851562  104.859375   \n",
       "\n",
       "       zf_low    zf_close  zf_volume     zn_open     zn_high      zn_low  \\\n",
       "0  104.843750  104.843750     1640.0  106.750000  106.765625  106.703125   \n",
       "1  104.828125  104.835938     6235.0  106.718750  106.734375  106.703125   \n",
       "2  104.835938  104.851562     2477.0  106.703125  106.734375  106.687500   \n",
       "3  104.843750  104.851562     3767.0  106.734375  106.750000  106.734375   \n",
       "4  104.851562  104.851562     1634.0  106.734375  106.750000  106.734375   \n",
       "\n",
       "     zn_close  zn_volume  \n",
       "0  106.703125     2238.0  \n",
       "1  106.703125     4672.0  \n",
       "2  106.734375     2382.0  \n",
       "3  106.750000     2937.0  \n",
       "4  106.734375      962.0  \n",
       "\n",
       "[5 rows x 131 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "df = pd.read_csv(Path(r'C:/\\Users/\\vchar/\\OneDrive/\\Desktop/\\ML Projects/\\Upwork/\\AlgoT_ML_Dev/\\GrammarEvolution/\\PonyGE2/\\all_data_1min_all.csv'))\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "df.sort_values('datetime', ascending=True, inplace=True)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50400, 131)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[252000: (252000+50400)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[252000: (252000+50400)].to_csv(\"all_data_1min.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(414836, 1327)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 1_327)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>datetime</th><th>btc_open</th><th>btc_high</th><th>btc_low</th><th>btc_close</th><th>btc_volume</th><th>6e_open</th><th>6e_high</th><th>6e_low</th><th>6e_close</th><th>6e_volume</th><th>aapl_open</th><th>aapl_high</th><th>aapl_low</th><th>aapl_close</th><th>aapl_volume</th><th>aav_open</th><th>aav_high</th><th>aav_low</th><th>aav_close</th><th>aav_volume</th><th>amzn_open</th><th>amzn_high</th><th>amzn_low</th><th>amzn_close</th><th>amzn_volume</th><th>cl_open</th><th>cl_high</th><th>cl_low</th><th>cl_close</th><th>cl_volume</th><th>coin_open</th><th>coin_high</th><th>coin_low</th><th>coin_close</th><th>coin_volume</th><th>dog_open</th><th>&hellip;</th><th>zn_rstd_2h</th><th>zn_rvolume_2h</th><th>zn_rmean_4h</th><th>zn_rmax_4h</th><th>zn_rmin_4h</th><th>zn_rstd_4h</th><th>zn_rvolume_4h</th><th>zn_rmean_1h</th><th>zn_rmax_1h</th><th>zn_rmin_1h</th><th>zn_rstd_1h</th><th>zn_rvolume_1h</th><th>zn_high_1d_ago</th><th>zn_high_3d_ago</th><th>zn_high_5d_ago</th><th>zn_low_1d_ago</th><th>zn_low_3d_ago</th><th>zn_low_5d_ago</th><th>zn_open_1d_ago</th><th>zn_open_3d_ago</th><th>zn_open_5d_ago</th><th>zn_close_1d_ago</th><th>zn_close_3d_ago</th><th>zn_close_5d_ago</th><th>zn_volume_1d_ago</th><th>zn_volume_3d_ago</th><th>zn_volume_5d_ago</th><th>zn_high_1w_ago</th><th>zn_low_1w_ago</th><th>zn_open_1w_ago</th><th>zn_close_1w_ago</th><th>zn_volume_1w_ago</th><th>zn_high_1m_ago</th><th>zn_low_1m_ago</th><th>zn_open_1m_ago</th><th>zn_close_1m_ago</th><th>zn_volume_1m_ago</th></tr><tr><td>datetime[s]</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>&hellip;</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>2023-12-01 00:02:00</td><td>37725.87</td><td>37725.87</td><td>37700.0</td><td>37700.9</td><td>8.4220985</td><td>1.09</td><td>1.0901</td><td>1.08995</td><td>1.0901</td><td>6.0</td><td>190.06</td><td>190.06</td><td>190.06</td><td>190.06</td><td>1.0</td><td>98.2</td><td>98.2</td><td>98.09</td><td>98.13</td><td>11.696</td><td>145.93</td><td>145.93</td><td>145.92</td><td>145.92</td><td>280.0</td><td>75.78</td><td>75.78</td><td>75.78</td><td>75.78</td><td>2.0</td><td>124.18</td><td>124.18</td><td>124.18</td><td>124.18</td><td>4.0</td><td>0.08339</td><td>&hellip;</td><td>0.060134</td><td>530.0</td><td>109.58112</td><td>110.03125</td><td>109.390625</td><td>0.100762</td><td>4024.0</td><td>109.683594</td><td>110.03125</td><td>109.609375</td><td>0.07422</td><td>466.0</td><td>110.09375</td><td>109.65625</td><td>108.484375</td><td>109.390625</td><td>108.796875</td><td>108.3125</td><td>109.984375</td><td>108.921875</td><td>108.453125</td><td>109.671875</td><td>109.625</td><td>108.328125</td><td>56253.0</td><td>1.142538e6</td><td>4.682008e6</td><td>109.265625</td><td>108.3125</td><td>108.65625</td><td>108.328125</td><td>1.6199495e7</td><td>110.125</td><td>106.578125</td><td>106.75</td><td>109.671875</td><td>6.1111728e7</td></tr><tr><td>2023-12-01 00:03:00</td><td>37700.87</td><td>37708.29</td><td>37700.87</td><td>37704.84</td><td>5.054187</td><td>1.09005</td><td>1.0901</td><td>1.09005</td><td>1.09005</td><td>54.0</td><td>190.06</td><td>190.06</td><td>190.06</td><td>190.06</td><td>1.0</td><td>98.1</td><td>98.14</td><td>98.1</td><td>98.13</td><td>12.509</td><td>145.93</td><td>145.93</td><td>145.92</td><td>145.92</td><td>280.0</td><td>75.77</td><td>75.79</td><td>75.77</td><td>75.78</td><td>3.0</td><td>124.18</td><td>124.18</td><td>124.18</td><td>124.18</td><td>4.0</td><td>0.08345</td><td>&hellip;</td><td>0.068535</td><td>808.0</td><td>109.583333</td><td>110.03125</td><td>109.390625</td><td>0.104397</td><td>4229.0</td><td>109.690365</td><td>110.03125</td><td>109.609375</td><td>0.085072</td><td>742.0</td><td>110.09375</td><td>109.65625</td><td>108.484375</td><td>109.390625</td><td>108.796875</td><td>108.3125</td><td>109.984375</td><td>108.921875</td><td>108.453125</td><td>109.671875</td><td>109.625</td><td>108.328125</td><td>56253.0</td><td>1.142538e6</td><td>4.682008e6</td><td>109.265625</td><td>108.3125</td><td>108.65625</td><td>108.328125</td><td>1.6199495e7</td><td>110.125</td><td>106.578125</td><td>106.75</td><td>109.671875</td><td>6.1111728e7</td></tr><tr><td>2023-12-01 00:04:00</td><td>37704.84</td><td>37704.85</td><td>37689.5</td><td>37694.05</td><td>8.9862729</td><td>1.09005</td><td>1.0901</td><td>1.09005</td><td>1.0901</td><td>75.0</td><td>190.06</td><td>190.06</td><td>190.06</td><td>190.06</td><td>1.0</td><td>98.14</td><td>98.14</td><td>98.09</td><td>98.09</td><td>16.145</td><td>145.93</td><td>145.93</td><td>145.92</td><td>145.92</td><td>280.0</td><td>75.78</td><td>75.79</td><td>75.78</td><td>75.79</td><td>11.0</td><td>124.18</td><td>124.18</td><td>124.18</td><td>124.18</td><td>4.0</td><td>0.08352</td><td>&hellip;</td><td>0.077144</td><td>2398.0</td><td>109.585547</td><td>110.046875</td><td>109.390625</td><td>0.108507</td><td>5756.0</td><td>109.697656</td><td>110.046875</td><td>109.609375</td><td>0.096053</td><td>2330.0</td><td>110.09375</td><td>109.65625</td><td>108.484375</td><td>109.390625</td><td>108.796875</td><td>108.3125</td><td>109.984375</td><td>108.921875</td><td>108.453125</td><td>109.671875</td><td>109.625</td><td>108.328125</td><td>56253.0</td><td>1.142538e6</td><td>4.682008e6</td><td>109.265625</td><td>108.3125</td><td>108.65625</td><td>108.328125</td><td>1.6199495e7</td><td>110.125</td><td>106.578125</td><td>106.75</td><td>109.671875</td><td>6.1111728e7</td></tr><tr><td>2023-12-01 00:05:00</td><td>37694.05</td><td>37708.74</td><td>37690.87</td><td>37704.13</td><td>17.602861</td><td>1.09015</td><td>1.09025</td><td>1.0901</td><td>1.09025</td><td>83.0</td><td>190.06</td><td>190.06</td><td>190.06</td><td>190.06</td><td>1.0</td><td>98.11</td><td>98.3</td><td>98.11</td><td>98.3</td><td>16.545</td><td>145.93</td><td>145.93</td><td>145.92</td><td>145.92</td><td>280.0</td><td>75.81</td><td>75.81</td><td>75.8</td><td>75.8</td><td>5.0</td><td>124.18</td><td>124.18</td><td>124.18</td><td>124.18</td><td>4.0</td><td>0.08354</td><td>&hellip;</td><td>0.084738</td><td>2400.0</td><td>109.58776</td><td>110.0625</td><td>109.390625</td><td>0.112423</td><td>5707.0</td><td>109.704948</td><td>110.0625</td><td>109.609375</td><td>0.10539</td><td>2330.0</td><td>110.09375</td><td>109.65625</td><td>108.484375</td><td>109.390625</td><td>108.796875</td><td>108.3125</td><td>109.984375</td><td>108.921875</td><td>108.453125</td><td>109.671875</td><td>109.625</td><td>108.328125</td><td>56253.0</td><td>1.142538e6</td><td>4.682008e6</td><td>109.265625</td><td>108.3125</td><td>108.65625</td><td>108.328125</td><td>1.6199495e7</td><td>110.125</td><td>106.578125</td><td>106.75</td><td>109.671875</td><td>6.1111728e7</td></tr><tr><td>2023-12-01 00:06:00</td><td>37704.13</td><td>37708.19</td><td>37704.12</td><td>37707.02</td><td>1.737424</td><td>1.0902</td><td>1.0902</td><td>1.09015</td><td>1.0902</td><td>10.0</td><td>190.06</td><td>190.06</td><td>190.06</td><td>190.06</td><td>1.0</td><td>98.11</td><td>98.3</td><td>98.11</td><td>98.3</td><td>16.545</td><td>145.93</td><td>145.93</td><td>145.92</td><td>145.92</td><td>280.0</td><td>75.82</td><td>75.82</td><td>75.82</td><td>75.82</td><td>5.0</td><td>124.18</td><td>124.18</td><td>124.18</td><td>124.18</td><td>4.0</td><td>0.08353</td><td>&hellip;</td><td>0.092694</td><td>2983.0</td><td>109.590104</td><td>110.078125</td><td>109.390625</td><td>0.116695</td><td>6239.0</td><td>109.71276</td><td>110.078125</td><td>109.609375</td><td>0.115111</td><td>2911.0</td><td>110.09375</td><td>109.65625</td><td>108.484375</td><td>109.390625</td><td>108.796875</td><td>108.3125</td><td>109.984375</td><td>108.921875</td><td>108.453125</td><td>109.671875</td><td>109.625</td><td>108.328125</td><td>56253.0</td><td>1.142538e6</td><td>4.682008e6</td><td>109.265625</td><td>108.3125</td><td>108.65625</td><td>108.328125</td><td>1.6199495e7</td><td>110.125</td><td>106.578125</td><td>106.75</td><td>109.671875</td><td>6.1111728e7</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 1_327)\n",
       "\n",
       " datetime    btc_open  btc_high  btc_low     zn_low_1m_  zn_open_1  zn_close_  zn_volume \n",
       " ---         ---       ---       ---          ago         m_ago      1m_ago     _1m_ago   \n",
       " datetime[  f64       f64       f64          ---         ---        ---        ---       \n",
       " s]                                           f64         f64        f64        f64       \n",
       "\n",
       " 2023-12-01  37725.87  37725.87  37700.0     106.578125  106.75     109.67187  6.1111728 \n",
       " 00:02:00                                                            5          e7        \n",
       " 2023-12-01  37700.87  37708.29  37700.87    106.578125  106.75     109.67187  6.1111728 \n",
       " 00:03:00                                                            5          e7        \n",
       " 2023-12-01  37704.84  37704.85  37689.5     106.578125  106.75     109.67187  6.1111728 \n",
       " 00:04:00                                                            5          e7        \n",
       " 2023-12-01  37694.05  37708.74  37690.87    106.578125  106.75     109.67187  6.1111728 \n",
       " 00:05:00                                                            5          e7        \n",
       " 2023-12-01  37704.13  37708.19  37704.12    106.578125  106.75     109.67187  6.1111728 \n",
       " 00:06:00                                                            5          e7        \n",
       ""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "from pathlib import Path\n",
    "\n",
    "df_pl = pl.read_csv(Path(r'/\\Users/\\vchar/\\OneDrive/\\Desktop/\\ML Projects/\\Upwork/\\AlgoT_ML_Dev/\\GrammarEvolution/\\PonyGE2/\\all_data_1min.csv'))\n",
    "df_pl = df_pl.with_columns(pl.col('datetime').str.to_datetime())\n",
    "df_pl = df_pl.sort('datetime', descending=False)\n",
    "df_pl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>btc_open</th>\n",
       "      <th>btc_high</th>\n",
       "      <th>btc_low</th>\n",
       "      <th>btc_close</th>\n",
       "      <th>btc_volume</th>\n",
       "      <th>6e_open</th>\n",
       "      <th>6e_high</th>\n",
       "      <th>6e_low</th>\n",
       "      <th>6e_close</th>\n",
       "      <th>...</th>\n",
       "      <th>zn_high_1w_ago</th>\n",
       "      <th>zn_low_1w_ago</th>\n",
       "      <th>zn_open_1w_ago</th>\n",
       "      <th>zn_close_1w_ago</th>\n",
       "      <th>zn_volume_1w_ago</th>\n",
       "      <th>zn_high_1m_ago</th>\n",
       "      <th>zn_low_1m_ago</th>\n",
       "      <th>zn_open_1m_ago</th>\n",
       "      <th>zn_close_1m_ago</th>\n",
       "      <th>zn_volume_1m_ago</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-09-14 11:30:00</td>\n",
       "      <td>59815.61</td>\n",
       "      <td>59825.88</td>\n",
       "      <td>59805.44</td>\n",
       "      <td>59813.19</td>\n",
       "      <td>0.866345</td>\n",
       "      <td>1.11185</td>\n",
       "      <td>1.11185</td>\n",
       "      <td>1.11175</td>\n",
       "      <td>1.11185</td>\n",
       "      <td>...</td>\n",
       "      <td>115.40625</td>\n",
       "      <td>113.375</td>\n",
       "      <td>113.578125</td>\n",
       "      <td>114.84375</td>\n",
       "      <td>14427365.0</td>\n",
       "      <td>115.109375</td>\n",
       "      <td>112.046875</td>\n",
       "      <td>112.125</td>\n",
       "      <td>113.09375</td>\n",
       "      <td>77381257.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-09-14 11:31:00</td>\n",
       "      <td>59811.70</td>\n",
       "      <td>59827.60</td>\n",
       "      <td>59805.43</td>\n",
       "      <td>59827.18</td>\n",
       "      <td>2.052995</td>\n",
       "      <td>1.11185</td>\n",
       "      <td>1.11185</td>\n",
       "      <td>1.11175</td>\n",
       "      <td>1.11185</td>\n",
       "      <td>...</td>\n",
       "      <td>115.40625</td>\n",
       "      <td>113.375</td>\n",
       "      <td>113.578125</td>\n",
       "      <td>114.84375</td>\n",
       "      <td>14427365.0</td>\n",
       "      <td>115.109375</td>\n",
       "      <td>112.046875</td>\n",
       "      <td>112.125</td>\n",
       "      <td>113.09375</td>\n",
       "      <td>77381257.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-09-14 11:32:00</td>\n",
       "      <td>59827.17</td>\n",
       "      <td>59833.78</td>\n",
       "      <td>59824.37</td>\n",
       "      <td>59831.64</td>\n",
       "      <td>1.489819</td>\n",
       "      <td>1.11185</td>\n",
       "      <td>1.11185</td>\n",
       "      <td>1.11175</td>\n",
       "      <td>1.11185</td>\n",
       "      <td>...</td>\n",
       "      <td>115.40625</td>\n",
       "      <td>113.375</td>\n",
       "      <td>113.578125</td>\n",
       "      <td>114.84375</td>\n",
       "      <td>14427365.0</td>\n",
       "      <td>115.109375</td>\n",
       "      <td>112.046875</td>\n",
       "      <td>112.125</td>\n",
       "      <td>113.09375</td>\n",
       "      <td>77381257.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-09-14 11:33:00</td>\n",
       "      <td>59831.64</td>\n",
       "      <td>59836.10</td>\n",
       "      <td>59831.64</td>\n",
       "      <td>59836.10</td>\n",
       "      <td>0.078481</td>\n",
       "      <td>1.11185</td>\n",
       "      <td>1.11185</td>\n",
       "      <td>1.11175</td>\n",
       "      <td>1.11185</td>\n",
       "      <td>...</td>\n",
       "      <td>115.40625</td>\n",
       "      <td>113.375</td>\n",
       "      <td>113.578125</td>\n",
       "      <td>114.84375</td>\n",
       "      <td>14427365.0</td>\n",
       "      <td>115.109375</td>\n",
       "      <td>112.046875</td>\n",
       "      <td>112.125</td>\n",
       "      <td>113.09375</td>\n",
       "      <td>77381257.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows  1327 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime  btc_open  btc_high   btc_low  btc_close  btc_volume  \\\n",
       "0 2024-09-14 11:30:00  59815.61  59825.88  59805.44   59813.19    0.866345   \n",
       "1 2024-09-14 11:31:00  59811.70  59827.60  59805.43   59827.18    2.052995   \n",
       "2 2024-09-14 11:32:00  59827.17  59833.78  59824.37   59831.64    1.489819   \n",
       "3 2024-09-14 11:33:00  59831.64  59836.10  59831.64   59836.10    0.078481   \n",
       "\n",
       "   6e_open  6e_high   6e_low  6e_close  ...  zn_high_1w_ago  zn_low_1w_ago  \\\n",
       "0  1.11185  1.11185  1.11175   1.11185  ...       115.40625        113.375   \n",
       "1  1.11185  1.11185  1.11175   1.11185  ...       115.40625        113.375   \n",
       "2  1.11185  1.11185  1.11175   1.11185  ...       115.40625        113.375   \n",
       "3  1.11185  1.11185  1.11175   1.11185  ...       115.40625        113.375   \n",
       "\n",
       "   zn_open_1w_ago  zn_close_1w_ago  zn_volume_1w_ago  zn_high_1m_ago  \\\n",
       "0      113.578125        114.84375        14427365.0      115.109375   \n",
       "1      113.578125        114.84375        14427365.0      115.109375   \n",
       "2      113.578125        114.84375        14427365.0      115.109375   \n",
       "3      113.578125        114.84375        14427365.0      115.109375   \n",
       "\n",
       "   zn_low_1m_ago  zn_open_1m_ago  zn_close_1m_ago  zn_volume_1m_ago  \n",
       "0     112.046875         112.125        113.09375        77381257.0  \n",
       "1     112.046875         112.125        113.09375        77381257.0  \n",
       "2     112.046875         112.125        113.09375        77381257.0  \n",
       "3     112.046875         112.125        113.09375        77381257.0  \n",
       "\n",
       "[4 rows x 1327 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pl.slice(-4).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# # set crossover probability.\n",
      "# 'crossover_probability': 0.75,\n",
      "# # prevents crossover from generating invalids.\n",
      "# 'no_crossover_invalids': false,\n",
      "\n",
      "# # set mutation probability (none defaults to 1 over the length of\n",
      "# # the genome for each codon)\n",
      "# 'mutation_probability': none,\n",
      "# # set number of mutation events\n",
      "# 'mutation_events': 1,\n",
      "# # prevents mutation from generating invalids.\n",
      "# 'no_mutation_invalids': false,\n",
      "\n",
      "# # set elite size.\n",
      "# 'elite_size': none,\n",
      "\n",
      "# # agent size. number of agents having their own copy of genetic material\n",
      "# 'agent_size': 100,\n",
      "# # interaction probability: how frequently the agents can interaction with\n",
      "# # each other\n",
      "# 'interaction_probability': 0.5\n"
     ]
    }
   ],
   "source": [
    "text = '''# # Set crossover probability.\n",
    "# 'CROSSOVER_PROBABILITY': 0.75,\n",
    "# # Prevents crossover from generating invalids.\n",
    "# 'NO_CROSSOVER_INVALIDS': False,\n",
    "\n",
    "# # Set mutation probability (None defaults to 1 over the length of\n",
    "# # the genome for each codon)\n",
    "# 'MUTATION_PROBABILITY': None,\n",
    "# # Set number of mutation events\n",
    "# 'MUTATION_EVENTS': 1,\n",
    "# # Prevents mutation from generating invalids.\n",
    "# 'NO_MUTATION_INVALIDS': False,\n",
    "\n",
    "# # Set elite size.\n",
    "# 'ELITE_SIZE': None,\n",
    "\n",
    "# # Agent Size. Number of agents having their own copy of genetic material\n",
    "# 'AGENT_SIZE': 100,\n",
    "# # Interaction Probability: how frequently the agents can interaction with\n",
    "# # each other\n",
    "# 'INTERACTION_PROBABILITY': 0.5'''\n",
    "\n",
    "print(text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50400, 100800, 151200, 252000, 302400, 352800, 403200, 453600, 414836)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7 * 60 * 24 * 5, 7 * 60 * 24 * 10, 7 * 60 * 24 * 15, 7 * 60 * 24 * 25, 7 * 60 * 24 * 30, 7 * 60 * 24 * 35, 7 * 60 * 24 * 40, 7 * 60 * 24 * 45, 414836"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "252000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7 * 60 * 24 * 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(Path(r'C:/\\Users/\\vchar/\\OneDrive/\\Desktop/\\ML Projects/\\Upwork/\\AlgoT_ML_Dev/\\GrammarEvolution/\\PonyGE2/\\all_data_1min.csv'))\n",
    "# df = pd.read_csv('/kaggle/input/btcusd-test/BTCUSD_ohlcv.csv')\n",
    "# df = pd.read_csv('/kaggle/input/btcusd-test/BTC-ETH-1m.csv')\n",
    "# df = pd.read_csv('/kaggle/input/btcusd-test/all_data_1min.csv')\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "# df = df.iloc[-10080:]\n",
    "# df = df.iloc[-525600:]\n",
    "# df = df.iloc[252000: (252000+50400)]\n",
    "df.sort_values('datetime', ascending=True, inplace=True)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "price_data = {}\n",
    "# price_data['open'] = df['open'].values\n",
    "# price_data['close'] = df['close'].values\n",
    "# price_data['high'] = df['high'].values\n",
    "# price_data['low'] = df['low'].values\n",
    "# price_data['volume'] = df['volume'].values\n",
    "for col in df.columns:\n",
    "    if col == 'datetime':\n",
    "        continue\n",
    "    else:\n",
    "        price_data[col] = df[col].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(457520, 131)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50400"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7 * 24 * 60 * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>btc_open</th>\n",
       "      <th>btc_high</th>\n",
       "      <th>btc_low</th>\n",
       "      <th>btc_close</th>\n",
       "      <th>btc_volume</th>\n",
       "      <th>6e_open</th>\n",
       "      <th>6e_high</th>\n",
       "      <th>6e_low</th>\n",
       "      <th>6e_close</th>\n",
       "      <th>...</th>\n",
       "      <th>zf_open</th>\n",
       "      <th>zf_high</th>\n",
       "      <th>zf_low</th>\n",
       "      <th>zf_close</th>\n",
       "      <th>zf_volume</th>\n",
       "      <th>zn_open</th>\n",
       "      <th>zn_high</th>\n",
       "      <th>zn_low</th>\n",
       "      <th>zn_close</th>\n",
       "      <th>zn_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6106</th>\n",
       "      <td>2023-11-06 00:00:00</td>\n",
       "      <td>35035.79</td>\n",
       "      <td>35042.11</td>\n",
       "      <td>35009.03</td>\n",
       "      <td>35015.86</td>\n",
       "      <td>7.140489</td>\n",
       "      <td>1.07500</td>\n",
       "      <td>1.07505</td>\n",
       "      <td>1.07480</td>\n",
       "      <td>1.07480</td>\n",
       "      <td>...</td>\n",
       "      <td>105.648438</td>\n",
       "      <td>105.671875</td>\n",
       "      <td>105.648438</td>\n",
       "      <td>105.664062</td>\n",
       "      <td>484.0</td>\n",
       "      <td>108.140625</td>\n",
       "      <td>108.156250</td>\n",
       "      <td>108.140625</td>\n",
       "      <td>108.156250</td>\n",
       "      <td>405.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6107</th>\n",
       "      <td>2023-11-06 00:01:00</td>\n",
       "      <td>35012.72</td>\n",
       "      <td>35012.72</td>\n",
       "      <td>34980.90</td>\n",
       "      <td>34985.74</td>\n",
       "      <td>11.882682</td>\n",
       "      <td>1.07475</td>\n",
       "      <td>1.07475</td>\n",
       "      <td>1.07465</td>\n",
       "      <td>1.07465</td>\n",
       "      <td>...</td>\n",
       "      <td>105.664062</td>\n",
       "      <td>105.664062</td>\n",
       "      <td>105.656250</td>\n",
       "      <td>105.664062</td>\n",
       "      <td>62.0</td>\n",
       "      <td>108.156250</td>\n",
       "      <td>108.156250</td>\n",
       "      <td>108.156250</td>\n",
       "      <td>108.156250</td>\n",
       "      <td>509.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6108</th>\n",
       "      <td>2023-11-06 00:02:00</td>\n",
       "      <td>34984.82</td>\n",
       "      <td>35005.84</td>\n",
       "      <td>34950.98</td>\n",
       "      <td>34971.55</td>\n",
       "      <td>20.170384</td>\n",
       "      <td>1.07470</td>\n",
       "      <td>1.07485</td>\n",
       "      <td>1.07470</td>\n",
       "      <td>1.07485</td>\n",
       "      <td>...</td>\n",
       "      <td>105.664062</td>\n",
       "      <td>105.664062</td>\n",
       "      <td>105.656250</td>\n",
       "      <td>105.664062</td>\n",
       "      <td>143.0</td>\n",
       "      <td>108.156250</td>\n",
       "      <td>108.171875</td>\n",
       "      <td>108.156250</td>\n",
       "      <td>108.156250</td>\n",
       "      <td>1315.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6109</th>\n",
       "      <td>2023-11-06 00:03:00</td>\n",
       "      <td>34969.70</td>\n",
       "      <td>34997.71</td>\n",
       "      <td>34961.29</td>\n",
       "      <td>34962.50</td>\n",
       "      <td>4.791926</td>\n",
       "      <td>1.07485</td>\n",
       "      <td>1.07485</td>\n",
       "      <td>1.07470</td>\n",
       "      <td>1.07470</td>\n",
       "      <td>...</td>\n",
       "      <td>105.664062</td>\n",
       "      <td>105.664062</td>\n",
       "      <td>105.648438</td>\n",
       "      <td>105.648438</td>\n",
       "      <td>201.0</td>\n",
       "      <td>108.156250</td>\n",
       "      <td>108.156250</td>\n",
       "      <td>108.140625</td>\n",
       "      <td>108.140625</td>\n",
       "      <td>358.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6110</th>\n",
       "      <td>2023-11-06 00:04:00</td>\n",
       "      <td>34959.86</td>\n",
       "      <td>34986.90</td>\n",
       "      <td>34954.00</td>\n",
       "      <td>34983.92</td>\n",
       "      <td>11.766786</td>\n",
       "      <td>1.07465</td>\n",
       "      <td>1.07465</td>\n",
       "      <td>1.07450</td>\n",
       "      <td>1.07450</td>\n",
       "      <td>...</td>\n",
       "      <td>105.648438</td>\n",
       "      <td>105.648438</td>\n",
       "      <td>105.640625</td>\n",
       "      <td>105.640625</td>\n",
       "      <td>1060.0</td>\n",
       "      <td>108.140625</td>\n",
       "      <td>108.140625</td>\n",
       "      <td>108.125000</td>\n",
       "      <td>108.140625</td>\n",
       "      <td>1136.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                datetime  btc_open  btc_high   btc_low  btc_close  btc_volume  \\\n",
       "6106 2023-11-06 00:00:00  35035.79  35042.11  35009.03   35015.86    7.140489   \n",
       "6107 2023-11-06 00:01:00  35012.72  35012.72  34980.90   34985.74   11.882682   \n",
       "6108 2023-11-06 00:02:00  34984.82  35005.84  34950.98   34971.55   20.170384   \n",
       "6109 2023-11-06 00:03:00  34969.70  34997.71  34961.29   34962.50    4.791926   \n",
       "6110 2023-11-06 00:04:00  34959.86  34986.90  34954.00   34983.92   11.766786   \n",
       "\n",
       "      6e_open  6e_high   6e_low  6e_close  ...     zf_open     zf_high  \\\n",
       "6106  1.07500  1.07505  1.07480   1.07480  ...  105.648438  105.671875   \n",
       "6107  1.07475  1.07475  1.07465   1.07465  ...  105.664062  105.664062   \n",
       "6108  1.07470  1.07485  1.07470   1.07485  ...  105.664062  105.664062   \n",
       "6109  1.07485  1.07485  1.07470   1.07470  ...  105.664062  105.664062   \n",
       "6110  1.07465  1.07465  1.07450   1.07450  ...  105.648438  105.648438   \n",
       "\n",
       "          zf_low    zf_close  zf_volume     zn_open     zn_high      zn_low  \\\n",
       "6106  105.648438  105.664062      484.0  108.140625  108.156250  108.140625   \n",
       "6107  105.656250  105.664062       62.0  108.156250  108.156250  108.156250   \n",
       "6108  105.656250  105.664062      143.0  108.156250  108.171875  108.156250   \n",
       "6109  105.648438  105.648438      201.0  108.156250  108.156250  108.140625   \n",
       "6110  105.640625  105.640625     1060.0  108.140625  108.140625  108.125000   \n",
       "\n",
       "        zn_close  zn_volume  \n",
       "6106  108.156250      405.0  \n",
       "6107  108.156250      509.0  \n",
       "6108  108.156250     1315.0  \n",
       "6109  108.140625      358.0  \n",
       "6110  108.140625     1136.0  \n",
       "\n",
       "[5 rows x 131 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['datetime'].dt.dayofweek == 0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-07-20 21:37:00</td>\n",
       "      <td>277.98</td>\n",
       "      <td>277.98</td>\n",
       "      <td>277.97</td>\n",
       "      <td>277.97</td>\n",
       "      <td>0.791300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-07-20 21:38:00</td>\n",
       "      <td>277.98</td>\n",
       "      <td>277.99</td>\n",
       "      <td>277.98</td>\n",
       "      <td>277.99</td>\n",
       "      <td>0.560600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-07-20 21:39:00</td>\n",
       "      <td>277.97</td>\n",
       "      <td>277.97</td>\n",
       "      <td>277.97</td>\n",
       "      <td>277.97</td>\n",
       "      <td>0.149600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-07-20 21:40:00</td>\n",
       "      <td>277.98</td>\n",
       "      <td>277.99</td>\n",
       "      <td>277.98</td>\n",
       "      <td>277.99</td>\n",
       "      <td>1.216800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-07-20 21:41:00</td>\n",
       "      <td>277.99</td>\n",
       "      <td>277.99</td>\n",
       "      <td>277.99</td>\n",
       "      <td>277.99</td>\n",
       "      <td>2.704924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime    open    high     low   close    volume\n",
       "0 2015-07-20 21:37:00  277.98  277.98  277.97  277.97  0.791300\n",
       "1 2015-07-20 21:38:00  277.98  277.99  277.98  277.99  0.560600\n",
       "2 2015-07-20 21:39:00  277.97  277.97  277.97  277.97  0.149600\n",
       "3 2015-07-20 21:40:00  277.98  277.99  277.98  277.99  1.216800\n",
       "4 2015-07-20 21:41:00  277.99  277.99  277.99  277.99  2.704924"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instrument_name = files_list[4].replace('-', '_').split('_')[0].lower()\n",
    "\n",
    "temp_df = pd.read_csv(os.path.join(main_path, files_list[4]))\n",
    "temp_df['datetime'] = pd.to_datetime(temp_df['datetime'])\n",
    "\n",
    "temp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(Path(r'C:/\\Users/\\vchar/\\OneDrive/\\Desktop/\\ML Projects/\\Upwork/\\AlgoT_ML_Dev/\\GrammarEvolution/\\PonyGE2/\\all_data_1min.csv'))\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "df.sort_values('datetime', ascending=True, inplace=True)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "price_data = {}\n",
    "for col in df.columns:\n",
    "    if col == 'datetime':\n",
    "        continue\n",
    "    else:\n",
    "        price_data[col] = df[col].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "buy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1728"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6 * 6 * 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 6/6 [00:00<00:00, 730.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grammar_evol",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
