{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "cur_dir = os.getcwd()\n",
    "os.chdir(Path(r'C:/\\Users/\\vchar/\\OneDrive/\\Desktop/\\ML Projects/\\Upwork/\\AlgoT_ML_Dev/\\GrammarEvolution/\\PonyGE2/\\src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start:\t 2024-10-15 07:08:03.917559 \n",
      "\n",
      "Warning: Grammar contains unit production for production rule <fc>\n",
      "         Unit productions consume GE codons.\n",
      "Warning: Grammar contains unit production for production rule <deff>\n",
      "         Unit productions consume GE codons.\n",
      "Warning: Grammar contains unit production for production rule <callf>\n",
      "         Unit productions consume GE codons.\n",
      "Evolution: 0% complete\n",
      "Evolution: 0% complete\n",
      "Evolution: 1% complete\n",
      "Evolution: 2% complete\n",
      "Evolution: 3% complete\n",
      "Evolution: 4% complete\n",
      "Evolution: 5% complete\n",
      "Evolution: 6% complete\n",
      "Evolution: 7% complete\n",
      "Evolution: 8% complete\n",
      "Evolution: 9% complete\n",
      "Evolution: 10% complete\n",
      "Evolution: 11% complete\n",
      "Evolution: 12% complete\n",
      "Evolution: 13% complete\n",
      "Evolution: 14% complete\n",
      "Evolution: 15% complete\n",
      "Evolution: 16% complete\n",
      "Evolution: 17% complete\n",
      "Evolution: 18% complete\n",
      "Evolution: 19% complete\n",
      "Evolution: 20% complete\n",
      "Evolution: 21% complete\n",
      "Evolution: 22% complete\n",
      "Evolution: 23% complete\n",
      "Evolution: 24% complete\n",
      "Evolution: 25% complete\n",
      "Evolution: 26% complete\n",
      "Evolution: 27% complete\n",
      "Evolution: 28% complete\n",
      "Evolution: 29% complete\n",
      "Evolution: 30% complete\n",
      "Evolution: 31% complete\n",
      "Evolution: 32% complete\n",
      "Evolution: 33% complete\n",
      "Evolution: 34% complete\n",
      "Evolution: 35% complete\n",
      "Evolution: 36% complete\n",
      "Evolution: 37% complete\n",
      "Evolution: 38% complete\n",
      "Evolution: 39% complete\n",
      "Evolution: 40% complete\n",
      "Evolution: 41% complete\n",
      "Evolution: 42% complete\n",
      "Evolution: 43% complete\n",
      "Evolution: 44% complete\n",
      "Evolution: 45% complete\n",
      "Evolution: 46% complete\n",
      "Evolution: 47% complete\n",
      "Evolution: 48% complete\n",
      "Evolution: 49% complete\n",
      "Evolution: 50% complete\n",
      "Evolution: 51% complete\n",
      "Evolution: 52% complete\n",
      "Evolution: 53% complete\n",
      "Evolution: 54% complete\n",
      "Evolution: 55% complete\n",
      "Evolution: 56% complete\n",
      "Evolution: 57% complete\n",
      "Evolution: 58% complete\n",
      "Evolution: 59% complete\n",
      "Evolution: 60% complete\n",
      "Evolution: 61% complete\n",
      "Evolution: 62% complete\n",
      "Evolution: 63% complete\n",
      "Evolution: 64% complete\n",
      "Evolution: 65% complete\n",
      "Evolution: 66% complete\n",
      "Evolution: 67% complete\n",
      "Evolution: 68% complete\n",
      "Evolution: 69% complete\n",
      "Evolution: 70% complete\n",
      "Evolution: 71% complete\n",
      "Evolution: 72% complete\n",
      "Evolution: 73% complete\n",
      "Evolution: 74% complete\n",
      "Evolution: 75% complete\n",
      "Evolution: 76% complete\n",
      "Evolution: 77% complete\n",
      "Evolution: 78% complete\n",
      "Evolution: 79% complete\n",
      "Evolution: 80% complete\n",
      "Evolution: 81% complete\n",
      "Evolution: 82% complete\n",
      "Evolution: 83% complete\n",
      "Evolution: 84% complete\n",
      "Evolution: 85% complete\n",
      "Evolution: 86% complete\n",
      "Evolution: 87% complete\n",
      "Evolution: 88% complete\n",
      "Evolution: 89% complete\n",
      "Evolution: 90% complete\n",
      "Evolution: 91% complete\n",
      "Evolution: 92% complete\n",
      "Evolution: 93% complete\n",
      "Evolution: 94% complete\n",
      "Evolution: 95% complete\n",
      "Evolution: 96% complete\n",
      "Evolution: 97% complete\n",
      "Evolution: 98% complete\n",
      "Evolution: 99% complete\n",
      "Evolution: 99% complete\n",
      "\n",
      "\n",
      "Best:\n",
      "  Fitness:\t -993.3135082640398\n",
      "  Phenotype: def fun(price_data):\n",
      "  import pandas as pd\n",
      "  import numpy as np\n",
      "  from fitness.indicators import numba_indicators\n",
      "  from fitness.performance.helper_func import merge_pnl, get_drawdowns, get_pnl, trading_signals, get_lag\n",
      "  from numba import njit\n",
      "  COMMISSION = 0.015\n",
      "  SLIPPAGE = 0.00005\n",
      "  AVAILABLE_CAPITAL = 700000\n",
      "  TRADE_SIZE = 0.5\n",
      "  MAX_LAG = 5\n",
      "  buy_idxs, sell_idxs = trading_signals(buy_signal=((get_lag(price_data['btc_low'], lag=5)[MAX_LAG:] - get_lag(price_data['btc_close'], lag=1)[MAX_LAG:]) / get_lag(price_data['zn_low'], lag=3)[MAX_LAG:] ** 0.80) < 0.2, sell_signal=np.sin(price_data['tsla_volume'][MAX_LAG:]) <= np.sin(numba_indicators.macd(prices=price_data['ng_close'][MAX_LAG:], short_window=53, long_window=1834, signal_window=29)[1]))\n",
      "  if len(buy_idxs) == 0 or len(sell_idxs) == 0:\n",
      "    return 999\n",
      "  buy_idxs = np.array(buy_idxs)\n",
      "  sell_idxs = np.array(sell_idxs)\n",
      "  open_prices = price_data['btc_open']\n",
      "  buy_prices = open_prices[np.isin(np.arange(len(open_prices)), buy_idxs)]\n",
      "  sell_prices = open_prices[np.isin(np.arange(len(open_prices)), sell_idxs)]\n",
      "  if buy_idxs[0] < sell_idxs[0]:\n",
      "    buy_arr = get_pnl(sell_prices, buy_prices, COMMISSION, SLIPPAGE, AVAILABLE_CAPITAL, TRADE_SIZE, 1)\n",
      "    buy_pnl = np.sum(buy_arr)\n",
      "    sell_arr = get_pnl(buy_prices[1:], sell_prices[:-1], COMMISSION, SLIPPAGE, AVAILABLE_CAPITAL, TRADE_SIZE, 0)\n",
      "    sell_pnl = np.sum(sell_arr)\n",
      "    all_arr = merge_pnl(buy_arr, sell_arr)\n",
      "  else:\n",
      "    sell_arr = get_pnl(buy_prices, sell_prices, COMMISSION, SLIPPAGE, AVAILABLE_CAPITAL, TRADE_SIZE, 0)\n",
      "    sell_pnl = np.sum(sell_arr)\n",
      "    buy_arr = get_pnl(sell_prices[1:], buy_prices[:-1], COMMISSION, SLIPPAGE, AVAILABLE_CAPITAL, TRADE_SIZE, 1)\n",
      "    buy_pnl = np.sum(buy_arr)\n",
      "    all_arr = merge_pnl(sell_arr, buy_arr)\n",
      "  total_pnl = buy_pnl + sell_pnl\n",
      "  if total_pnl <= 0:\n",
      "    return 999\n",
      "  fitness = total_pnl / (AVAILABLE_CAPITAL * TRADE_SIZE)\n",
      "  if np.isnan(fitness):\n",
      "    return 999\n",
      "  return -fitness\n",
      "fitness = fun(price_data)\n",
      "  Genome: [47983, 2694, 91475, 31829, 59022, 94796, 99392, 20436, 82330, 43233, 22281, 94702, 49125, 64682, 18622, 77551, 42160, 13857, 70177, 39064, 529, 82405, 96890, 27401, 18419, 72640, 3343, 3386, 78585, 57294, 88078, 9513, 52582, 48213, 24924, 29970, 44268, 6533, 76264, 42277, 55990, 22469, 36473, 98473, 22281, 42160, 47285, 61551, 58370, 6756, 50765, 82285, 14082, 14494, 32036, 961, 8746, 88103, 24924, 9320, 31692, 6445, 80632, 79122, 52868, 51350, 32633, 48213, 24924, 9320, 78585, 39958, 90685, 961, 79053, 18419, 91212, 50687, 78658, 83212, 78585, 39958, 33043, 89621, 39877, 7655, 84536, 60836, 31378, 9320, 78585, 88830, 36201, 7655, 94600, 34010, 53147, 3343, 26074, 28719, 52582, 46894, 77551, 42160, 13857, 9320, 78585, 39958, 61126, 46894, 22304, 24924, 9320, 54807, 961, 8746, 88103, 75409, 73146, 84588, 23782, 3203, 35041, 67425, 65524, 13169, 14880, 2755, 56852, 82661, 81446, 19140, 15602, 79335, 35752, 12020, 48658, 64139, 46852, 90825, 57057, 51596, 39433, 60335, 63647, 378, 23614, 91291, 84312, 53779, 5877, 23052, 49414, 26807, 79039, 50282, 91333, 46558, 68084, 11492, 7116, 9215, 63667, 31502, 47862, 91475, 31829, 59022, 86132, 99392, 13951, 94852, 24868, 99392, 40086, 94852, 59396, 22469, 68984, 51441, 57147, 3805, 84523, 46274, 43909, 99855, 70303, 21504, 53241, 73925, 33274, 11111, 44470, 31208, 72797, 76505, 17822, 93698, 12884, 42160, 13857, 83462, 35878, 33011, 46894, 59337, 5633, 28396, 53605, 11997, 88753, 86638, 34144, 50976, 62904, 44844, 12694, 49198, 49700, 4859, 67226, 19561, 81743, 31357, 73799, 68574, 59530, 50988, 46249, 27249, 76482, 85018, 76450, 37836, 32536, 71826, 7393, 67466, 68252, 20527, 18419, 7486, 54918, 94702, 55990, 54083, 72640, 26570, 87636, 29970, 44268, 21682, 69754, 2753, 65752, 61011, 4885, 32308, 1890, 63169, 22281, 19515, 89621, 99424, 17995, 42160, 13857, 83462, 44934, 15128, 55536, 6863, 12884, 14966, 13857, 83462, 44934, 15128, 55536, 6863, 27750, 77959, 59022, 86132, 13921, 38332, 90560, 90446, 92934, 5787, 78638, 18444, 51575, 7202, 31645, 43390, 84128, 91366, 49062, 7284, 32683, 23933, 21295, 49271, 36230, 84812, 76795, 40734, 79755, 54703, 38269, 5024, 88991, 18873, 55609, 92828, 77598, 79189, 38355, 11699, 82480, 31018, 82330, 88047, 70168, 85046, 86730, 32930, 69034, 26852, 46540, 51876, 41391, 58728, 22361, 77755, 22036, 2215, 68420, 63047, 67558, 47123, 46481, 51401, 95174, 70126, 77940, 4724, 99928, 27023, 64695, 43170, 55054, 66088, 5700, 44312, 99546]\n",
      "______\n",
      "\n",
      "  ave_fitness : \t 523.0331820617181\n",
      "  ave_genome_length : \t 285.176\n",
      "  ave_tree_depth : \t 8.518\n",
      "  ave_tree_nodes : \t 58.988\n",
      "  ave_used_codons : \t 38.72\n",
      "  best_fitness : \t -993.3135082640398\n",
      "  gen : \t 100\n",
      "  invalids : \t 513\n",
      "  max_genome_length : \t 535\n",
      "  max_tree_depth : \t 11\n",
      "  max_tree_nodes : \t 167\n",
      "  max_used_codons : \t 106\n",
      "  min_genome_length : \t 75\n",
      "  min_tree_depth : \t 6\n",
      "  min_tree_nodes : \t 22\n",
      "  min_used_codons : \t 15\n",
      "  runtime_error : \t 0\n",
      "  time_adjust : \t 0\n",
      "  time_taken : \t 398.07491540908813\n",
      "  total_inds : \t 50500\n",
      "  total_time : \t 63005.643372535706\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! python ponyge.py --fitness_function max_fitness_numba --grammar_file btc_roi_inst_ind_comb_numba.pybnf --population_size 500 --generations 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start:\t 2024-10-16 06:36:30.780661 \n",
      "\n",
      "Warning: Grammar contains unit production for production rule <fc>\n",
      "         Unit productions consume GE codons.\n",
      "Warning: Grammar contains unit production for production rule <deff>\n",
      "         Unit productions consume GE codons.\n",
      "Warning: Grammar contains unit production for production rule <callf>\n",
      "         Unit productions consume GE codons.\n",
      "No columns to parse from file\n",
      "No columns to parse from file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "multiprocessing.pool.RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vchar\\anaconda3\\envs\\grammar_evol\\lib\\multiprocessing\\pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"C:\\Users\\vchar\\OneDrive\\Desktop\\ML Projects\\Upwork\\AlgoT_ML_Dev\\GrammarEvolution\\PonyGE2\\src\\representation\\individual.py\", line 130, in evaluate\n",
      "    self.fitness = params['FITNESS_FUNCTION'](self)\n",
      "  File \"C:\\Users\\vchar\\OneDrive\\Desktop\\ML Projects\\Upwork\\AlgoT_ML_Dev\\GrammarEvolution\\PonyGE2\\src\\fitness\\base_ff_classes\\base_ff.py\", line 35, in __call__\n",
      "    fitness = self.evaluate(ind, **kwargs)\n",
      "  File \"C:\\Users\\vchar\\OneDrive\\Desktop\\ML Projects\\Upwork\\AlgoT_ML_Dev\\GrammarEvolution\\PonyGE2\\src\\fitness\\max_fitness_numba.py\", line 73, in evaluate\n",
      "    temp_df = pd.read_csv('ge_results.csv')\n",
      "  File \"c:\\Users\\vchar\\anaconda3\\envs\\grammar_evol\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"c:\\Users\\vchar\\anaconda3\\envs\\grammar_evol\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 620, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "  File \"c:\\Users\\vchar\\anaconda3\\envs\\grammar_evol\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1620, in __init__\n",
      "    self._engine = self._make_engine(f, self.engine)\n",
      "  File \"c:\\Users\\vchar\\anaconda3\\envs\\grammar_evol\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1898, in _make_engine\n",
      "    return mapping[engine](f, **self.options)\n",
      "  File \"c:\\Users\\vchar\\anaconda3\\envs\\grammar_evol\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\", line 93, in __init__\n",
      "    self._reader = parsers.TextReader(src, **kwds)\n",
      "  File \"parsers.pyx\", line 581, in pandas._libs.parsers.TextReader.__cinit__\n",
      "pandas.errors.EmptyDataError: No columns to parse from file\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vchar\\OneDrive\\Desktop\\ML Projects\\Upwork\\AlgoT_ML_Dev\\GrammarEvolution\\PonyGE2\\src\\ponyge.py\", line 31, in <module>\n",
      "    mane()\n",
      "  File \"C:\\Users\\vchar\\OneDrive\\Desktop\\ML Projects\\Upwork\\AlgoT_ML_Dev\\GrammarEvolution\\PonyGE2\\src\\ponyge.py\", line 24, in mane\n",
      "    individuals = params['SEARCH_LOOP']()\n",
      "  File \"C:\\Users\\vchar\\OneDrive\\Desktop\\ML Projects\\Upwork\\AlgoT_ML_Dev\\GrammarEvolution\\PonyGE2\\src\\algorithm\\search_loop.py\", line 29, in search_loop\n",
      "    individuals = evaluate_fitness(individuals)\n",
      "  File \"C:\\Users\\vchar\\OneDrive\\Desktop\\ML Projects\\Upwork\\AlgoT_ML_Dev\\GrammarEvolution\\PonyGE2\\src\\fitness\\evaluation.py\", line 81, in evaluate_fitness\n",
      "    ind = result.get()\n",
      "  File \"c:\\Users\\vchar\\anaconda3\\envs\\grammar_evol\\lib\\multiprocessing\\pool.py\", line 774, in get\n",
      "    raise self._value\n",
      "pandas.errors.EmptyDataError: No columns to parse from file\n"
     ]
    }
   ],
   "source": [
    "! python ponyge.py --fitness_function max_fitness_numba --grammar_file btc_roi_inst_ind_comb_numba.pybnf --population_size 500 --generations 100 --multicore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ge_results1.csv size = (54701, 3)\n",
      "ge_results2.csv size = (19778, 3)\n",
      "There is/are 2620 duplicated rows.\n",
      "(71859, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buy</th>\n",
       "      <th>sell</th>\n",
       "      <th>fitness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>np.sqrt(numba_indicators.aroon(prices=price_da...</td>\n",
       "      <td>((numba_indicators.macd(prices=price_data['goo...</td>\n",
       "      <td>404.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>np.sqrt(numba_indicators.aroon(prices=price_da...</td>\n",
       "      <td>(np.cos(get_lag(price_data['es_high'], lag=2)[...</td>\n",
       "      <td>404.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>np.sqrt(numba_indicators.moving_average(prices...</td>\n",
       "      <td>np.sin(get_lag(price_data['aapl_high'], lag=4)...</td>\n",
       "      <td>404.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(np.sqrt(numba_indicators.price_entropy(prices...</td>\n",
       "      <td>(get_lag(price_data['lin_volume'], lag=5)[MAX_...</td>\n",
       "      <td>404.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(np.sqrt(numba_indicators.n_day_low(prices=pri...</td>\n",
       "      <td>(price_data['btc_open'][MAX_LAG:] &gt;= get_lag(p...</td>\n",
       "      <td>404.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 buy  \\\n",
       "0  np.sqrt(numba_indicators.aroon(prices=price_da...   \n",
       "1  np.sqrt(numba_indicators.aroon(prices=price_da...   \n",
       "2  np.sqrt(numba_indicators.moving_average(prices...   \n",
       "3  (np.sqrt(numba_indicators.price_entropy(prices...   \n",
       "4  (np.sqrt(numba_indicators.n_day_low(prices=pri...   \n",
       "\n",
       "                                                sell  fitness  \n",
       "0  ((numba_indicators.macd(prices=price_data['goo...    404.0  \n",
       "1  (np.cos(get_lag(price_data['es_high'], lag=2)[...    404.0  \n",
       "2  np.sin(get_lag(price_data['aapl_high'], lag=4)...    404.0  \n",
       "3  (get_lag(price_data['lin_volume'], lag=5)[MAX_...    404.0  \n",
       "4  (price_data['btc_open'][MAX_LAG:] >= get_lag(p...    404.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "list_files = os.listdir()\n",
    "list_files = [file for file in list_files if file.endswith('.csv')]\n",
    "\n",
    "ge_df = pd.DataFrame()\n",
    "\n",
    "for file in list_files:\n",
    "    temp_df = pd.read_csv(file)\n",
    "    print(f\"{file} size = {temp_df.shape}\")\n",
    "    ge_df = pd.concat([ge_df, temp_df], axis=0)\n",
    "\n",
    "print(f'There is/are {ge_df.duplicated().sum()} duplicated rows.')\n",
    "\n",
    "ge_df = ge_df[~ge_df.duplicated()]\n",
    "ge_df.to_csv('ge_results_dd_inst_ind_comb_numba.csv', index=False)\n",
    "\n",
    "print(ge_df.shape)\n",
    "\n",
    "ge_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grammar_evol",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
