{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "cur_dir = os.getcwd()\n",
    "os.chdir(Path(r'C:/\\Users/\\vchar/\\OneDrive/\\Desktop/\\ML Projects/\\Upwork/\\AlgoT_ML_Dev/\\GrammarEvolution/\\PonyGE2/\\src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start:\t 2024-10-16 07:55:55.283088 \n",
      "\n",
      "Warning: Grammar contains unit production for production rule <fc>\n",
      "         Unit productions consume GE codons.\n",
      "Warning: Grammar contains unit production for production rule <deff>\n",
      "         Unit productions consume GE codons.\n",
      "Warning: Grammar contains unit production for production rule <callf>\n",
      "         Unit productions consume GE codons.\n",
      "Evolution: 0% complete\n",
      "Evolution: 0% complete\n",
      "Evolution: 1% complete\n",
      "Evolution: 2% complete\n",
      "Evolution: 3% complete\n",
      "Evolution: 4% complete\n",
      "Evolution: 5% complete\n",
      "Evolution: 6% complete\n",
      "Evolution: 7% complete\n",
      "Evolution: 8% complete\n",
      "Evolution: 9% complete\n",
      "Evolution: 10% complete\n",
      "Evolution: 11% complete\n",
      "Evolution: 12% complete\n",
      "Evolution: 13% complete\n",
      "Evolution: 14% complete\n",
      "Evolution: 15% complete\n",
      "Evolution: 16% complete\n",
      "Evolution: 17% complete\n",
      "Evolution: 18% complete\n",
      "Evolution: 19% complete\n",
      "Evolution: 20% complete\n",
      "Evolution: 21% complete\n",
      "Evolution: 22% complete\n",
      "Evolution: 23% complete\n",
      "Evolution: 24% complete\n",
      "Evolution: 25% complete\n",
      "Evolution: 26% complete\n",
      "Evolution: 27% complete\n",
      "Evolution: 28% complete\n",
      "Evolution: 29% complete\n",
      "Evolution: 30% complete\n",
      "Evolution: 31% complete\n",
      "Evolution: 32% complete\n",
      "Evolution: 33% complete\n",
      "Evolution: 34% complete\n",
      "Evolution: 35% complete\n",
      "Evolution: 36% complete\n",
      "Evolution: 37% complete\n",
      "Evolution: 38% complete\n",
      "Evolution: 39% complete\n",
      "Evolution: 40% complete\n",
      "Evolution: 41% complete\n",
      "Evolution: 42% complete\n",
      "Evolution: 43% complete\n",
      "Evolution: 44% complete\n",
      "Evolution: 45% complete\n",
      "Evolution: 46% complete\n",
      "Evolution: 47% complete\n",
      "Evolution: 48% complete\n",
      "Evolution: 49% complete\n",
      "Evolution: 50% complete\n",
      "Evolution: 51% complete\n",
      "Evolution: 52% complete\n",
      "Evolution: 53% complete\n",
      "Evolution: 54% complete\n",
      "Evolution: 55% complete\n",
      "Evolution: 56% complete\n",
      "Evolution: 57% complete\n",
      "Evolution: 58% complete\n",
      "Evolution: 59% complete\n",
      "Evolution: 60% complete\n",
      "Evolution: 61% complete\n",
      "Evolution: 62% complete\n",
      "Evolution: 63% complete\n",
      "Evolution: 64% complete\n",
      "Evolution: 65% complete\n",
      "Evolution: 66% complete\n",
      "Evolution: 67% complete\n",
      "Evolution: 68% complete\n",
      "Evolution: 69% complete\n",
      "Evolution: 70% complete\n",
      "Evolution: 71% complete\n",
      "Evolution: 72% complete\n",
      "Evolution: 73% complete\n",
      "Evolution: 74% complete\n",
      "Evolution: 75% complete\n",
      "Evolution: 76% complete\n",
      "Evolution: 77% complete\n",
      "Evolution: 78% complete\n",
      "Evolution: 79% complete\n",
      "Evolution: 80% complete\n",
      "Evolution: 81% complete\n",
      "Evolution: 82% complete\n",
      "Evolution: 83% complete\n",
      "Evolution: 84% complete\n",
      "Evolution: 85% complete\n",
      "Evolution: 86% complete\n",
      "Evolution: 87% complete\n",
      "Evolution: 88% complete\n",
      "Evolution: 89% complete\n",
      "Evolution: 90% complete\n",
      "Evolution: 91% complete\n",
      "Evolution: 92% complete\n",
      "Evolution: 93% complete\n",
      "Evolution: 94% complete\n",
      "Evolution: 95% complete\n",
      "Evolution: 96% complete\n",
      "Evolution: 97% complete\n",
      "Evolution: 98% complete\n",
      "Evolution: 99% complete\n",
      "Evolution: 99% complete\n",
      "\n",
      "\n",
      "Best:\n",
      "  Fitness:\t -58057.351814400965\n",
      "  Phenotype: def fun(price_data):\n",
      "  import pandas as pd\n",
      "  import numpy as np\n",
      "  from fitness.indicators import numba_indicators\n",
      "  from fitness.performance.helper_func import merge_pnl, get_drawdowns, get_pnl, trading_signals, get_lag\n",
      "  from numba import njit\n",
      "  COMMISSION = 0.015\n",
      "  SLIPPAGE = 0.00005\n",
      "  AVAILABLE_CAPITAL = 700000\n",
      "  TRADE_SIZE = 0.5\n",
      "  MAX_LAG = 5\n",
      "  buy_idxs, sell_idxs = trading_signals(buy_signal=(np.sqrt(get_lag(price_data['lin_volume'], lag=1)[MAX_LAG:]) >= np.sin(get_lag(price_data['inj_low'], lag=5)[MAX_LAG:])) & ((np.sin(get_lag(price_data['dog_low'], lag=4)[MAX_LAG:]) + 5) != 0.28266), sell_signal=(np.cos(get_lag(price_data['nvda_close'], lag=1)[MAX_LAG:]) * 4338) >= 92)\n",
      "  if len(buy_idxs) == 0 or len(sell_idxs) == 0:\n",
      "    return 999\n",
      "  buy_idxs = np.array(buy_idxs)\n",
      "  sell_idxs = np.array(sell_idxs)\n",
      "  open_prices = price_data['btc_open']\n",
      "  buy_prices = open_prices[np.isin(np.arange(len(open_prices)), buy_idxs)]\n",
      "  sell_prices = open_prices[np.isin(np.arange(len(open_prices)), sell_idxs)]\n",
      "  if buy_idxs[0] < sell_idxs[0]:\n",
      "    buy_arr = get_pnl(sell_prices, buy_prices, COMMISSION, SLIPPAGE, AVAILABLE_CAPITAL, TRADE_SIZE, 1)\n",
      "    buy_pnl = np.sum(buy_arr)\n",
      "    sell_arr = get_pnl(buy_prices[1:], sell_prices[:-1], COMMISSION, SLIPPAGE, AVAILABLE_CAPITAL, TRADE_SIZE, 0)\n",
      "    sell_pnl = np.sum(sell_arr)\n",
      "    all_arr = merge_pnl(buy_arr, sell_arr)\n",
      "  else:\n",
      "    sell_arr = get_pnl(buy_prices, sell_prices, COMMISSION, SLIPPAGE, AVAILABLE_CAPITAL, TRADE_SIZE, 0)\n",
      "    sell_pnl = np.sum(sell_arr)\n",
      "    buy_arr = get_pnl(sell_prices[1:], buy_prices[:-1], COMMISSION, SLIPPAGE, AVAILABLE_CAPITAL, TRADE_SIZE, 1)\n",
      "    buy_pnl = np.sum(buy_arr)\n",
      "    all_arr = merge_pnl(sell_arr, buy_arr)\n",
      "  total_pnl = buy_pnl + sell_pnl\n",
      "  if total_pnl <= 0:\n",
      "    return 999\n",
      "  equity_curve_arr = np.cumsum(all_arr)\n",
      "  drawdowns = get_drawdowns(equity_curve_arr)\n",
      "  if len(drawdowns[drawdowns!=0]) == 0:\n",
      "    return 999\n",
      "  avg_drawdown = np.sum(drawdowns[drawdowns!=0]) / len(drawdowns[drawdowns!=0])\n",
      "  fitness = total_pnl / avg_drawdown\n",
      "  if np.isnan(fitness):\n",
      "    return 999\n",
      "  return -fitness\n",
      "fitness = fun(price_data)\n",
      "  Genome: [44033, 55834, 65971, 11876, 52011, 6520, 4173, 19614, 72261, 72569, 40000, 73520, 67931, 61189, 75664, 68127, 14084, 50682, 79139, 50188, 8525, 24973, 38786, 62735, 74818, 90328, 16952, 82676, 26056, 86984, 14874, 11414, 16216, 66656, 7530, 40956, 51834, 62573, 95613, 60828, 39648, 70126, 42647, 83762, 22822, 1231, 21200, 7868, 66235, 9074, 25511, 57189, 31428, 27766, 29773, 67544, 12473, 95682, 67375, 88448, 31263, 35780, 92000, 8197, 8905, 38197, 92966, 60877, 51690, 11236, 28883, 82227, 2188, 59454, 28773, 37434, 20609, 93077, 42481, 45790, 87136, 38717, 73291, 64695, 89352, 73520, 67931, 16854, 29093, 19091, 14084, 50682, 79139, 15873, 8525, 82860, 41391, 97878, 24078, 41041, 20609, 90526, 79414, 45058, 33773, 80982, 26716, 44575, 36509, 24078, 29707, 15212, 91176, 36201, 13350, 55197, 26989, 28220, 41479, 98617, 26406, 58026, 35452, 4851, 78738, 29027, 93368, 50252, 41792, 24823, 67905, 77009, 94991, 48792, 84845, 56255, 91491, 80019, 17728, 32854, 99275, 40679, 65188, 95493, 99468, 10350, 7356, 15172, 60200, 89096, 86880, 74213, 9871, 48619, 40043, 52063, 53830, 77658, 37844, 72689, 15898, 97343, 40733, 12514, 23330, 14742, 95795, 5148, 21119, 4279, 6082, 43814, 4523, 94024, 16722, 96954, 65520, 36621, 29121, 19110, 79121, 28103, 96106, 55375, 47095, 86074, 22333, 54027, 69769, 85204, 5752]\n",
      "______\n",
      "\n",
      "  ave_fitness : \t -1018.397303234891\n",
      "  ave_genome_length : \t 298.174\n",
      "  ave_tree_depth : \t 9.48496993987976\n",
      "  ave_tree_nodes : \t 86.93987975951904\n",
      "  ave_used_codons : \t 56.50901803607214\n",
      "  best_fitness : \t -58057.351814400965\n",
      "  gen : \t 100\n",
      "  invalids : \t 938\n",
      "  max_genome_length : \t 602\n",
      "  max_tree_depth : \t 12.0\n",
      "  max_tree_nodes : \t 208.0\n",
      "  max_used_codons : \t 135.0\n",
      "  min_genome_length : \t 45\n",
      "  min_tree_depth : \t 7.0\n",
      "  min_tree_nodes : \t 25.0\n",
      "  min_used_codons : \t 18.0\n",
      "  runtime_error : \t 0\n",
      "  time_adjust : \t 0\n",
      "  time_taken : \t 1457.760424375534\n",
      "  total_inds : \t 50500\n",
      "  total_time : \t 53439.465901613235\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! python ponyge.py --fitness_function max_fitness_numba --grammar_file btc_inst_ind_comb_numba.pybnf --population_size 10 --generations 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set crossover probability.\n",
    "# 'CROSSOVER_PROBABILITY': 0.75,\n",
    "# # Prevents crossover from generating invalids.\n",
    "# 'NO_CROSSOVER_INVALIDS': False,\n",
    "\n",
    "# # Set mutation probability (None defaults to 1 over the length of\n",
    "# # the genome for each codon)\n",
    "# 'MUTATION_PROBABILITY': None,\n",
    "# # Set number of mutation events\n",
    "# 'MUTATION_EVENTS': 1,\n",
    "# # Prevents mutation from generating invalids.\n",
    "# 'NO_MUTATION_INVALIDS': False,\n",
    "\n",
    "# # Set elite size.\n",
    "# 'ELITE_SIZE': None,\n",
    "\n",
    "# # Agent Size. Number of agents having their own copy of genetic material\n",
    "# 'AGENT_SIZE': 100,\n",
    "# # Interaction Probability: how frequently the agents can interaction with\n",
    "# # each other\n",
    "# 'INTERACTION_PROBABILITY': 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "! python ponyge.py --fitness_function max_fitness_numba_cache --grammar_file btc_test_modified.pybnf --population_size 50 --generations 5 --cache --mutate_duplicates --save_all --multicore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python ponyge.py --fitness_function fitness_calc --grammar_file btc_v2024_10_21.pybnf --population_size 10 --generations 1 --cache --mutate_duplicates --multicore --save_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! python ponyge.py --fitness_function max_fitness_numba_cache --grammar_file btc_test.pybnf --population_size 10 --generations 2 --cache --mutate_duplicates --save_all --crossover_probability 0.5 --mutation_probability 0.05 --elite_size 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ge_results1.csv size = (54701, 3)\n",
      "ge_results2.csv size = (19778, 3)\n",
      "There is/are 2620 duplicated rows.\n",
      "(71859, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buy</th>\n",
       "      <th>sell</th>\n",
       "      <th>fitness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>np.sqrt(numba_indicators.aroon(prices=price_da...</td>\n",
       "      <td>((numba_indicators.macd(prices=price_data['goo...</td>\n",
       "      <td>404.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>np.sqrt(numba_indicators.aroon(prices=price_da...</td>\n",
       "      <td>(np.cos(get_lag(price_data['es_high'], lag=2)[...</td>\n",
       "      <td>404.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>np.sqrt(numba_indicators.moving_average(prices...</td>\n",
       "      <td>np.sin(get_lag(price_data['aapl_high'], lag=4)...</td>\n",
       "      <td>404.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(np.sqrt(numba_indicators.price_entropy(prices...</td>\n",
       "      <td>(get_lag(price_data['lin_volume'], lag=5)[MAX_...</td>\n",
       "      <td>404.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(np.sqrt(numba_indicators.n_day_low(prices=pri...</td>\n",
       "      <td>(price_data['btc_open'][MAX_LAG:] &gt;= get_lag(p...</td>\n",
       "      <td>404.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 buy  \\\n",
       "0  np.sqrt(numba_indicators.aroon(prices=price_da...   \n",
       "1  np.sqrt(numba_indicators.aroon(prices=price_da...   \n",
       "2  np.sqrt(numba_indicators.moving_average(prices...   \n",
       "3  (np.sqrt(numba_indicators.price_entropy(prices...   \n",
       "4  (np.sqrt(numba_indicators.n_day_low(prices=pri...   \n",
       "\n",
       "                                                sell  fitness  \n",
       "0  ((numba_indicators.macd(prices=price_data['goo...    404.0  \n",
       "1  (np.cos(get_lag(price_data['es_high'], lag=2)[...    404.0  \n",
       "2  np.sin(get_lag(price_data['aapl_high'], lag=4)...    404.0  \n",
       "3  (get_lag(price_data['lin_volume'], lag=5)[MAX_...    404.0  \n",
       "4  (price_data['btc_open'][MAX_LAG:] >= get_lag(p...    404.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "list_files = os.listdir()\n",
    "list_files = [file for file in list_files if file.endswith('.csv')]\n",
    "\n",
    "ge_df = pd.DataFrame()\n",
    "\n",
    "for file in list_files:\n",
    "    temp_df = pd.read_csv(file)\n",
    "    print(f\"{file} size = {temp_df.shape}\")\n",
    "    ge_df = pd.concat([ge_df, temp_df], axis=0)\n",
    "\n",
    "print(f'There is/are {ge_df.duplicated().sum()} duplicated rows.')\n",
    "\n",
    "ge_df = ge_df[~ge_df.duplicated()]\n",
    "ge_df.to_csv('ge_results_dd_inst_ind_comb_numba.csv', index=False)\n",
    "\n",
    "print(ge_df.shape)\n",
    "\n",
    "ge_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grammar_evol",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
